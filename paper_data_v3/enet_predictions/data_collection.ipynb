{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a01728-b9ae-48b6-b5ff-0f283ecb8837",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e1bc065-dabb-45cb-8aff-a243fd9749c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from domseq import DomSeq\n",
    "\n",
    "\n",
    "NCBI_DIR = 'data/ncbi/'\n",
    "GISAID_DIR = 'data/gisaid/'\n",
    "DATA_DIR = 'data/merged/'\n",
    "\n",
    "NA_TRUNC = 468 # 2 less than official length of 470\n",
    "HA_TRUNC = 565 # 2 less than official length of 567"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeae7b7-8fa9-4e44-a490-f9484e86b40b",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "**Sources: [GISAID](https://platform.epicov.org/epi3/cfrontend#586f5f), [NCBI](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus), [WHO](https://www.who.int/teams/global-influenza-programme/vaccines/who-recommendations/recommendations-for-influenza-vaccine-composition-archive)**\n",
    "- Host: Human\n",
    "- Subtype: H1N1 or H3N2\n",
    "- Segment: HA (4) and NA (6)\n",
    "- Download all data from 09/25/2001 - 02/15/2023 (collection date) from both NCBI and GISAID\n",
    "- For NCBI, filter by the following sequence length\n",
    "    - HA: min = 550, max = 570\n",
    "    - NA: min = 450, max = 470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c76a4-e347-4206-a088-c6a91d37be5e",
   "metadata": {},
   "source": [
    "## Cleaning and Merging Data\n",
    "- Make `h1n1.csv` and `h3n2.csv`\n",
    "- Merge HA, and NA data\n",
    "    - Put HA strain in `sequence` column, NA strain in `na_sequence` column\n",
    "    - Keep only strains with both HA and NA available\n",
    "    - Truncate to 468 for NA (2 less than official length of 470)\n",
    "    - Truncate to 565 for HA (2 less than official length of 567)\n",
    "- Merge GISAID and NCBI data\n",
    "- Save to `data/merged/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afef8c70-8fa1-4ada-bd83-3e3d65c63d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_ncbi_gisaid(domseq, NCBI_FILE, GISAID_FILE):\n",
    "    ''' Returns merged sequence DataFrame.\n",
    "    '''\n",
    "    seq_df = pd.DataFrame({'acc':[],'name':[],'date':[],'sequence':[]})\n",
    "    if os.path.isfile(NCBI_FILE):\n",
    "        seq_df_ncbi = domseq.load_data(NCBI_FILE)\n",
    "        seq_df = seq_df.append(seq_df_ncbi)\n",
    "    if os.path.isfile(GISAID_FILE):\n",
    "        seq_df_gisaid = domseq.load_data(GISAID_FILE)\n",
    "        seq_df = seq_df.append(seq_df_gisaid)\n",
    "    return seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba560a8-5391-4449-9b8b-e7539f117c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine GISAID and NCBI, merge on HA and NA, remove duplicates by name\n",
    "for SUBTYPE in ['h1n1', 'h3n2']:\n",
    "    # Initialize the DomSeq\n",
    "    domseq_ha = DomSeq(seq_trunc_length=HA_TRUNC)\n",
    "    domseq_na = DomSeq(seq_trunc_length=NA_TRUNC)\n",
    "    \n",
    "    # File name\n",
    "    GISAID_FILE_HA = GISAID_DIR+SUBTYPE+'_ha.fasta'\n",
    "    GISAID_FILE_NA = GISAID_DIR+SUBTYPE+'_na.fasta'\n",
    "    NCBI_FILE_HA = NCBI_DIR+SUBTYPE+'_ha.fasta'\n",
    "    NCBI_FILE_NA = NCBI_DIR+SUBTYPE+'_na.fasta'\n",
    "    \n",
    "    # Load data\n",
    "    seq_df_ha = load_ncbi_gisaid(domseq_ha, NCBI_FILE_HA, GISAID_FILE_HA)\n",
    "    seq_df_na = load_ncbi_gisaid(domseq_na, NCBI_FILE_NA, GISAID_FILE_NA)\n",
    "    \n",
    "    # Drop duplicates by name\n",
    "    seq_df_ha.drop_duplicates(subset=['name'], inplace=True)\n",
    "    seq_df_na.drop_duplicates(subset=['name'], inplace=True)\n",
    "    seq_df_na.rename(columns={'acc':'acc_na', 'sequence':'sequence_na'}, inplace=True)\n",
    "    \n",
    "    # Merge HA and NA on name and date\n",
    "    seq_df = seq_df_ha.merge(seq_df_na, how='inner', on=['name', 'date'])\n",
    "    seq_df['date'] = pd.to_datetime(seq_df['date'])\n",
    "    seq_df.sort_values(by='date', inplace=True)\n",
    "    \n",
    "    # Save to csv\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)  \n",
    "    seq_df.to_csv(DATA_DIR+SUBTYPE+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23892e11-163a-4cac-878e-c9c91fa476ef",
   "metadata": {},
   "source": [
    "## Seasonal Files\n",
    "- Make seperate files for North H1N1, North H3N2, South H1N1, South H3N2\n",
    "    - Make seperate file for each season (21 seasons total for each category)\n",
    "- Flu Season example: \n",
    "    - Northern strains from 10/1/2002 - 4/1/2003: predict for 2003-04 season\n",
    "    - Southern strains from 4/1/2002 - 10/1/2002: predict for 2003 season\n",
    "    - Flu season dates from [CDC](https://www.cdc.gov/flu/school-business/travelersfacts.htm) and [WHO](https://www.who.int/teams/global-influenza-programme/vaccines/who-recommendations/recommendations-for-influenza-vaccine-composition-archive)\n",
    "- File names for raw data: `<hemisphere>_<subtype>_<season>` (+ '_pred' if prediction data)\n",
    "    - `hemisphere`: \"north\" or \"south\"\n",
    "    - `subtype`: \"h1n1\" or \"h3n2\"\n",
    "    - `season`: (ex. 02_03 for north 10/1/2002 - 4/1/2003, 02 for south 4/1/2002 - 10/1/2002)\n",
    "    - **'pred': all sequence data up to that point, used for prediction**\n",
    "        - Only use unique strains here\n",
    "        - Season specific data is for training models, but we will predict on all data up to that point\n",
    "- Save to `data/merged/`\n",
    "    - Some seasons will have no strains from a particular database\n",
    "    - In each year record how many strains come from NCBI and GISAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffe0c8b-8ed9-4b79-b963-d4c8e092b979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NORTH_YEARS = []\n",
    "for i in np.arange(2, 23):\n",
    "    YEAR = ''\n",
    "    if i < 10:\n",
    "        YEAR += '0' + str(i)\n",
    "    else:\n",
    "        YEAR += (str(i))\n",
    "    if i + 1 < 10:\n",
    "        YEAR += '_0' + str(i + 1)\n",
    "    else:\n",
    "        YEAR += '_' + str(i + 1)\n",
    "    NORTH_YEARS.append(YEAR)\n",
    "        \n",
    "SOUTH_YEARS = []\n",
    "for i in np.arange(2, 23):\n",
    "    if i < 10:\n",
    "        SOUTH_YEARS.append('0' + str(i))\n",
    "    else:\n",
    "        SOUTH_YEARS.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5031381-8641-4c06-a94f-dc3bc7fe4566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for SUBTYPE in ['h1n1', 'h3n2']:\n",
    "    df = pd.read_csv(DATA_DIR+SUBTYPE+'.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    for i in range(21):\n",
    "        NORTH_START = str(2002 + i) + '-10-01'\n",
    "        NORTH_END = str(2003 + i) + '-04-01'\n",
    "        NORTH_DIR = DATA_DIR + 'north_' + SUBTYPE + '/'\n",
    "        os.makedirs(NORTH_DIR, exist_ok=True) \n",
    "        os.makedirs(NORTH_DIR+'pred', exist_ok=True) \n",
    "        # North\n",
    "        north_df = df.loc[(df['date'] >= NORTH_START) & (df['date'] <= NORTH_END)]\n",
    "        north_df.to_csv(NORTH_DIR+'north_'+SUBTYPE+'_'+NORTH_YEARS[i]+'.csv', index=False)\n",
    "        # North prediction\n",
    "        north_pred_df = df.loc[df['date'] <= NORTH_END].drop_duplicates(subset=['sequence'])\n",
    "        north_pred_df.to_csv(NORTH_DIR+'pred/north_'+SUBTYPE+'_'+NORTH_YEARS[i]+'.csv', index=False)\n",
    "        \n",
    "        SOUTH_START = str(2002 + i) + '-04-01'\n",
    "        SOUTH_END = str(2002 + i) + '-10-01'\n",
    "        SOUTH_DIR = DATA_DIR + 'south_' + SUBTYPE + '/'\n",
    "        os.makedirs(SOUTH_DIR, exist_ok=True) \n",
    "        os.makedirs(SOUTH_DIR+'pred', exist_ok=True)\n",
    "        # South\n",
    "        south_df = df.loc[(df['date'] >= SOUTH_START) & (df['date'] <= SOUTH_END)]\n",
    "        south_df.to_csv(SOUTH_DIR+'south_'+SUBTYPE+'_'+SOUTH_YEARS[i]+'.csv', index=False)\n",
    "        # South prediction\n",
    "        south_pred_df = df.loc[df['date'] <= SOUTH_END].drop_duplicates(subset=['sequence'])\n",
    "        south_pred_df.to_csv(SOUTH_DIR+'pred/south_'+SUBTYPE+'_'+SOUTH_YEARS[i]+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f22d389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>north_season</th>\n",
       "      <th>north_h1n1</th>\n",
       "      <th>north_h3n2</th>\n",
       "      <th>south_season</th>\n",
       "      <th>south_h1n1</th>\n",
       "      <th>south_h3n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02_03</td>\n",
       "      <td>37</td>\n",
       "      <td>67</td>\n",
       "      <td>02</td>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03_04</td>\n",
       "      <td>14</td>\n",
       "      <td>345</td>\n",
       "      <td>03</td>\n",
       "      <td>16</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04_05</td>\n",
       "      <td>7</td>\n",
       "      <td>254</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05_06</td>\n",
       "      <td>34</td>\n",
       "      <td>154</td>\n",
       "      <td>05</td>\n",
       "      <td>36</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06_07</td>\n",
       "      <td>442</td>\n",
       "      <td>264</td>\n",
       "      <td>06</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07_08</td>\n",
       "      <td>394</td>\n",
       "      <td>407</td>\n",
       "      <td>07</td>\n",
       "      <td>91</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08_09</td>\n",
       "      <td>597</td>\n",
       "      <td>316</td>\n",
       "      <td>08</td>\n",
       "      <td>180</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09_10</td>\n",
       "      <td>3338</td>\n",
       "      <td>125</td>\n",
       "      <td>09</td>\n",
       "      <td>4473</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10_11</td>\n",
       "      <td>1611</td>\n",
       "      <td>1050</td>\n",
       "      <td>10</td>\n",
       "      <td>635</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11_12</td>\n",
       "      <td>454</td>\n",
       "      <td>1450</td>\n",
       "      <td>11</td>\n",
       "      <td>317</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12_13</td>\n",
       "      <td>1082</td>\n",
       "      <td>2152</td>\n",
       "      <td>12</td>\n",
       "      <td>304</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13_14</td>\n",
       "      <td>1690</td>\n",
       "      <td>1173</td>\n",
       "      <td>13</td>\n",
       "      <td>541</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14_15</td>\n",
       "      <td>844</td>\n",
       "      <td>3714</td>\n",
       "      <td>14</td>\n",
       "      <td>467</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15_16</td>\n",
       "      <td>5101</td>\n",
       "      <td>2005</td>\n",
       "      <td>15</td>\n",
       "      <td>690</td>\n",
       "      <td>1683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16_17</td>\n",
       "      <td>1053</td>\n",
       "      <td>7510</td>\n",
       "      <td>16</td>\n",
       "      <td>1313</td>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17_18</td>\n",
       "      <td>3722</td>\n",
       "      <td>5797</td>\n",
       "      <td>17</td>\n",
       "      <td>982</td>\n",
       "      <td>3698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18_19</td>\n",
       "      <td>8086</td>\n",
       "      <td>7373</td>\n",
       "      <td>18</td>\n",
       "      <td>2106</td>\n",
       "      <td>1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19_20</td>\n",
       "      <td>7058</td>\n",
       "      <td>4396</td>\n",
       "      <td>19</td>\n",
       "      <td>2008</td>\n",
       "      <td>3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20_21</td>\n",
       "      <td>191</td>\n",
       "      <td>251</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21_22</td>\n",
       "      <td>756</td>\n",
       "      <td>10117</td>\n",
       "      <td>21</td>\n",
       "      <td>228</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22_23</td>\n",
       "      <td>6557</td>\n",
       "      <td>11674</td>\n",
       "      <td>22</td>\n",
       "      <td>1587</td>\n",
       "      <td>8943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   north_season  north_h1n1  north_h3n2 south_season  south_h1n1  south_h3n2\n",
       "0         02_03          37          67           02           5         158\n",
       "1         03_04          14         345           03          16         200\n",
       "2         04_05           7         254           04           4         228\n",
       "3         05_06          34         154           05          36         270\n",
       "4         06_07         442         264           06          40          23\n",
       "5         07_08         394         407           07          91         214\n",
       "6         08_09         597         316           08         180         125\n",
       "7         09_10        3338         125           09        4473         738\n",
       "8         10_11        1611        1050           10         635         504\n",
       "9         11_12         454        1450           11         317         537\n",
       "10        12_13        1082        2152           12         304         913\n",
       "11        13_14        1690        1173           13         541         580\n",
       "12        14_15         844        3714           14         467         832\n",
       "13        15_16        5101        2005           15         690        1683\n",
       "14        16_17        1053        7510           16        1313        1417\n",
       "15        17_18        3722        5797           17         982        3698\n",
       "16        18_19        8086        7373           18        2106        1556\n",
       "17        19_20        7058        4396           19        2008        3289\n",
       "18        20_21         191         251           20          41         159\n",
       "19        21_22         756       10117           21         228         544\n",
       "20        22_23        6557       11674           22        1587        8943"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = pd.DataFrame({})\n",
    "for SEASON in ['north', 'south']:\n",
    "    YEARS = NORTH_YEARS\n",
    "    if SEASON == 'south':\n",
    "        YEARS = SOUTH_YEARS\n",
    "    num_seqs[SEASON + '_season'] = YEARS\n",
    "    \n",
    "    for SUBTYPE in ['h1n1', 'h3n2']:\n",
    "        seq_cnt = []\n",
    "        NAME = SEASON + '_' + SUBTYPE\n",
    "        DIR = DATA_DIR + NAME + '/'\n",
    "        for i in range(21):\n",
    "            seq_df = pd.read_csv(DIR+NAME+'_'+YEARS[i]+'.csv')\n",
    "            seq_cnt.append(len(seq_df))\n",
    "        num_seqs[NAME] = seq_cnt\n",
    "num_seqs.to_csv(DATA_DIR+'num_seqs.csv', index=False)\n",
    "num_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b17180b-7ad8-4e1a-ad33-d13fc0728ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>north_season</th>\n",
       "      <th>north_h1n1</th>\n",
       "      <th>north_h3n2</th>\n",
       "      <th>south_season</th>\n",
       "      <th>south_h1n1</th>\n",
       "      <th>south_h3n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02_03</td>\n",
       "      <td>31</td>\n",
       "      <td>156</td>\n",
       "      <td>02</td>\n",
       "      <td>20</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03_04</td>\n",
       "      <td>37</td>\n",
       "      <td>314</td>\n",
       "      <td>03</td>\n",
       "      <td>36</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04_05</td>\n",
       "      <td>46</td>\n",
       "      <td>451</td>\n",
       "      <td>04</td>\n",
       "      <td>40</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05_06</td>\n",
       "      <td>90</td>\n",
       "      <td>592</td>\n",
       "      <td>05</td>\n",
       "      <td>65</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06_07</td>\n",
       "      <td>282</td>\n",
       "      <td>749</td>\n",
       "      <td>06</td>\n",
       "      <td>119</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07_08</td>\n",
       "      <td>600</td>\n",
       "      <td>1048</td>\n",
       "      <td>07</td>\n",
       "      <td>355</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08_09</td>\n",
       "      <td>1085</td>\n",
       "      <td>1290</td>\n",
       "      <td>08</td>\n",
       "      <td>730</td>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09_10</td>\n",
       "      <td>3463</td>\n",
       "      <td>1644</td>\n",
       "      <td>09</td>\n",
       "      <td>2207</td>\n",
       "      <td>1565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10_11</td>\n",
       "      <td>4538</td>\n",
       "      <td>2258</td>\n",
       "      <td>10</td>\n",
       "      <td>3747</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11_12</td>\n",
       "      <td>4967</td>\n",
       "      <td>3048</td>\n",
       "      <td>11</td>\n",
       "      <td>4702</td>\n",
       "      <td>2469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12_13</td>\n",
       "      <td>5769</td>\n",
       "      <td>3968</td>\n",
       "      <td>12</td>\n",
       "      <td>5163</td>\n",
       "      <td>3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13_14</td>\n",
       "      <td>6709</td>\n",
       "      <td>4615</td>\n",
       "      <td>13</td>\n",
       "      <td>6076</td>\n",
       "      <td>4184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14_15</td>\n",
       "      <td>7249</td>\n",
       "      <td>6019</td>\n",
       "      <td>14</td>\n",
       "      <td>6919</td>\n",
       "      <td>4891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15_16</td>\n",
       "      <td>8953</td>\n",
       "      <td>7229</td>\n",
       "      <td>15</td>\n",
       "      <td>7569</td>\n",
       "      <td>6542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16_17</td>\n",
       "      <td>9698</td>\n",
       "      <td>9888</td>\n",
       "      <td>16</td>\n",
       "      <td>9317</td>\n",
       "      <td>7710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17_18</td>\n",
       "      <td>11415</td>\n",
       "      <td>12447</td>\n",
       "      <td>17</td>\n",
       "      <td>10119</td>\n",
       "      <td>10936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18_19</td>\n",
       "      <td>14835</td>\n",
       "      <td>15195</td>\n",
       "      <td>18</td>\n",
       "      <td>12278</td>\n",
       "      <td>13007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19_20</td>\n",
       "      <td>17692</td>\n",
       "      <td>17567</td>\n",
       "      <td>19</td>\n",
       "      <td>15502</td>\n",
       "      <td>16220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20_21</td>\n",
       "      <td>17767</td>\n",
       "      <td>17727</td>\n",
       "      <td>20</td>\n",
       "      <td>17703</td>\n",
       "      <td>17617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21_22</td>\n",
       "      <td>18172</td>\n",
       "      <td>19783</td>\n",
       "      <td>21</td>\n",
       "      <td>17892</td>\n",
       "      <td>17916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22_23</td>\n",
       "      <td>20071</td>\n",
       "      <td>24300</td>\n",
       "      <td>22</td>\n",
       "      <td>18607</td>\n",
       "      <td>21593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   north_season  north_h1n1  north_h3n2 south_season  south_h1n1  south_h3n2\n",
       "0         02_03          31         156           02          20         126\n",
       "1         03_04          37         314           03          36         220\n",
       "2         04_05          46         451           04          40         393\n",
       "3         05_06          90         592           05          65         534\n",
       "4         06_07         282         749           06         119         605\n",
       "5         07_08         600        1048           07         355         874\n",
       "6         08_09        1085        1290           08         730        1121\n",
       "7         09_10        3463        1644           09        2207        1565\n",
       "8         10_11        4538        2258           10        3747        1858\n",
       "9         11_12        4967        3048           11        4702        2469\n",
       "10        12_13        5769        3968           12        5163        3375\n",
       "11        13_14        6709        4615           13        6076        4184\n",
       "12        14_15        7249        6019           14        6919        4891\n",
       "13        15_16        8953        7229           15        7569        6542\n",
       "14        16_17        9698        9888           16        9317        7710\n",
       "15        17_18       11415       12447           17       10119       10936\n",
       "16        18_19       14835       15195           18       12278       13007\n",
       "17        19_20       17692       17567           19       15502       16220\n",
       "18        20_21       17767       17727           20       17703       17617\n",
       "19        21_22       18172       19783           21       17892       17916\n",
       "20        22_23       20071       24300           22       18607       21593"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs_pred = pd.DataFrame({})\n",
    "for SEASON in ['north', 'south']:\n",
    "    YEARS = NORTH_YEARS\n",
    "    if SEASON == 'south':\n",
    "        YEARS = SOUTH_YEARS\n",
    "    num_seqs_pred[SEASON + '_season'] = YEARS\n",
    "    \n",
    "    for SUBTYPE in ['h1n1', 'h3n2']:\n",
    "        seq_cnt = []\n",
    "        NAME = SEASON + '_' + SUBTYPE\n",
    "        DIR = DATA_DIR + NAME + '/pred/'\n",
    "        for i in range(21):\n",
    "            seq_df = pd.read_csv(DIR+NAME+'_'+YEARS[i]+'.csv')\n",
    "            seq_cnt.append(len(seq_df))\n",
    "        num_seqs_pred[NAME] = seq_cnt\n",
    "num_seqs_pred.to_csv(DATA_DIR+'num_seqs_pred.csv', index=False)\n",
    "num_seqs_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
