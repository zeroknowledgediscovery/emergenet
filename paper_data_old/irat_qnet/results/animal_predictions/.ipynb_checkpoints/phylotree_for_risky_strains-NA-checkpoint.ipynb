{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPI1907263 H1N1\n",
      "EPI2158738 H1N1\n",
      "EPI1830281 H1N1\n",
      "EPI1778720 H1N1\n",
      "EPI1777715 H1N1\n",
      "EPI1975300 H1N1\n",
      "EPI1908176 H1N1\n",
      "EPI1908559 H1N1\n",
      "EPI1908557 H1N1\n",
      "EPI1908547 H1N1\n",
      "EPI1833072 H1N1\n",
      "EPI1832802 H1N1\n",
      "EPI1775980 H1N1\n",
      "EPI1833157 H1N1\n",
      "EPI1908812 H1N1\n",
      "EPI1908102 H1N1\n",
      "EPI1832788 H1N1\n",
      "EPI1832641 H1N1\n",
      "EPI1775888 H1N1\n",
      "EPI1976602 H1N1\n",
      "EPI1976249 H1N1\n",
      "EPI1778580 H1N1\n",
      "EPI1768609 H1N1\n",
      "EPI1766616 H1N1\n",
      "EPI1910821 H1N1\n",
      "EPI1909021 H1N1\n",
      "EPI1910887 H1N1\n",
      "EPI1909019 H1N1\n",
      "EPI1908782 H1N1\n",
      "EPI1908789 H1N1\n",
      "EPI1832784 H1N1\n",
      "EPI2153378 H1N1\n",
      "EPI1832818 H1N1\n",
      "EPI1911033 H1N1\n",
      "EPI2026200 H7N9\n",
      "EPI1769192 H3N2\n",
      "EPI1930925 H3N2\n",
      "EPI2148218 H3N2\n",
      "EPI2148192 H3N2\n",
      "EPI1817170 H3N2\n",
      "EPI1775924 H3N2\n",
      "EPI1818137 H3N2\n",
      "EPI1766723 H3N2\n",
      "EPI1817876 H1N1\n",
      "EPI1769150 H1N1\n",
      "EPI1975820 H1N1\n",
      "EPI1975364 H1N1\n",
      "EPI1975316 H1N1\n",
      "EPI1910743 H1N1\n",
      "EPI2146879 H1N1\n",
      "EPI1910432 H1N1\n",
      "EPI1909033 H1N1\n",
      "EPI1908134 H1N1\n",
      "EPI1907387 H1N1\n",
      "EPI1932076 H1N1\n",
      "EPI1911241 H1N1\n",
      "EPI1910943 H1N1\n",
      "EPI1775916 H1N1\n",
      "EPI1908086 H1N1\n",
      "EPI1780479 H1N1\n",
      "EPI1818121 H1N1\n",
      "EPI1780419 H1N1\n",
      "EPI1780098 H1N1\n",
      "EPI1780243 H1N1\n",
      "EPI1818373 H1N1\n",
      "EPI1778732 H1N1\n",
      "EPI1773255 H1N1\n",
      "EPI1775900 H1N1\n",
      "EPI1909037 H1N1\n",
      "EPI1908513 H1N1\n",
      "EPI1908453 H1N1\n",
      "EPI1766712 H1N1\n",
      "EPI1766716 H1N1\n",
      "EPI1778590 H1N1\n",
      "EPI1779438 H1N1\n",
      "EPI1779454 H1N1\n",
      "EPI1779474 H1N1\n",
      "EPI1780120 H1N1\n",
      "EPI1818149 H1N1\n",
      "EPI1907229 H1N1\n",
      "42.26588051282051\n",
      "42.80180103896103\n",
      "43.36498263157894\n",
      "43.94318239999999\n",
      "44.537009189189185\n",
      "45.14704520547946\n",
      "45.75982944444445\n",
      "46.373960845070414\n",
      "47.003820714285716\n",
      "4.821311818181819\n",
      "3.8285700000000005\n",
      "2.0\n",
      "4.9467275\n",
      "6.014516666666668\n",
      "6.441972000000002\n",
      "6.241132499999999\n",
      "2.0036766666666668\n",
      "2.0\n",
      "0.5\n",
      "54.85225694915253\n",
      "55.76333689655171\n",
      "2.9999999999999996\n",
      "57.57534928571429\n",
      "2.2673349999999997\n",
      "3.0\n",
      "0.3527333333333332\n",
      "0.20021599999999995\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "66.31181\n",
      "3.0\n",
      "68.75736869565219\n",
      "153.7234510526316\n",
      "1.6154119999999998\n",
      "1.0196966666666667\n",
      "0.0\n",
      "0.0\n",
      "206.561985\n",
      "221.30248153846156\n",
      "238.3316583333333\n",
      "258.00362272727267\n",
      "147.21609111111107\n",
      "9.921707499999997\n",
      "8.818077142857144\n",
      "7.771415000000009\n",
      "0.5\n",
      "6.589132500000005\n",
      "4.753289999999993\n",
      "3.0\n",
      "0.5\n",
      "7.546015555555557\n",
      "4.5\n",
      "7.534327200000002\n",
      "3.809787916666666\n",
      "3.121814\n",
      "0.8768000000000006\n",
      "0.21406400000000048\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.015935\n",
      "1.34394\n",
      "0.0\n",
      "2.219657857142857\n",
      "1.6250233333333333\n",
      "1.2805074999999997\n",
      "1.0116971428571426\n",
      "1.002413333333333\n",
      "0.3396233333333332\n",
      "0.0\n",
      "1.1652033333333325\n",
      "0.5\n",
      "2.1294180000000003\n",
      "2.25\n",
      "1.0\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "class SeqInfo(object):\n",
    "    \"\"\"Holds information regarding the sequence.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, seq, \n",
    "                 protein,\n",
    "                 accession,\n",
    "                 name=None,\n",
    "                 subtype=None,\n",
    "                 host=None, \n",
    "                 date=None, \n",
    "                 erisk=None,\n",
    "                 irisk=None,\n",
    "                 risk_flag=None,\n",
    "                 country=None):\n",
    "        self.name = name\n",
    "        self.protein=protein\n",
    "        self.subtype=subtype        \n",
    "        self.seq = seq\n",
    "        self.accession = accession \n",
    "        self.host = host\n",
    "        self.date = date\n",
    "        self.erisk = erisk\n",
    "        self.irisk = irisk\n",
    "        self.risk_flag = risk_flag\n",
    "        self.country = country\n",
    "        \n",
    "class MultipleSeqInfo(object):\n",
    "    \"\"\"Holds information regarding the sequences in the records.\n",
    "    \n",
    "    Args:\n",
    "        records (list): list of records parsed from NCBI\n",
    "        cov19_accessions (list): of accessions corresponding to cov19\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dataframe,\n",
    "                 accessionname,\n",
    "                 proteinname,\n",
    "                 risk_threshold=6.2):\n",
    "        \n",
    "        self.seq_infos = {}\n",
    "        self.risk_threshold = risk_threshold\n",
    "        for i in np.arange(dataframe.index.size):\n",
    "            record=dataframe.iloc[i,:]\n",
    "            seqinfo = SeqInfo(\n",
    "                name=record.id,\n",
    "                seq=record[proteinname], \n",
    "                protein=proteinname,\n",
    "                accession=record[accessionname],\n",
    "                subtype=record.subtype,\n",
    "                erisk=record.predicted_emergence_score,\n",
    "                irisk=record.predicted_impact_score,\n",
    "                risk_flag = record.predicted_emergence_score > self.risk_threshold,\n",
    "                host=None,\n",
    "                date=None,\n",
    "                country=None)\n",
    "            #print(record.predicted_emergence_score > self.risk_threshold)\n",
    "            self.seq_infos[seqinfo.accession] = seqinfo\n",
    "            \n",
    "    \n",
    "    def compute_L_diatance_matrix(self):\n",
    "        highriskseq = pd.DataFrame.from_dict({key:val.seq \n",
    "                                              for (key,val) in self.seq_infos.items() \n",
    "                                              if val.risk_flag},orient='index',columns=['seq'])\n",
    "        num=highriskseq.index.size\n",
    "        d=np.zeros([num,num])\n",
    "        for i in np.arange(num):\n",
    "            for j in np.arange(num):\n",
    "                if i > j:\n",
    "                    d[i,j] = Levenshtein.distance(highriskseq.seq.values[i],\n",
    "                                                  highriskseq.seq.values[j])\n",
    "                    ds=pd.DataFrame(d)        \n",
    "                    ds=(ds+ds.transpose())\n",
    "                    ds.columns=highriskseq.index.values\n",
    "                    self.highriskdistancematrix=ds.copy()\n",
    "        return ds\n",
    "    \n",
    "    \n",
    "    def accessions_to_subtype(self, accessions):\n",
    "        \"\"\"Create a dictionary mapping the accession to the host.\n",
    "        \"\"\"\n",
    "        \n",
    "        subtypes = []\n",
    "        \n",
    "        for accession in accessions:\n",
    "            seqinfo = self.seq_infos[accession]\n",
    "            subtypes.append(seqinfo.subtype)\n",
    "            \n",
    "        return subtypes\n",
    "\n",
    "    def accessions_to_host(self, accessions):\n",
    "        \"\"\"Create a dictionary mapping the accession to the host.\n",
    "        \"\"\"\n",
    "        \n",
    "        hosts = []\n",
    "        \n",
    "        for accession in accessions:\n",
    "            seqinfo = self.seq_infos[accession]\n",
    "            hosts.append(seqinfo.host)\n",
    "            \n",
    "        return hosts\n",
    "    \n",
    "\n",
    "\n",
    "#N=10000\n",
    "df=pd.read_csv('./combined_results.csv',index_col=0)\n",
    "#df1=df[['subtype','predicted_impact_score', 'predicted_emergence_score', 'ha', 'na']]\n",
    "#df1=df1.sort_values('predicted_emergence_score',ascending=False).head(N)\n",
    "#df1=df1[df1.predicted_emergence_score>6.2]\n",
    "#df1.subtype.value_counts()\n",
    "\n",
    "ALLinfoNA=MultipleSeqInfo(df.reset_index(),'na_accession','na',risk_threshold=6.2)\n",
    "ds=ALLinfoNA.compute_L_diatance_matrix()\n",
    "\n",
    "\n",
    "from Bio.Phylo import TreeConstruction\n",
    "from Bio import Phylo\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "def load_dm(file_, upper_diag=True):\n",
    "    \"\"\"Load the distance matrix. \n",
    "    \n",
    "    Also, do some preprocessing. \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_)\n",
    "    #df.set_index('Unnamed: 0', inplace=True)\n",
    "    #assert np.all(df.columns == df.index)\n",
    "    \n",
    "    # drop duplicate columns after reading csv\n",
    "    #df = df.loc[:, ~df.columns.str.replace(\"(\\.\\d+)$\", \"\").duplicated()]\n",
    "    \n",
    "    if upper_diag:\n",
    "        df = df + df.T\n",
    "    return df\n",
    "\n",
    "def save_tree(tree, file_name, save_type='xml'):\n",
    "    \"\"\"Saved the created phylogenetic tree.\"\"\"\n",
    "    \n",
    "    if save_type == 'pickle':\n",
    "        graph = Phylo.to_networkx(tree)\n",
    "        save_pickled(graph, file_name)\n",
    "    elif save_type == 'xml':\n",
    "        Phylo.write(tree, file_name, 'phyloxml')\n",
    "    else:\n",
    "        raise ValueError('Not a correct save type.')\n",
    "    \n",
    "def pandas_dm_to_biopython_dm(dm):\n",
    "    \"\"\"Convert the pandas distance matrix to the biopython distance matrix.\n",
    "    \n",
    "    Returns:\n",
    "        biopython distance matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    accessions = dm.columns\n",
    "    bio_dm = []\n",
    "    for i, accession in enumerate(accessions):\n",
    "        bio_dm.append(list(dm.iloc[i, :i+1].values))\n",
    "        \n",
    "    bio_dm = TreeConstruction._DistanceMatrix(\n",
    "        list(dm.columns), \n",
    "        bio_dm)\n",
    "    \n",
    "    return bio_dm\n",
    "\n",
    "def distance_matrix_to_phylo_tree(dm, outfile=None):\n",
    "    \"\"\"Create a phylogenetic tree from the distance matrix.\"\"\"\n",
    "    \n",
    "    dm = pandas_dm_to_biopython_dm(dm)\n",
    "    \n",
    "    treeConstructor = TreeConstruction.DistanceTreeConstructor()\n",
    "    tree = treeConstructor.nj(dm)\n",
    "    \n",
    "    if outfile is not None:\n",
    "        save_tree(tree, outfile)\n",
    "\n",
    "\n",
    "ds.to_csv('dm.csv',index=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from ete3 import Tree, TreeStyle\n",
    "from ete3 import Phyloxml\n",
    "from ete3 import AttrFace, faces, Tree, NodeStyle, TreeStyle\n",
    "\n",
    "def load_pickled(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f, encoding='latin')\n",
    "\n",
    "\n",
    "def get_farthest_node(tree, sequence):\n",
    "    return (tree&sequence).get_farthest_node()\n",
    "\n",
    "def get_all_accessions_from_tree(tree):\n",
    "    return [leaf_node.name for leaf_node in tree.get_leaves()]\n",
    "\n",
    "def remove_certain_hosts_from_tree(tree, hosts):\n",
    "    \"\"\"Remove leaf nodes if the host of that leaf is in `hosts`\"\"\"\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    removed_accessions = []\n",
    "    for leaf_node in tree.get_leaves():\n",
    "        if leaf_node.host in hosts:\n",
    "            leaf_node.detach()\n",
    "            \n",
    "    return tree\n",
    "\n",
    "def set_midpoint_outgroup(tree):\n",
    "    tree.set_outgroup(tree.get_midpoint_outgroup())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_tree(filename, type_='phyloxml'):\n",
    "    \"\"\"Load saved phylogenetic tree.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type_ == 'phyloxml':\n",
    "        project = Phyloxml()\n",
    "        project.build_from_file(filename)\n",
    "\n",
    "        for tree in project.get_phylogeny():\n",
    "            break\n",
    "\n",
    "        t=tree\n",
    "        \n",
    "    elif type_ == 'newick':\n",
    "        t = Tree(filename, format=1)\n",
    "    else:\n",
    "        raise ValueError('Not a correct type.')\n",
    "    \n",
    "    return t\n",
    "\n",
    "\n",
    "\n",
    "PHYLO_DIR='./'\n",
    "\n",
    "Phylo.convert(\n",
    "    PHYLO_DIR + 'ldistanceh1n1.xml','phyloxml',\n",
    "    PHYLO_DIR + 'ldistance.nhx','newick')\n",
    "\n",
    "ltree = load_tree(\n",
    "    PHYLO_DIR + 'ldistance.nhx',\n",
    "    type_='newick')\n",
    "\n",
    "\n",
    "\n",
    "def label_nodes(\n",
    "        tree, \n",
    "        recordinfo):\n",
    "    \"\"\"Label the nodes of the tree.\n",
    "    \n",
    "    We label nodes on whether:\n",
    "        it is covid19\n",
    "    \"\"\"\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    for node in tree:\n",
    "        name = node.name      \n",
    "        node.host = recordinfo.seq_infos[name].subtype\n",
    "        print(node.name,node.host)\n",
    "    return tree\n",
    "\n",
    "\n",
    "labelled_tree=label_nodes(\n",
    "    ltree, ALLinfoHA)\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "def prune_nodes(t):\n",
    "    # collapsed nodes are labeled, so you locate them and prune them\n",
    "    for n in t.search_nodes(collapsed=True):\n",
    "        for ch in n.get_children():\n",
    "            ch.detach()\n",
    "            \n",
    "            \n",
    "def mean(array):\n",
    "    return sum(array)/float(len(array))\n",
    "\n",
    "def cache_distances(tree):\n",
    "    ''' precalculate distances of all nodes to the root''' \n",
    "    node2rootdist = {tree:0}\n",
    "    for node in tree.iter_descendants('preorder'):\n",
    "        node2rootdist[node] = node.dist + node2rootdist[node.up]\n",
    "    return node2rootdist\n",
    "\n",
    "def closest_node(node, node2tips, root_distance):\n",
    "    \"\"\"Find the closest node.\"\"\"\n",
    "    \n",
    "    tips = []\n",
    "    distances = []\n",
    "    for tip in node2tips[node]:\n",
    "        distances.append(root_distance[tip]-root_distance[node])\n",
    "        tips.append(tip)\n",
    "        #     index = np.argmin([root_distance[tip]-root_distance[node] for tip in node2tips[node]])\n",
    "    index = np.argmin(distances)\n",
    "    return tips[index]\n",
    "\n",
    "def collapse(tree, min_dist,AllrecordInfo):\n",
    "    # cache the tip content of each node to reduce the number of times the tree is traversed\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    node2tips = tree.get_cached_content()\n",
    "    root_distance = cache_distances(tree)\n",
    "\n",
    "    for node in tree.get_descendants('preorder'):\n",
    "        if not node.is_leaf():\n",
    "            avg_distance_to_tips = mean([root_distance[tip]-root_distance[node]\n",
    "                                         for tip in node2tips[node]])\n",
    "            print(avg_distance_to_tips)\n",
    "            if avg_distance_to_tips < min_dist:\n",
    "                # do whatever, ete support node annotation, deletion, labeling, etc.\n",
    "\n",
    "                # rename\n",
    "                #                node.name += ' COLLAPSED avg_d:%g {%s}' %(avg_distance_to_tips,\n",
    "                #                                                 ','.join([tip.name for tip in node2tips[node]]))\n",
    "                #node.name += '{%s}' %(list(node2tips[node])[-1].name)\n",
    "                #node.name = 'avg_d:%g' %(avg_distance_to_tips)\n",
    "                # label\n",
    "            \n",
    "                closest_name = closest_node(node, node2tips, root_distance).name\n",
    "                node.host = AllrecordInfo.seq_infos[closest_name].subtype\n",
    "                node.name = '%s (%g)' %(closest_name,avg_distance_to_tips)\n",
    "                \n",
    "            \n",
    "                node.add_features(collapsed=True)\n",
    "\n",
    "                # set drawing attribute so they look collapsed when displayed with tree.show()\n",
    "                node.img_style['draw_descendants'] = False\n",
    "\n",
    "    return tree\n",
    "\n",
    "ltree_collapsed = collapse(\n",
    "    labelled_tree, \n",
    "    min_dist=4, \n",
    "    AllrecordInfo=ALLinfoHA)\n",
    "\n",
    "prune_nodes(ltree_collapsed)\n",
    "\n",
    "\n",
    "# COLBAT='DarkRed'\n",
    "# COLRAT='SteelBlue'\n",
    "COLHUMAN='DarkGreen'\n",
    "COLCOVID='DarkRed'\n",
    "COLBAT='Red'\n",
    "COLRAT='Blue'\n",
    "COLCAMEL='Purple'\n",
    "COLGAME='Red'\n",
    "COLCATTLE='Yellow'\n",
    "# COLHUMAN='Black'\n",
    "FS=50\n",
    "PW=10\n",
    "\n",
    "\n",
    "\n",
    "def nodeAttribConstruct(color, node):\n",
    "    N = AttrFace(\n",
    "        \"name\", fsize=FS, \n",
    "        text_prefix=\" \",penwidth=PW,ftype='Arial',\n",
    "        fgcolor=color,fstyle='bold')\n",
    "    faces.add_face_to_node(N, node, 1, position=\"branch-right\")\n",
    "    return N\n",
    "\n",
    "def layout(node):\n",
    "    if node.is_leaf():\n",
    "        if  node.host == 'H1N1':\n",
    "            N = nodeAttribConstruct(COLBAT,node)\n",
    "        elif node.host == 'H3N2':\n",
    "            N = nodeAttribConstruct(COLRAT,node)\n",
    "        elif node.host == 'H7N9':\n",
    "            N = nodeAttribConstruct(COLHUMAN,node)\n",
    "        elif node.host == 'H1N2':\n",
    "            N = nodeAttribConstruct(COLCATTLE,node)\n",
    "        elif node.host == 'game':\n",
    "            N = nodeAttribConstruct(COLGAME,node)\n",
    "        elif node.host == 'camel':\n",
    "            N = nodeAttribConstruct(COLCAMEL,node)\n",
    "        else:\n",
    "            N = nodeAttribConstruct(COLGAME,node)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "def render_tree(tree, outfile):# all_seq_data, display_type='nearest_host'):\n",
    "    \"\"\"Render the tree inside the file to a circular \n",
    "    phylogenetic tree.\n",
    "    \n",
    "    NOTE: outfile should be in .pdf for best visuals\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    #tree = Tree(nwfile,format=1)\n",
    "\n",
    "    ts = TreeStyle()\n",
    "    ns = NodeStyle()\n",
    "    ts.show_leaf_name = False\n",
    "    #ts.rotation = 90\n",
    "    ts.mode = \"r\"\n",
    "    #ts.arc_start = -360 # 0 degrees = 3 o'clock\n",
    "    #ts.arc_span = 360\n",
    "    ts.scale=4\n",
    "    ts.show_scale=False\n",
    "    ts.branch_vertical_margin = .5 # 10 pixels between adjacent branches\n",
    "    # ts.show_branch_length=True\n",
    "    #ts.min_leaf_separation=10\n",
    "    #ts.optimal_scale_level='full'\n",
    "    #ts.branch_vertical_margin=0\n",
    "    \n",
    "    ns.hz_line_width=2\n",
    "    ns.vt_line_width=1\n",
    "    #ts.layout_fn = layout\n",
    "    ns[\"vt_line_width\"] = 16\n",
    "    ns[\"hz_line_width\"] = 16\n",
    "    #     ns['fsize'] = 20\n",
    "    for n in tree.traverse():\n",
    "        n.set_style(ns)\n",
    "        \n",
    "    #all_accessions = all_seq_data['accessions'].values\n",
    "    for n in tree:\n",
    "        ts.layout_fn = layout\n",
    "\n",
    "        \n",
    "    tree.set_style(ns)\n",
    "    #tree.set_style(ts)\n",
    "    \n",
    "    #t.show()\n",
    "    tree.render(\n",
    "        outfile, \n",
    "        dpi=300, \n",
    "        h=500,\n",
    "        tree_style=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_tree(\n",
    "    ltree_collapsed, './riskyphylo6pt2.pdf')\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
