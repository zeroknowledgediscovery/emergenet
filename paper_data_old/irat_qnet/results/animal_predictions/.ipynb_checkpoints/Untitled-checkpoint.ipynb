{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "class SeqInfo(object):\n",
    "    \"\"\"Holds information regarding the sequence.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, seq, \n",
    "                 protein,\n",
    "                 accession,\n",
    "                 name=None,\n",
    "                 subtype=None,\n",
    "                 host=None, \n",
    "                 date=None, \n",
    "                 erisk=None,\n",
    "                 irisk=None,\n",
    "                 risk_flag=None,\n",
    "                 country=None):\n",
    "        self.name = name\n",
    "        self.protein=protein\n",
    "        self.subtype=subtype        \n",
    "        self.seq = seq\n",
    "        self.accession = accession \n",
    "        self.host = host\n",
    "        self.date = date\n",
    "        self.erisk = erisk\n",
    "        self.irisk = irisk\n",
    "        self.risk_flag = risk_flag\n",
    "        self.country = country\n",
    "        \n",
    "class MultipleSeqInfo(object):\n",
    "    \"\"\"Holds information regarding the sequences in the records.\n",
    "    \n",
    "    Args:\n",
    "        records (list): list of records parsed from NCBI\n",
    "        cov19_accessions (list): of accessions corresponding to cov19\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dataframe,\n",
    "                 accessionname,\n",
    "                 proteinname,\n",
    "                 risk_threshold=6.25):\n",
    "        \n",
    "        self.seq_infos = {}\n",
    "        self.risk_threshold = risk_threshold\n",
    "        for i in np.arange(dataframe.index.size):\n",
    "            record=dataframe.iloc[i,:]\n",
    "            seqinfo = SeqInfo(\n",
    "                name=record.id,\n",
    "                seq=record[proteinname], \n",
    "                protein=proteinname,\n",
    "                accession=record[accessionname],\n",
    "                subtype=record.subtype,\n",
    "                erisk=record.predicted_emergence_score,\n",
    "                irisk=record.predicted_impact_score,\n",
    "                risk_flag = record.predicted_emergence_score > self.risk_threshold,\n",
    "                host=None,\n",
    "                date=None,\n",
    "                country=None)\n",
    "            #print(record.predicted_emergence_score > self.risk_threshold)\n",
    "            self.seq_infos[seqinfo.accession] = seqinfo\n",
    "        \n",
    "    \n",
    "    def compute_L_diatance_matrix(self):\n",
    "        highriskseq = pd.DataFrame.from_dict({key:val.seq \n",
    "                                              for (key,val) in self.seq_infos.items() \n",
    "                                              if val.risk_flag},orient='index',columns=['seq'])\n",
    "        num=highriskseq.index.size\n",
    "        d=np.zeros([num,num])\n",
    "        for i in np.arange(num):\n",
    "            for j in np.arange(num):\n",
    "                if i > j:\n",
    "                    d[i,j] = Levenshtein.distance(highriskseq.seq.values[i],\n",
    "                                                  highriskseq.seq.values[j])\n",
    "        ds=pd.DataFrame(d)        \n",
    "        ds=(ds+ds.transpose())\n",
    "        ds.columns=highriskseq.index.values\n",
    "        self.highriskdistancematrix=ds.copy()\n",
    "        return ds\n",
    "        \n",
    "    \n",
    "    def accessions_to_subtype(self, accessions):\n",
    "        \"\"\"Create a dictionary mapping the accession to the host.\n",
    "        \"\"\"\n",
    "        \n",
    "        subtypes = []\n",
    "        \n",
    "        for accession in accessions:\n",
    "            seqinfo = self.seq_infos[accession]\n",
    "            subtypes.append(seqinfo.subtype)\n",
    "            \n",
    "        return subtypes\n",
    "\n",
    "    def accessions_to_host(self, accessions):\n",
    "        \"\"\"Create a dictionary mapping the accession to the host.\n",
    "        \"\"\"\n",
    "        \n",
    "        hosts = []\n",
    "        \n",
    "        for accession in accessions:\n",
    "            seqinfo = self.seq_infos[accession]\n",
    "            hosts.append(seqinfo.host)\n",
    "            \n",
    "        return hosts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H1N1    190\n",
       "H3N2     94\n",
       "H7N9      1\n",
       "Name: subtype, dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=10000\n",
    "df=pd.read_csv('./combined_results.csv',index_col=0)\n",
    "df1=df[['subtype','predicted_impact_score', 'predicted_emergence_score', 'ha', 'na']]\n",
    "df1=df1.sort_values('predicted_emergence_score',ascending=False).head(N)\n",
    "df1=df1[df1.predicted_emergence_score>6.2]\n",
    "df1.subtype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLinfoHA=MultipleSeqInfo(df.reset_index(),'ha_accession','ha',risk_threshold=6.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ALLinfoHA.compute_L_diatance_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (80) does not match length of index (285)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6820/680415471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subtype'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4485\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4486\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \"\"\"\n\u001b[0;32m-> 3784\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m         if (\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (80) does not match length of index (285)"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "cls = DBSCAN(metric='precomputed').fit(ds)\n",
    "cls.labels_\n",
    "pd.set_option('display.max_rows', None)\n",
    "df1.assign(cls=cls.labels_)[['subtype','cls']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "dss=(1/ds).replace(np.inf,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (80) does not match length of index (285)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6820/2481300623.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maffinity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'precomputed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subtype'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   4484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4485\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4486\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4487\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \"\"\"\n\u001b[0;32m-> 3784\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m         if (\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (80) does not match length of index (285)"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "cls = SpectralClustering(n_clusters=10,affinity='precomputed').fit(dss)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df1.assign(cls=cls.labels_)[['subtype','cls']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta(seqs, fasta_file, wrap=80):\n",
    "    \"\"\"Write sequences to a fasta file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seqs : dict[seq_id] -> seq\n",
    "        Sequences indexed by sequence id.\n",
    "    fasta_file : str\n",
    "        Path to write the sequences to.\n",
    "    wrap: int\n",
    "        Number of AA/NT before the line is wrapped.\n",
    "    \"\"\"\n",
    "    with open(fasta_file, 'w') as f:\n",
    "        for gid, gseq in seqs.items():\n",
    "            f.write('>{}\\n'.format(gid))\n",
    "            for i in range(0, len(gseq), wrap):\n",
    "                f.write('{}\\n'.format(gseq[i:i + wrap])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsn=df1.ha.to_json()\n",
    "import json    # or `import simplejson as json` if on Python < 2.6\n",
    "obj = json.loads(jsn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_fasta(obj,'ha.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Phylo import TreeConstruction\n",
    "from Bio import Phylo\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "#from Bio.Alphabet import generic_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dm(file_, upper_diag=True):\n",
    "    \"\"\"Load the distance matrix. \n",
    "    \n",
    "    Also, do some preprocessing. \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_)\n",
    "    #df.set_index('Unnamed: 0', inplace=True)\n",
    "    #assert np.all(df.columns == df.index)\n",
    "    \n",
    "    # drop duplicate columns after reading csv\n",
    "    #df = df.loc[:, ~df.columns.str.replace(\"(\\.\\d+)$\", \"\").duplicated()]\n",
    "    \n",
    "    if upper_diag:\n",
    "        df = df + df.T\n",
    "    return df\n",
    "\n",
    "def save_tree(tree, file_name, save_type='xml'):\n",
    "    \"\"\"Saved the created phylogenetic tree.\"\"\"\n",
    "    \n",
    "    if save_type == 'pickle':\n",
    "        graph = Phylo.to_networkx(tree)\n",
    "        save_pickled(graph, file_name)\n",
    "    elif save_type == 'xml':\n",
    "        Phylo.write(tree, file_name, 'phyloxml')\n",
    "    else:\n",
    "        raise ValueError('Not a correct save type.')\n",
    "        \n",
    "def pandas_dm_to_biopython_dm(dm):\n",
    "    \"\"\"Convert the pandas distance matrix to the biopython distance matrix.\n",
    "    \n",
    "    Returns:\n",
    "        biopython distance matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    accessions = dm.columns\n",
    "    bio_dm = []\n",
    "    for i, accession in enumerate(accessions):\n",
    "        bio_dm.append(list(dm.iloc[i, :i+1].values))\n",
    "        \n",
    "    bio_dm = TreeConstruction._DistanceMatrix(\n",
    "        list(dm.columns), \n",
    "        bio_dm)\n",
    "    \n",
    "    return bio_dm\n",
    "\n",
    "def distance_matrix_to_phylo_tree(dm, outfile=None):\n",
    "    \"\"\"Create a phylogenetic tree from the distance matrix.\"\"\"\n",
    "    \n",
    "    dm = pandas_dm_to_biopython_dm(dm)\n",
    "    \n",
    "    treeConstructor = TreeConstruction.DistanceTreeConstructor()\n",
    "    tree = treeConstructor.nj(dm)\n",
    "    \n",
    "    if outfile is not None:\n",
    "        save_tree(tree, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EPI1766616', 'EPI1766712', 'EPI1766716', 'EPI1768609', 'EPI1769150',\n",
       "       'EPI1773255', 'EPI1775888', 'EPI1775900', 'EPI1775916', 'EPI1775980',\n",
       "       'EPI1777715', 'EPI1778580', 'EPI1778590', 'EPI1778720', 'EPI1778732',\n",
       "       'EPI1779438', 'EPI1779454', 'EPI1779474', 'EPI1780098', 'EPI1780120',\n",
       "       'EPI1780243', 'EPI1780419', 'EPI1780479', 'EPI1817876', 'EPI1818121',\n",
       "       'EPI1818149', 'EPI1818373', 'EPI1830281', 'EPI1832641', 'EPI1832784',\n",
       "       'EPI1832788', 'EPI1832802', 'EPI1832818', 'EPI1833072', 'EPI1833157',\n",
       "       'EPI1907229', 'EPI1907263', 'EPI1907387', 'EPI1908086', 'EPI1908102',\n",
       "       'EPI1908134', 'EPI1908176', 'EPI1908453', 'EPI1908513', 'EPI1908547',\n",
       "       'EPI1908557', 'EPI1908559', 'EPI1908782', 'EPI1908789', 'EPI1908812',\n",
       "       'EPI1909019', 'EPI1909021', 'EPI1909033', 'EPI1909037', 'EPI1910432',\n",
       "       'EPI1910743', 'EPI1910821', 'EPI1910887', 'EPI1910943', 'EPI1911033',\n",
       "       'EPI1911241', 'EPI1932076', 'EPI1975300', 'EPI1975316', 'EPI1975364',\n",
       "       'EPI1975820', 'EPI1976249', 'EPI1976602', 'EPI2146879', 'EPI2153378',\n",
       "       'EPI2158738', 'EPI1766723', 'EPI1769192', 'EPI1775924', 'EPI1817170',\n",
       "       'EPI1818137', 'EPI1930925', 'EPI2148192', 'EPI2148218', 'EPI2026200'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ds.columns=[x.replace('/','_') for x in df1.index.values]\n",
    "ds.to_csv('dm.csv',index=None)\n",
    "ds.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSTRUCT_PHYLO=True\n",
    "PHYLO_TREE_DIR='./'\n",
    "OUTPUT_DIR='./'\n",
    "\n",
    "if CONSTRUCT_PHYLO:\n",
    "    ALL_dm_ldistance = load_dm(\n",
    "        OUTPUT_DIR + 'dm.csv', \n",
    "        upper_diag=False)\n",
    "#    ALL_dm_qdistance = load_dm(\n",
    "#        OUTPUT_DIR + 'ALL_qdistance_dm.csv', \n",
    "#        upper_diag=True)\n",
    "    \n",
    "    distance_matrix_to_phylo_tree(\n",
    "        ALL_dm_ldistance, PHYLO_TREE_DIR + 'ldistanceh1n1.xml')\n",
    "    \n",
    "#    distance_matrix_to_phylo_tree(\n",
    "#        ALL_dm_qdistance, PHYLO_TREE_DIR + 'qdistance.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree, TreeStyle\n",
    "from ete3 import Phyloxml\n",
    "from ete3 import AttrFace, faces, Tree, NodeStyle, TreeStyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickled(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f, encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ETE3 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_farthest_node(tree, sequence):\n",
    "    return (tree&sequence).get_farthest_node()\n",
    "\n",
    "def get_all_accessions_from_tree(tree):\n",
    "    return [leaf_node.name for leaf_node in tree.get_leaves()]\n",
    "\n",
    "def remove_certain_hosts_from_tree(tree, hosts):\n",
    "    \"\"\"Remove leaf nodes if the host of that leaf is in `hosts`\"\"\"\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    removed_accessions = []\n",
    "    for leaf_node in tree.get_leaves():\n",
    "        if leaf_node.host in hosts:\n",
    "            leaf_node.detach()\n",
    "            \n",
    "    return tree\n",
    "\n",
    "def set_midpoint_outgroup(tree):\n",
    "    tree.set_outgroup(tree.get_midpoint_outgroup())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Host To Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_to_name(name, specific_game_name=False):\n",
    "    \"\"\"Map the host name to some standard name\n",
    "    \n",
    "    categories:\n",
    "        mouse/rat\n",
    "        bat\n",
    "        cattle/cows/goat/calf/bovine/donkey/pigs/camel\n",
    "        humans\n",
    "        \n",
    "    Args:\n",
    "        name (str): name of the host\n",
    "        specific_game_name (bool): if we want a specific game name\n",
    "    \"\"\"\n",
    "    \n",
    "    name = name.lower()\n",
    "    orig_name = name\n",
    "    def names_in_host(orig_name, sub_names):\n",
    "        \"\"\"Check if any of the sub names are in the orig name\"\"\"\n",
    "        \n",
    "        for sub_name in sub_names:\n",
    "            if sub_name.lower() in orig_name:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    def names_is_host(orig_name, names):\n",
    "        \"\"\"Check if any of the sub names are in the orig name\"\"\"\n",
    "        \n",
    "        for name in names:\n",
    "            if name.lower() == orig_name:\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "    bat_subnames = [\n",
    "        'bat', 'Artibeus', 'Rhinolophus', 'Megaerops niphanae', 'Chiroptera', \n",
    "        'dupreanum', 'Pipistrellus', 'Rousettus leschenaultii', 'Pteronotus',\n",
    "        'Hipposideros', 'Tylonycteris pachypus', 'Pteropus', 'Myotis', 'Epomophorus',\n",
    "        'Tadarida', 'Cynopterus', 'Epomops', 'Nycteris', 'Scotophilus', 'Rhinilophus',\n",
    "        'Eptesicus', 'Neoromicia', 'Rousettus', 'Rhinopoma', 'Macroglossus', 'Megaloglossus',\n",
    "        'Dyacopterus', 'Aselliscus', 'Carollia perspicillata', 'Chaerephon plicata',\n",
    "        'Vespertilio', 'Miniopterus', 'Triaenops', 'Glossophaginae', 'Hypsugo',\n",
    "        'Ptenochirus', 'Ia io', 'Eumops', 'Nyctalus noctula', 'Nyctinomops', \n",
    "        'Dobsonia moluccensis', 'Mops condyluru', 'Eidolon helvum', 'Taphozous perforatus']\n",
    "    \n",
    "    cattle = [\n",
    "        'cow', 'calf', 'Bovine', 'taurus', 'cattle', \n",
    "        'Bubalus', 'Bovidae', 'wisent', 'buffalo', 'yak']\n",
    "    camels = ['dromedary', 'Camel']\n",
    "    pigs = ['pig', 'porcine', 'swine', 'Sus scrofa']\n",
    "    canines = ['canine', 'dog', 'canis'] # canines (i.e. wolves, foxes, dogs)\n",
    "    birds = [\n",
    "        'Asio clamator', 'Columba livia', 'Megascops', 'Ara ararauna', \n",
    "        'Pyroderus', 'Coragyps atratus', 'Pyroderus scutatus', 'Rupornis',\n",
    "         'Pitangus sulphuratus']\n",
    "    horses = ['equus', 'Equine', 'horse',]\n",
    "    alpaca = ['Vicugna', 'alpaca', 'lama']\n",
    "    antelopes = ['antelope', 'nyala', 'waterbuck', 'sitatunga']\n",
    "    chimps = ['Pan troglodytes verus', 'Chlorocebus aethiops']\n",
    "    \n",
    "    game_subnames = [\n",
    "        'civet', # cat \n",
    "        'cuniculus', # rabbit\n",
    "        'tahr', 'goat', # goat\n",
    "        'donkey', 'deer', 'giraffe', 'Erinaceus', 'Manis javanica',\n",
    "        'Myodes glareolus', # mole\n",
    "        'Nycticebus pygmaeus', \n",
    "        'Cavia_porcellus', # guiness pig \n",
    "    ]\n",
    "    \n",
    "    game_subnames = game_subnames + cattle + camels + pigs + canines + birds + horses\\\n",
    "        + alpaca + antelopes + chimps\n",
    "    \n",
    "    rat_subnames = [\n",
    "        'Apodemus', 'mouse', 'Murine', 'rodent', 'mus',\n",
    "        'Crocidura', 'Niviventer', 'Mastomys', 'Rattus']\n",
    "    rat_names = ['rat']\n",
    "    human_subnames = ['Homo sapiens', 'human']\n",
    "    \n",
    "    coronavirus_subnames = ['coronavirus']\n",
    "    \n",
    "    other_subnames = ['genomic DNA']\n",
    "    \n",
    "    if names_in_host(name, bat_subnames):\n",
    "        name = 'bat'\n",
    "        \n",
    "    elif names_in_host(name, game_subnames):\n",
    "        name = 'game'\n",
    "    \n",
    "    elif names_in_host(name, rat_subnames) or names_is_host(name, rat_names):\n",
    "        name = 'rat'\n",
    "    \n",
    "    elif names_in_host(name, human_subnames):\n",
    "        name = 'human'\n",
    "        \n",
    "    elif names_in_host(name, coronavirus_subnames):\n",
    "        # TODO: may need to check this if the data changes\n",
    "        name = 'human'\n",
    "        \n",
    "    elif names_in_host(name, other_subnames):\n",
    "        name = 'other'\n",
    "    else:\n",
    "        raise ValueError('Not a name that has been considered: {}'.format(name))\n",
    "        \n",
    "    if specific_game_name and name == 'game':\n",
    "#         print orig_name\n",
    "        if names_in_host(orig_name, cattle):\n",
    "            name = 'cattle'\n",
    "        elif names_in_host(orig_name, camels):\n",
    "            name = 'camel'\n",
    "        elif names_in_host(orig_name, pigs):\n",
    "            name = 'pig'\n",
    "        elif names_in_host(orig_name, canines):\n",
    "            name = 'canine'\n",
    "        elif names_in_host(orig_name, birds):\n",
    "            name = 'bird'\n",
    "        elif names_in_host(orig_name, horses):\n",
    "            name = 'horse'\n",
    "        elif names_in_host(orig_name, chimps):\n",
    "            name = 'chimp'\n",
    "            \n",
    "            \n",
    "    # cattle + camels + pigs + canines + birds + horses + alpaca + antelopes + chimps\n",
    "    # cattle, camel, pig, canine,  bird, horse, alpaca, antelope, chimp\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tree(filename, type_='phyloxml'):\n",
    "    \"\"\"Load saved phylogenetic tree.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type_ == 'phyloxml':\n",
    "        project = Phyloxml()\n",
    "        project.build_from_file(filename)\n",
    "\n",
    "        for tree in project.get_phylogeny():\n",
    "            break\n",
    "\n",
    "        t=tree\n",
    "        \n",
    "    elif type_ == 'newick':\n",
    "        t = Tree(filename, format=1)\n",
    "    else:\n",
    "        raise ValueError('Not a correct type.')\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHYLO_DIR='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phylo.convert(\n",
    "    PHYLO_DIR + 'ldistanceh1n1.xml','phyloxml',\n",
    "    PHYLO_DIR + 'ldistance.nhx','newick')\n",
    "\n",
    "ltree = load_tree(\n",
    "    PHYLO_DIR + 'ldistance.nhx',\n",
    "    type_='newick')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_nodes(\n",
    "    tree, \n",
    "    recordinfo):\n",
    "    \"\"\"Label the nodes of the tree.\n",
    "    \n",
    "    We label nodes on whether:\n",
    "        it is covid19\n",
    "    \"\"\"\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "   \n",
    "    for node in tree:\n",
    "        name = node.name      \n",
    "        node.host = recordinfo.seq_infos[name].subtype\n",
    "        print(node.name,node.host)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPI1907263 H1N1\n",
      "EPI2158738 H1N1\n",
      "EPI1830281 H1N1\n",
      "EPI1778720 H1N1\n",
      "EPI1777715 H1N1\n",
      "EPI1975300 H1N1\n",
      "EPI1908176 H1N1\n",
      "EPI1908559 H1N1\n",
      "EPI1908557 H1N1\n",
      "EPI1908547 H1N1\n",
      "EPI1833072 H1N1\n",
      "EPI1832802 H1N1\n",
      "EPI1775980 H1N1\n",
      "EPI1833157 H1N1\n",
      "EPI1908812 H1N1\n",
      "EPI1908102 H1N1\n",
      "EPI1832788 H1N1\n",
      "EPI1832641 H1N1\n",
      "EPI1775888 H1N1\n",
      "EPI1976602 H1N1\n",
      "EPI1976249 H1N1\n",
      "EPI1778580 H1N1\n",
      "EPI1768609 H1N1\n",
      "EPI1766616 H1N1\n",
      "EPI1910821 H1N1\n",
      "EPI1909021 H1N1\n",
      "EPI1910887 H1N1\n",
      "EPI1909019 H1N1\n",
      "EPI1908782 H1N1\n",
      "EPI1908789 H1N1\n",
      "EPI1832784 H1N1\n",
      "EPI2153378 H1N1\n",
      "EPI1832818 H1N1\n",
      "EPI1911033 H1N1\n",
      "EPI2026200 H7N9\n",
      "EPI1769192 H3N2\n",
      "EPI1930925 H3N2\n",
      "EPI2148218 H3N2\n",
      "EPI2148192 H3N2\n",
      "EPI1817170 H3N2\n",
      "EPI1775924 H3N2\n",
      "EPI1818137 H3N2\n",
      "EPI1766723 H3N2\n",
      "EPI1817876 H1N1\n",
      "EPI1769150 H1N1\n",
      "EPI1975820 H1N1\n",
      "EPI1975364 H1N1\n",
      "EPI1975316 H1N1\n",
      "EPI1910743 H1N1\n",
      "EPI2146879 H1N1\n",
      "EPI1910432 H1N1\n",
      "EPI1909033 H1N1\n",
      "EPI1908134 H1N1\n",
      "EPI1907387 H1N1\n",
      "EPI1932076 H1N1\n",
      "EPI1911241 H1N1\n",
      "EPI1910943 H1N1\n",
      "EPI1775916 H1N1\n",
      "EPI1908086 H1N1\n",
      "EPI1780479 H1N1\n",
      "EPI1818121 H1N1\n",
      "EPI1780419 H1N1\n",
      "EPI1780098 H1N1\n",
      "EPI1780243 H1N1\n",
      "EPI1818373 H1N1\n",
      "EPI1778732 H1N1\n",
      "EPI1773255 H1N1\n",
      "EPI1775900 H1N1\n",
      "EPI1909037 H1N1\n",
      "EPI1908513 H1N1\n",
      "EPI1908453 H1N1\n",
      "EPI1766712 H1N1\n",
      "EPI1766716 H1N1\n",
      "EPI1778590 H1N1\n",
      "EPI1779438 H1N1\n",
      "EPI1779454 H1N1\n",
      "EPI1779474 H1N1\n",
      "EPI1780120 H1N1\n",
      "EPI1818149 H1N1\n",
      "EPI1907229 H1N1\n"
     ]
    }
   ],
   "source": [
    "labelled_tree=label_nodes(\n",
    "    ltree, ALLinfoHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPI1907263 H1N1\n",
      "EPI2158738 H1N1\n",
      "EPI1830281 H1N1\n",
      "EPI1778720 H1N1\n",
      "EPI1777715 H1N1\n",
      "EPI1975300 H1N1\n",
      "EPI1908176 H1N1\n",
      "EPI1908559 H1N1\n",
      "EPI1908557 H1N1\n",
      "EPI1908547 H1N1\n",
      "EPI1833072 H1N1\n",
      "EPI1832802 H1N1\n",
      "EPI1775980 H1N1\n",
      "EPI1833157 H1N1\n",
      "EPI1908812 H1N1\n",
      "EPI1908102 H1N1\n",
      "EPI1832788 H1N1\n",
      "EPI1832641 H1N1\n",
      "EPI1775888 H1N1\n",
      "EPI1976602 H1N1\n",
      "EPI1976249 H1N1\n",
      "EPI1778580 H1N1\n",
      "EPI1768609 H1N1\n",
      "EPI1766616 H1N1\n",
      "EPI1910821 H1N1\n",
      "EPI1909021 H1N1\n",
      "EPI1910887 H1N1\n",
      "EPI1909019 H1N1\n",
      "EPI1908782 H1N1\n",
      "EPI1908789 H1N1\n",
      "EPI1832784 H1N1\n",
      "EPI2153378 H1N1\n",
      "EPI1832818 H1N1\n",
      "EPI1911033 H1N1\n",
      "EPI2026200 H7N9\n",
      "EPI1769192 H3N2\n",
      "EPI1930925 H3N2\n",
      "EPI2148218 H3N2\n",
      "EPI2148192 H3N2\n",
      "EPI1817170 H3N2\n",
      "EPI1775924 H3N2\n",
      "EPI1818137 H3N2\n",
      "EPI1766723 H3N2\n",
      "EPI1817876 H1N1\n",
      "EPI1769150 H1N1\n",
      "EPI1975820 H1N1\n",
      "EPI1975364 H1N1\n",
      "EPI1975316 H1N1\n",
      "EPI1910743 H1N1\n",
      "EPI2146879 H1N1\n",
      "EPI1910432 H1N1\n",
      "EPI1909033 H1N1\n",
      "EPI1908134 H1N1\n",
      "EPI1907387 H1N1\n",
      "EPI1932076 H1N1\n",
      "EPI1911241 H1N1\n",
      "EPI1910943 H1N1\n",
      "EPI1775916 H1N1\n",
      "EPI1908086 H1N1\n",
      "EPI1780479 H1N1\n",
      "EPI1818121 H1N1\n",
      "EPI1780419 H1N1\n",
      "EPI1780098 H1N1\n",
      "EPI1780243 H1N1\n",
      "EPI1818373 H1N1\n",
      "EPI1778732 H1N1\n",
      "EPI1773255 H1N1\n",
      "EPI1775900 H1N1\n",
      "EPI1909037 H1N1\n",
      "EPI1908513 H1N1\n",
      "EPI1908453 H1N1\n",
      "EPI1766712 H1N1\n",
      "EPI1766716 H1N1\n",
      "EPI1778590 H1N1\n",
      "EPI1779438 H1N1\n",
      "EPI1779454 H1N1\n",
      "EPI1779474 H1N1\n",
      "EPI1780120 H1N1\n",
      "EPI1818149 H1N1\n",
      "EPI1907229 H1N1\n"
     ]
    }
   ],
   "source": [
    "for node in labelled_tree:\n",
    "    print(node.name,node.host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_nodes(t):\n",
    "    # collapsed nodes are labeled, so you locate them and prune them\n",
    "    for n in t.search_nodes(collapsed=True):\n",
    "        for ch in n.get_children():\n",
    "            ch.detach()\n",
    "            \n",
    "            \n",
    "def mean(array):\n",
    "    return sum(array)/float(len(array))\n",
    "\n",
    "def cache_distances(tree):\n",
    "    ''' precalculate distances of all nodes to the root''' \n",
    "    node2rootdist = {tree:0}\n",
    "    for node in tree.iter_descendants('preorder'):\n",
    "        node2rootdist[node] = node.dist + node2rootdist[node.up]\n",
    "    return node2rootdist\n",
    "\n",
    "def closest_node(node, node2tips, root_distance):\n",
    "    \"\"\"Find the closest node.\"\"\"\n",
    "    \n",
    "    tips = []\n",
    "    distances = []\n",
    "    for tip in node2tips[node]:\n",
    "        distances.append(root_distance[tip]-root_distance[node])\n",
    "        tips.append(tip)\n",
    "#     index = np.argmin([root_distance[tip]-root_distance[node] for tip in node2tips[node]])\n",
    "    index = np.argmin(distances)\n",
    "    return tips[index]\n",
    "\n",
    "def collapse(tree, min_dist,AllrecordInfo):\n",
    "    # cache the tip content of each node to reduce the number of times the tree is traversed\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    node2tips = tree.get_cached_content()\n",
    "    root_distance = cache_distances(tree)\n",
    "\n",
    "    for node in tree.get_descendants('preorder'):\n",
    "        if not node.is_leaf():\n",
    "            avg_distance_to_tips = mean([root_distance[tip]-root_distance[node]\n",
    "                                         for tip in node2tips[node]])\n",
    "\n",
    "            if avg_distance_to_tips < min_dist:\n",
    "                # do whatever, ete support node annotation, deletion, labeling, etc.\n",
    "\n",
    "                # rename\n",
    "#                node.name += ' COLLAPSED avg_d:%g {%s}' %(avg_distance_to_tips,\n",
    "#                                                 ','.join([tip.name for tip in node2tips[node]]))\n",
    "                #node.name += '{%s}' %(list(node2tips[node])[-1].name)\n",
    "                #node.name = 'avg_d:%g' %(avg_distance_to_tips)\n",
    "                # label\n",
    "            \n",
    "                closest_name = closest_node(node, node2tips, root_distance).name\n",
    "                node.host = AllrecordInfo.seq_infos[closest_name].subtype\n",
    "                node.name = '%s (%g)' %(closest_name,avg_distance_to_tips)\n",
    "                \n",
    "            \n",
    "                node.add_features(collapsed=True)\n",
    "\n",
    "                # set drawing attribute so they look collapsed when displayed with tree.show()\n",
    "                node.img_style['draw_descendants'] = False\n",
    "\n",
    "    return tree\n",
    "                # etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltree_collapsed = collapse(\n",
    "    labelled_tree, \n",
    "    min_dist=1, \n",
    "    AllrecordInfo=ALLinfoHA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLBAT='DarkRed'\n",
    "# COLRAT='SteelBlue'\n",
    "COLHUMAN='DarkGreen'\n",
    "COLCOVID='DarkRed'\n",
    "COLBAT='Red'\n",
    "COLRAT='Blue'\n",
    "COLCAMEL='Purple'\n",
    "COLGAME='Red'\n",
    "COLCATTLE='Yellow'\n",
    "# COLHUMAN='Black'\n",
    "FS=40\n",
    "PW=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree node 'Inner78' (0x7f0b7140859)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltree_collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree node 'Inner78' (0x7f0a1a187b5)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodeAttribConstruct(color, node):\n",
    "    N = AttrFace(\n",
    "        \"name\", fsize=FS, \n",
    "        text_prefix=\" \",penwidth=PW,ftype='Arial',\n",
    "        fgcolor=color,fstyle='bold')\n",
    "    faces.add_face_to_node(N, node, 1, position=\"branch-right\")\n",
    "    return N\n",
    "\n",
    "def layout(node):\n",
    "    if node.is_leaf():\n",
    "        if  node.host == 'H1N1':\n",
    "            N = nodeAttribConstruct(COLBAT,node)\n",
    "        elif node.host == 'H3N2':\n",
    "            N = nodeAttribConstruct(COLRAT,node)\n",
    "        elif node.host == 'H7N9':\n",
    "            N = nodeAttribConstruct(COLHUMAN,node)\n",
    "        elif node.host == 'H1N2':\n",
    "            N = nodeAttribConstruct(COLCATTLE,node)\n",
    "        elif node.host == 'game':\n",
    "            N = nodeAttribConstruct(COLGAME,node)\n",
    "        elif node.host == 'camel':\n",
    "            N = nodeAttribConstruct(COLCAMEL,node)\n",
    "        else:\n",
    "            N = nodeAttribConstruct(COLGAME,node)\n",
    "            \n",
    "            \n",
    "def render_tree(tree, outfile):# all_seq_data, display_type='nearest_host'):\n",
    "    \"\"\"Render the tree inside the file to a circular \n",
    "    phylogenetic tree.\n",
    "    \n",
    "    NOTE: outfile should be in .pdf for best visuals\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    #tree = Tree(nwfile,format=1)\n",
    "\n",
    "    ts = TreeStyle()\n",
    "    ns = NodeStyle()\n",
    "    ts.show_leaf_name = True\n",
    "    #ts.rotation = 90\n",
    "    ts.mode = \"r\"\n",
    "    #ts.arc_start = -360 # 0 degrees = 3 o'clock\n",
    "    #ts.arc_span = 360\n",
    "    ts.scale=7500\n",
    "    ts.show_scale=True\n",
    "    # ts.show_branch_length=True\n",
    "    #ts.min_leaf_separation=10\n",
    "    #ts.optimal_scale_level='full'\n",
    "    #ts.branch_vertical_margin=0\n",
    "    \n",
    "    ns.hz_line_width=2\n",
    "    ns.vt_line_width=1\n",
    "    #ts.layout_fn = layout\n",
    "    ns[\"vt_line_width\"] = 2\n",
    "    ns[\"hz_line_width\"] = 1\n",
    "#     ns['fsize'] = 20\n",
    "    for n in tree.traverse():\n",
    "        n.set_style(ns)\n",
    "     \n",
    "    #all_accessions = all_seq_data['accessions'].values\n",
    "    for n in tree:\n",
    "        ts.layout_fn = layout\n",
    "\n",
    "        \n",
    "    tree.set_style(ns)\n",
    "    #tree.set_style(ts)\n",
    "    \n",
    "    #t.show()\n",
    "    tree.render(\n",
    "        outfile, \n",
    "        dpi=100, \n",
    "        h=1000,\n",
    "    tree_style=ts)\n",
    "# def layout(node):\n",
    "#     if node.is_leaf():\n",
    "#         if node.host == 'bat':\n",
    "#             N = AttrFace(\"name\", fsize=FS, text_prefix=\" \",penwidth=PW,ftype='Arial',fgcolor=COLBAT,fstyle='bold')\n",
    "#             faces.add_face_to_node(N, node, 1, position=\"branch-right\")\n",
    "#         elif node.host == 'rat':\n",
    "#             N = AttrFace(\"name\", fsize=FS, text_prefix=\" \",penwidth=PW,ftype='Arial',fgcolor=COLRAT,fstyle='bold')\n",
    "#             faces.add_face_to_node(N, node, 1, position=\"branch-right\")\n",
    "#         elif node.host == 'human':\n",
    "#             N = AttrFace(\"name\", fsize=FS, text_prefix=\" \",penwidth=PW,ftype='Arial',fgcolor=COLHUMAN)\n",
    "#             faces.add_face_to_node(N, node, 1, position=\"branch-right\")\n",
    "#         else:\n",
    "# #             print (node.host)\n",
    "#             N = AttrFace(\"name\", fsize=FS, text_prefix=\" \",penwidth=PW,ftype='Arial')\n",
    "#             faces.add_face_to_node(N, node, 1, position=\"branch-right\")\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_tree(\n",
    "    labelled_tree, './tmp.pdf')\n",
    "#     SAVE_PHYLO_DIR + 'Lcollapsed_farthest_from_earliest_covid_as_outgroup.pdf',\n",
    "#     SAVE_PHYLO_DIR + 'Lcollapsed_earliest_seq_as_outgroup.pdf',\n",
    "#    all_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_tree(\n",
    "    ltree_collapsed, './tmp.pdf')\n",
    "#     SAVE_PHYLO_DIR + 'Lcollapsed_farthest_from_earliest_covid_as_outgroup.pdf',\n",
    "#     SAVE_PHYLO_DIR + 'Lcollapsed_earliest_seq_as_outgroup.pdf',\n",
    "#    all_seq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for (key,val) in ddict.items()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
