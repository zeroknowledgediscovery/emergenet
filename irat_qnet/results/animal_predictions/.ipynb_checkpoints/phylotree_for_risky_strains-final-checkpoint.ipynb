{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "from tqdm import tqdm\n",
    "class SeqInfo(object):\n",
    "    \"\"\"Holds information regarding the sequence.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, seq, \n",
    "                 protein,\n",
    "                 accession,\n",
    "                 id=None,\n",
    "                 name=None,\n",
    "                 subtype=None,\n",
    "                 host=None, \n",
    "                 date=None, \n",
    "                 erisk=None,\n",
    "                 irisk=None,\n",
    "                 risk_flag=None,\n",
    "                 country=None):\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.protein=protein\n",
    "        self.subtype=subtype        \n",
    "        self.seq = seq\n",
    "        self.accession = accession \n",
    "        self.host = host\n",
    "        self.date = date\n",
    "        self.erisk = erisk\n",
    "        self.irisk = irisk\n",
    "        self.risk_flag = risk_flag\n",
    "        self.country = country\n",
    "        \n",
    "class MultipleSeqInfo(object):\n",
    "    \"\"\"Holds information regarding the sequences in the records.\n",
    "    \n",
    "    Args:\n",
    "        records (list): list of records parsed from NCBI\n",
    "        cov19_accessions (list): of accessions corresponding to cov19\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dataframe,\n",
    "                 accessionname,\n",
    "                 proteinname,\n",
    "                 risk_threshold=6.2):\n",
    "        \n",
    "        self.seq_infos = {}\n",
    "        self.risk_threshold = risk_threshold\n",
    "        for i in np.arange(dataframe.index.size):\n",
    "            record=dataframe.iloc[i,:]\n",
    "            seqinfo = SeqInfo(\n",
    "                name=record.id,\n",
    "                seq=record[proteinname], \n",
    "                protein=proteinname,\n",
    "                accession=record[accessionname],\n",
    "                subtype=record.subtype,\n",
    "                erisk=record.predicted_emergence_score,\n",
    "                irisk=record.predicted_impact_score,\n",
    "                risk_flag = record.predicted_emergence_score > self.risk_threshold,\n",
    "                host=None,\n",
    "                date=None,\n",
    "                country=None)\n",
    "            #print(record.predicted_emergence_score > self.risk_threshold)\n",
    "            self.seq_infos[seqinfo.accession] = seqinfo\n",
    "            \n",
    "    \n",
    "    def compute_L_diatance_matrix(self):\n",
    "        highriskseq = pd.DataFrame.from_dict({key:val.seq \n",
    "                                              for (key,val) in self.seq_infos.items() \n",
    "                                              if val.risk_flag},orient='index',columns=['seq'])\n",
    "        num=highriskseq.index.size\n",
    "        d=np.zeros([num,num])\n",
    "        for x in tqdm(np.arange(num*num)):\n",
    "            j=x//num\n",
    "            i=x-num*j\n",
    "            if i > j:\n",
    "                d[i,j] = Levenshtein.distance(highriskseq.seq.values[i],\n",
    "                                                  highriskseq.seq.values[j])\n",
    "        ds=pd.DataFrame(d)        \n",
    "        ds=(ds+ds.transpose())\n",
    "        ds.columns=highriskseq.index.values\n",
    "        self.highriskdistancematrix=ds.copy()\n",
    "        return ds\n",
    "    \n",
    "    \n",
    "    def accessions_to_subtype(self, accessions):\n",
    "        \"\"\"Create a dictionary mapping the accession to the host.\n",
    "        \"\"\"\n",
    "        \n",
    "        subtypes = []\n",
    "        for accession in accessions:\n",
    "            seqinfo = self.seq_infos[accession]\n",
    "            subtypes.append(seqinfo.subtype)\n",
    "            \n",
    "        return subtypes\n",
    "\n",
    "    def accessions_to_host(self, accessions):\n",
    "        \"\"\"Create a dictionary mapping the accession to the host.\n",
    "        \"\"\"\n",
    "        \n",
    "        hosts = []\n",
    "        for accession in accessions:\n",
    "            seqinfo = self.seq_infos[accession]\n",
    "            hosts.append(seqinfo.host)\n",
    "        return hosts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./combined_results.csv',index_col=0).reset_index()\n",
    "ALLinfoHA=MultipleSeqInfo(df.reset_index(),'ha_accession','ha',risk_threshold=6.054)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM=10\n",
    "for x in np.arange(((NUM*NUM)-NUM)//2):\n",
    "    j=x//NUM\n",
    "    i=x-NUM*j\n",
    "    #print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 2553604/2553604 [00:48<00:00, 53121.92it/s]\n"
     ]
    }
   ],
   "source": [
    "ds=ALLinfoHA.compute_L_diatance_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df.id.str.contains('chicken')].sort_values('predicted_emergence_score',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Phylo import TreeConstruction\n",
    "from Bio import Phylo\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "def load_dm(file_, upper_diag=True):\n",
    "    \"\"\"Load the distance matrix. \n",
    "    \n",
    "    Also, do some preprocessing. \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_)\n",
    "    #df.set_index('Unnamed: 0', inplace=True)\n",
    "    #assert np.all(df.columns == df.index)\n",
    "    \n",
    "    # drop duplicate columns after reading csv\n",
    "    #df = df.loc[:, ~df.columns.str.replace(\"(\\.\\d+)$\", \"\").duplicated()]\n",
    "    \n",
    "    if upper_diag:\n",
    "        df = df + df.T\n",
    "    return df\n",
    "\n",
    "def save_tree(tree, file_name, save_type='xml'):\n",
    "    \"\"\"Saved the created phylogenetic tree.\"\"\"\n",
    "    \n",
    "    if save_type == 'pickle':\n",
    "        graph = Phylo.to_networkx(tree)\n",
    "        save_pickled(graph, file_name)\n",
    "    elif save_type == 'xml':\n",
    "        Phylo.write(tree, file_name, 'phyloxml')\n",
    "    else:\n",
    "        raise ValueError('Not a correct save type.')\n",
    "    \n",
    "def pandas_dm_to_biopython_dm(dm):\n",
    "    \"\"\"Convert the pandas distance matrix to the biopython distance matrix.\n",
    "    \n",
    "    Returns:\n",
    "        biopython distance matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    accessions = dm.columns\n",
    "    bio_dm = []\n",
    "    for i, accession in enumerate(accessions):\n",
    "        bio_dm.append(list(dm.iloc[i, :i+1].values))\n",
    "        \n",
    "    bio_dm = TreeConstruction._DistanceMatrix(\n",
    "        list(dm.columns), \n",
    "        bio_dm)\n",
    "    \n",
    "    return bio_dm\n",
    "\n",
    "def distance_matrix_to_phylo_tree(dm, outfile=None):\n",
    "    \"\"\"Create a phylogenetic tree from the distance matrix.\"\"\"\n",
    "    \n",
    "    dm = pandas_dm_to_biopython_dm(dm)\n",
    "    \n",
    "    treeConstructor = TreeConstruction.DistanceTreeConstructor()\n",
    "    tree = treeConstructor.nj(dm)\n",
    "    \n",
    "    if outfile is not None:\n",
    "        save_tree(tree, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_csv('dmnew.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree, TreeStyle\n",
    "from ete3 import Phyloxml\n",
    "from ete3 import AttrFace, faces, Tree, NodeStyle, TreeStyle\n",
    "\n",
    "def load_pickled(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f, encoding='latin')\n",
    "\n",
    "\n",
    "def get_farthest_node(tree, sequence):\n",
    "    return (tree&sequence).get_farthest_node()\n",
    "\n",
    "def get_all_accessions_from_tree(tree):\n",
    "    return [leaf_node.name for leaf_node in tree.get_leaves()]\n",
    "\n",
    "def remove_certain_hosts_from_tree(tree, hosts):\n",
    "    \"\"\"Remove leaf nodes if the host of that leaf is in `hosts`\"\"\"\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    removed_accessions = []\n",
    "    for leaf_node in tree.get_leaves():\n",
    "        if leaf_node.host in hosts:\n",
    "            leaf_node.detach()\n",
    "            \n",
    "    return tree\n",
    "\n",
    "def set_midpoint_outgroup(tree):\n",
    "    tree.set_outgroup(tree.get_midpoint_outgroup())\n",
    "\n",
    "\n",
    "def load_tree(filename, type_='phyloxml'):\n",
    "    \"\"\"Load saved phylogenetic tree.\n",
    "    \"\"\"\n",
    "    \n",
    "    if type_ == 'phyloxml':\n",
    "        project = Phyloxml()\n",
    "        project.build_from_file(filename)\n",
    "\n",
    "        for tree in project.get_phylogeny():\n",
    "            break\n",
    "\n",
    "        t=tree\n",
    "        \n",
    "    elif type_ == 'newick':\n",
    "        t = Tree(filename, format=1)\n",
    "    else:\n",
    "        raise ValueError('Not a correct type.')\n",
    "    \n",
    "    return t\n",
    "\n",
    "\n",
    "\n",
    "PHYLO_DIR='./'\n",
    "\n",
    "Phylo.convert(\n",
    "    PHYLO_DIR + 'ldistanceh1n1.xml','phyloxml',\n",
    "    PHYLO_DIR + 'ldistance.nhx','newick')\n",
    "\n",
    "ltree = load_tree(\n",
    "    PHYLO_DIR + 'ldistance.nhx',\n",
    "    type_='newick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandify(val,min=6.27,max=6.295):\n",
    "    maptoten=int(np.ceil(((val-min)/(max-min))*10))+1\n",
    "    return ' '+u'\\u2580'*maptoten\n",
    "\n",
    "def label_nodes(\n",
    "        tree, \n",
    "        recordinfo):\n",
    "    \"\"\"Label the nodes of the tree.\n",
    "    \n",
    "    We label nodes on whether:\n",
    "        it is covid19\n",
    "    \"\"\"\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    for node in tree:\n",
    "        name = node.name      \n",
    "        node.subtype = recordinfo.seq_infos[name].subtype\n",
    "        node.erisk =recordinfo.seq_infos[name].erisk\n",
    "        node.id = recordinfo.seq_infos[name].name + bandify(recordinfo.seq_infos[name].erisk,min=6.054)\n",
    "        print(node.name,node.subtype,node.id,node.erisk)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_tree=label_nodes(\n",
    "    ltree, ALLinfoHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_nodes(t):\n",
    "    # collapsed nodes are labeled, so you locate them and prune them\n",
    "    for n in t.search_nodes(collapsed=True):\n",
    "        for ch in n.get_children():\n",
    "            ch.detach()\n",
    "            \n",
    "            \n",
    "def mean(array):\n",
    "    return sum(array)/float(len(array))\n",
    "\n",
    "def cache_distances(tree):\n",
    "    ''' precalculate distances of all nodes to the root''' \n",
    "    node2rootdist = {tree:0}\n",
    "    for node in tree.iter_descendants('preorder'):\n",
    "        node2rootdist[node] = node.dist + node2rootdist[node.up]\n",
    "    return node2rootdist\n",
    "\n",
    "def closest_node(node, node2tips, root_distance):\n",
    "    \"\"\"Find the closest node.\"\"\"\n",
    "    \n",
    "    tips = []\n",
    "    distances = []\n",
    "    for tip in node2tips[node]:\n",
    "        distances.append(root_distance[tip]-root_distance[node])\n",
    "        tips.append(tip)\n",
    "        #     index = np.argmin([root_distance[tip]-root_distance[node] for tip in node2tips[node]])\n",
    "    index = np.argmin(distances)\n",
    "    return tips[index]\n",
    "\n",
    "def riskiest_node(node, node2tips):\n",
    "    \"\"\"Find the closest node.\"\"\"\n",
    "    \n",
    "    tips = []\n",
    "    risks = []\n",
    "    for tip in node2tips[node]:\n",
    "        risks.append(tip.erisk)\n",
    "        tips.append(tip)\n",
    "        #     index = np.argmin([root_distance[tip]-root_distance[node] for tip in node2tips[node]])\n",
    "    index = np.argmax(risks)\n",
    "    return tips[index]\n",
    "\n",
    "def collapse(tree, min_dist,AllrecordInfo):\n",
    "    # cache the tip content of each node to reduce the number of times the tree is traversed\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    node2tips = tree.get_cached_content()\n",
    "    root_distance = cache_distances(tree)\n",
    "\n",
    "    for node in tree.get_descendants('preorder'):\n",
    "        if not node.is_leaf():\n",
    "            avg_distance_to_tips = mean([root_distance[tip]-root_distance[node]\n",
    "                                         for tip in node2tips[node]])\n",
    "            print(avg_distance_to_tips)\n",
    "            if avg_distance_to_tips < min_dist:\n",
    "                # do whatever, ete support node annotation, deletion, labeling, etc.\n",
    "            \n",
    "                #closest_name = closest_node(node, node2tips, root_distance).name\n",
    "                closest_name = riskiest_node(node, node2tips).name\n",
    "                node.subtype = AllrecordInfo.seq_infos[closest_name].subtype\n",
    "                node.id = AllrecordInfo.seq_infos[closest_name].name + bandify(AllrecordInfo.seq_infos[closest_name].erisk,min=6.054)\n",
    "                node.name = '%s (%g)' %(closest_name,avg_distance_to_tips)\n",
    "                \n",
    "            \n",
    "                node.add_features(collapsed=True)\n",
    "\n",
    "                # set drawing attribute so they look collapsed when displayed with tree.show()\n",
    "                node.img_style['draw_descendants'] = False\n",
    "\n",
    "    return tree\n",
    "num_collapsed=10\n",
    "ltree_collapsed = collapse(\n",
    "    labelled_tree, \n",
    "    min_dist=num_collapsed, \n",
    "    AllrecordInfo=ALLinfoHA)\n",
    "\n",
    "prune_nodes(ltree_collapsed)\n",
    "\n",
    "\n",
    "# COLBAT='DarkRed'\n",
    "# COLRAT='SteelBlue'\n",
    "COLHUMAN='DarkGreen'\n",
    "COLCOVID='DarkRed'\n",
    "COLBAT='Red'\n",
    "COLRAT='Blue'\n",
    "COLCAMEL='Purple'\n",
    "COLGAME='Red'\n",
    "COLCATTLE='Yellow'\n",
    "# COLHUMAN='Black'\n",
    "FS=50\n",
    "PW=10\n",
    "\n",
    "\n",
    "def nodeAttribConstruct(color, node):\n",
    "    N = AttrFace(\n",
    "        \"id\", fsize=FS, \n",
    "        text_prefix=\" \",penwidth=PW,ftype='Arial',\n",
    "        fgcolor=color,fstyle='bold')\n",
    "    faces.add_face_to_node(N, node, 1, position=\"branch-right\")\n",
    "    return N\n",
    "\n",
    "def layout(node):\n",
    "    if node.is_leaf():\n",
    "        if  node.subtype == 'H1N1':\n",
    "            N = nodeAttribConstruct(COLBAT,node)\n",
    "        elif node.subtype == 'H3N2':\n",
    "            N = nodeAttribConstruct(COLRAT,node)\n",
    "        elif node.subtype == 'H7N9':\n",
    "            N = nodeAttribConstruct(COLHUMAN,node)\n",
    "        elif node.subtype == 'H1N2':\n",
    "            N = nodeAttribConstruct(COLCATTLE,node)\n",
    "        else:\n",
    "            N = nodeAttribConstruct(COLGAME,node)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "def render_tree(tree, outfile):# all_seq_data, display_type='nearest_host'):\n",
    "    \"\"\"Render the tree inside the file to a circular \n",
    "    phylogenetic tree.\n",
    "    \n",
    "    NOTE: outfile should be in .pdf for best visuals\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    #tree = Tree(nwfile,format=1)\n",
    "\n",
    "    ts = TreeStyle()\n",
    "    ns = NodeStyle()\n",
    "    ts.show_leaf_name = False\n",
    "    #ts.rotation = 90\n",
    "    ts.mode = \"r\"\n",
    "    #ts.arc_start = -360 # 0 degrees = 3 o'clock\n",
    "    #ts.arc_span = 360\n",
    "    ts.scale=4\n",
    "    ts.show_scale=False\n",
    "    ts.branch_vertical_margin = .5 # 10 pixels between adjacent branches\n",
    "    # ts.show_branch_length=True\n",
    "    #ts.min_leaf_separation=10\n",
    "    #ts.optimal_scale_level='full'\n",
    "    #ts.branch_vertical_margin=0\n",
    "    \n",
    "    ns.hz_line_width=2\n",
    "    ns.vt_line_width=1\n",
    "    #ts.layout_fn = layout\n",
    "    ns[\"vt_line_width\"] = 16\n",
    "    ns[\"hz_line_width\"] = 16\n",
    "    #     ns['fsize'] = 20\n",
    "    for n in tree.traverse():\n",
    "        n.set_style(ns)\n",
    "        \n",
    "    #all_accessions = all_seq_data['accessions'].values\n",
    "    for n in tree:\n",
    "        ts.layout_fn = layout\n",
    "\n",
    "        \n",
    "    tree.set_style(ns)\n",
    "    tree.set_style(ts)\n",
    "    \n",
    "    #t.show()\n",
    "    tree.render(\n",
    "        outfile, \n",
    "        dpi=300, \n",
    "        h=500,\n",
    "        tree_style=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_tree(\n",
    "    labelled_tree, './riskyphylo6pt054.pdf')\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_tree(\n",
    "    ltree_collapsed, './riskyphylo6pt054_collapsed_'+str(num_collapsed)+'.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
