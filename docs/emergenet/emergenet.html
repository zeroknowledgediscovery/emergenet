<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>emergenet.emergenet API documentation</title>
<meta name="description" content="Emergenet: Fast Scalable Emergence Risk Assessment of Influenza A Strains Circulating In Non-human Hosts" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#666666;background-color:black;//mix-blend-mode:difference;color:#bbbbbb;z-index:3}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#ccbb66;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#66FF66}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:transparent;padding:1px 4px;color:#FFA500;overflow-wrap:break-word}h1 code{background:transparent}pre{overflow-wrap:break-word;background:#111111;word-wrap:break-word;border:0;border-top:1px solid #666;border-bottom:1px solid #666;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#333333;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#aaeeaa;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;color:#bbbbbb;background-color:black;overflow-wrap:break-word}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:18%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>emergenet.emergenet</code></h1>
</header>
<section id="section-intro">
<p>Emergenet: Fast Scalable Emergence Risk Assessment of Influenza A Strains Circulating In Non-human Hosts</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Emergenet: Fast Scalable Emergence Risk Assessment of Influenza A Strains Circulating In Non-human Hosts
&#34;&#34;&#34;
import re, os, json, joblib
import numpy as np
import pandas as pd
from typing import Tuple, Union
from datetime import date, datetime
from collections import Counter
from pkg_resources import resource_filename
from quasinet.qnet import Qnet, qdistance, qdistance_matrix
from .utils import filter_by_date_range, load_model, save_model


# Lengths to truncate sequences
HA_TRUNC = 560
NA_TRUNC = 460


class Enet(object):
    &#39;&#39;&#39; Emergenet architecture for predicting emergence risk.
    &#39;&#39;&#39; 

    def __init__(self, analysis_date:str, ha_seq:str, na_seq:str, 
                 pretrained_enet_path:str=None, save_data:str=None, random_state:int=None):
        &#39;&#39;&#39; Initializes an Emergenet instance.

        Parameters
        ----------
        analysis_date - `PRESENT` or date of analysis (YYYY-MM-DD), supported from 2010-01-01 to 2024-01-01

        ha_seq - The target&#39;s HA sequence to be analysed by Emergenet
            
        na_seq - The target&#39;s NA sequence to be analysed by Emergenet

        save_data - Directory to save data to (Enet models, sequences used for training, etc.)

        random_state - Sets seed for random number generator
        
        pretrained_enet_path - Base path for all pretrained Enet models
        &#39;&#39;&#39;
        # Date
        if analysis_date != &#39;PRESENT&#39;:
            if not re.match(r&#39;^[0-9]{4}-[0-9]{2}-[0-9]{2}$&#39;, analysis_date):
                raise ValueError(&#39;Date must be in format YYYY-MM-DD! or &#34;PRESENT&#34;&#39;)
            if analysis_date &gt; &#39;2024-01-01&#39; or analysis_date &lt; &#39;2010-01-01&#39;:
                raise ValueError(&#39;Emergenet only supports sequences from 2010-01-01 to 2024-01-01!&#39;)
        self.analysis_date = analysis_date
        # Sequences
        if HA_TRUNC &gt; len(ha_seq):
            print(&#39;HA sequence is shorter than required length (560), padding the end with Xs&#39;)
            ha_seq = ha_seq.ljust(HA_TRUNC, &#39;X&#39;)
        self.ha_seq = ha_seq.upper()[:HA_TRUNC]
        if NA_TRUNC &gt; len(na_seq):
            print(&#39;NA sequence is shorter than required length (460), padding the end with Xs&#39;)
            na_seq = na_seq.ljust(NA_TRUNC, &#39;X&#39;)
        self.na_seq = na_seq.upper()[:NA_TRUNC]
        # Pretrained Enet path
        self.pretrained_enet_path = pretrained_enet_path
        # Save data
        self.save_data = save_data
        if save_data is not None:
            if not os.path.exists(save_data):
                os.makedirs(save_data, exist_ok=True)
            if self.analysis_date != &#39;PRESENT&#39; and self.pretrained_enet_path is None:
                self.save_model = os.path.join(save_data, &#39;enet_models&#39;)
                self.save_sequences = os.path.join(save_data, &#39;data&#39;)
                self.save_results = os.path.join(save_data, &#39;results&#39;)
                os.makedirs(self.save_model, exist_ok=True)
                os.makedirs(self.save_sequences, exist_ok=True)
                os.makedirs(self.save_results, exist_ok=True)
        # Random state
        if random_state is not None and random_state &lt; 0:
            raise ValueError(&#39;Seed must be between 0 and 2**32 - 1!&#39;)
        self.random_state = random_state

        
    def __repr__(self):
        return &#39;emergenet.Emergenet&#39;


    def __str__(self):
        return self.__repr__()
    

    def _load_sequences(self, yearsbefore:int) -&gt; pd.DataFrame:
        &#39;&#39;&#39; Loads human sequences within yearsbefore years of the analysis date.

        Parameters
        ----------
        yearsbefore - Number of years prior to analysis_date to consider 

        Returns
        -------
        filtered - DataFrame of human sequences within one year of the analysis date
        &#39;&#39;&#39;
        filepath = resource_filename(&#39;emergenet&#39;, &#39;data/human.csv.gz&#39;)
        human = pd.read_csv(filepath, na_filter=False)
        end = datetime.strptime(self.analysis_date, &#39;%Y-%m-%d&#39;).date()
        start = date(end.year - yearsbefore, end.month, end.day)
        filtered = filter_by_date_range(human, &#39;date&#39;, str(start), str(end))
        print(&#39;Number of human sequences:&#39;, len(filtered))
        print(Counter(filtered[filtered[&#39;segment&#39;] == &#39;HA&#39;][&#39;HA&#39;]))
        print(Counter(filtered[filtered[&#39;segment&#39;] == &#39;NA&#39;][&#39;NA&#39;]))
        return filtered
    

    def _sequence_array(self, segment:str, seq_df:pd.DataFrame, 
                        sample_size:int=None, include_target:bool=True) -&gt; np.ndarray:
        &#39;&#39;&#39; Extracts array of sequence arrays from DataFrame.

        Parameters
        ----------
        segment - Either &#39;HA&#39; or &#39;NA&#39;
            
        seq_df - DataFrame containing sequences

        sample_size - Number of sequences to sample randomly
            
        include_target - If true, includes target sequence

        Returns
        -------
        seq_lst - Array of sequence arrays
        &#39;&#39;&#39; 
        if &#39;sequence&#39; not in seq_df.columns:
            raise ValueError(&#39;The DataFrame must store sequences in `sequence` column!&#39;)
        if sample_size is not None:
            sample_size = min(sample_size, len(seq_df))
            seq_df = seq_df.sample(sample_size, random_state=self.random_state)
        seqs = seq_df[&#39;sequence&#39;].values
        seq_lst = []
        if segment == &#39;HA&#39;:
            TRUNC = HA_TRUNC
            if include_target:
                seq_lst.append(np.array(list(self.ha_seq[:TRUNC])))
        elif segment == &#39;NA&#39;:
            TRUNC = NA_TRUNC
            if include_target:
                seq_lst.append(np.array(list(self.na_seq[:TRUNC])))
        for seq in seqs:
            if len(seq) &lt; TRUNC:
                continue
            seq_lst.append(np.array(list(seq[:TRUNC])))
        seq_lst = np.array(seq_lst)
        return seq_lst

    
    def _compute_risks(self, segment:str, seq_df:pd.DataFrame, enet:Qnet) -&gt; pd.DataFrame:
        &#39;&#39;&#39; Computes risk score with qdistance.

        Parameters
        ----------
        segment - Either &#39;HA&#39; or &#39;NA&#39;

        seq_df - DataFrame of sequences

        enet - Emergenet that sequences in `seq_df` belong to

        Returns
        -------
        seq_df - The input `seq_df` with extra risk column
        &#39;&#39;&#39; 
        if len(seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        seq_arr = self._sequence_array(segment, seq_df, include_target=False)
        if segment == &#39;HA&#39;:
            TRUNC = HA_TRUNC
            target_seq = np.array(list(self.ha_seq[:TRUNC]))
        elif segment == &#39;NA&#39;:
            TRUNC = NA_TRUNC
            target_seq = np.array(list(self.na_seq[:TRUNC]))
        qdist = qdistance_matrix(seq_arr, np.array([target_seq]), enet, enet)
        seq_df[&#39;risk&#39;] = qdist.ravel() 
        return seq_df
    

    def train(self, segment:str, seq_df:pd.DataFrame, sample_size:int=None, 
              include_target:bool=True, n_jobs:int=1) -&gt; Qnet:
        &#39;&#39;&#39; Trains an Emergenet model.

        Parameters
        ----------
        segment - Either &#39;HA&#39; or &#39;NA&#39;

        seq_df - DataFrame of sequences

        sample_size - Number of sequences to train Emergenet on, sampled randomly

        include_target - If true, includes target sequence

        n_jobs - Number of CPUs to use when training

        Returns
        -------
        enet - Trained Emergenet
        &#39;&#39;&#39; 
        if len(seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        if segment not in [&#39;HA&#39;, &#39;NA&#39;]:
            raise ValueError(&#39;Segment must be either HA or NA!&#39;)
        if segment == &#39;HA&#39;:
            TRUNC = HA_TRUNC
        elif segment == &#39;NA&#39;:
            TRUNC = NA_TRUNC
        seq_arr = self._sequence_array(segment, seq_df, sample_size, include_target)
        enet = Qnet(feature_names=[&#39;x&#39; + str(i) for i in np.arange(TRUNC)],
                    random_state=self.random_state, n_jobs=n_jobs)
        enet.fit(seq_arr)
        return enet
    

    def risk(self, yearsbefore:int=1, enet_sample_size:Union[int, float]=None, 
             risk_sample_size:Union[int, float]=None) -&gt; Tuple[float, float]:
        &#39;&#39;&#39; Computes risk scores for the target sequence.
        If `save_data` is not None, `analysis_date` is not &#39;PRESENT&#39; and pretrained_enet_path is None, saves the following:
        1. Emergenet models: `save_data/enet_models/&lt;subtype&gt;.joblib`
        2. DataFrames of sequences used for training: `save_data/data/&lt;subtype&gt;.csv`
        3. Results (sequence DataFrames with extra `risk_score` column): `save_data/results/&lt;subtype&gt;.csv`
        4. Minimum risks for each HA and NA subtype: `save_data/results/&lt;segment&gt;_min_risks.csv`

        If `save_data` is not None, and `analysis_date` is &#39;PRESENT&#39; or pretrained_enet_path is not None, saves the following:
        1. Results (sequence DataFrames with extra `risk_score` column): `save_data/&lt;subtype&gt;.csv`
        2. Minimum risks for each HA and NA subtype: `save_data/&lt;segment&gt;_min_risks.csv`

        Parameters
        ----------
        yearsbefore - Number of years prior to analysis_date to consider 
        
        enet_sample_size - Number of or proportion sequences of each subtype to train Emergenet on
        
        risk_sample_size - Number or proportion of unique sequences of each subtype to sample for risk estimation

        Returns
        -------
        ha_risk - Risk score for HA segment
        
        na_risk - Risk score for NA segment
        &#39;&#39;&#39;
        if self.analysis_date == &#39;PRESENT&#39;:
            filepath = resource_filename(&#39;emergenet&#39;, &#39;data/current_subtypes.json&#39;)
            with open(filepath, &#39;r&#39;) as file:
                current_subtypes = json.load(file)
            for segment in [&#39;HA&#39;, &#39;NA&#39;]:
                risks = pd.DataFrame()
                if segment == &#39;HA&#39;:
                    TRUNC = HA_TRUNC
                elif segment == &#39;NA&#39;:
                    TRUNC = NA_TRUNC
                for subtype in current_subtypes[segment]:
                    # Load human sequences for and pretrained Enet models for current subtype
                    human_filepath = resource_filename(&#39;emergenet&#39;, f&#39;data/current/{subtype}.csv&#39;)
                    model_filepath = resource_filename(&#39;emergenet&#39;, f&#39;models/{subtype}.joblib.gz&#39;)
                    df = pd.read_csv(human_filepath, na_filter=False)
                    # Sample from human sequences if needed
                    if risk_sample_size is not None:
                        if isinstance(risk_sample_size, int):
                            sample_size = min(risk_sample_size, len(df))
                        elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                            sample_size = int(risk_sample_size * len(df))
                        df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                    # Load Enet and compute risks
                    enet = load_model(model_filepath, gz=True)
                    df = self._compute_risks(segment, df, enet)
                    if self.save_data is not None:
                        df.to_csv(os.path.join(self.save_data, subtype + &#39;.csv&#39;), index=False)
                    # Save minimum risk for current subtype
                    risks[subtype] = [np.min(df[&#39;risk&#39;])]
                # Save overall minimum risk
                if self.save_data is not None:
                    risks.to_csv(os.path.join(self.save_data, segment + &#39;_min_risks.csv&#39;), index=False)
                if segment == &#39;HA&#39;:
                    ha_risk = risks.min(axis=1).values[0] + 1e-5
                elif segment == &#39;NA&#39;:
                    na_risk = risks.min(axis=1).values[0] + 1e-5
            return ha_risk, na_risk

        elif self.pretrained_enet_path is not None:
            human = self._load_sequences(yearsbefore)
            for segment in [&#39;HA&#39;, &#39;NA&#39;]:
                risks = pd.DataFrame()
                if segment == &#39;HA&#39;:
                    TRUNC = HA_TRUNC
                elif segment == &#39;NA&#39;:
                    TRUNC = NA_TRUNC
                human1 = human[human[&#39;segment&#39;] == segment]
                human1 = human1[human1[&#39;sequence&#39;].str.len() &gt;= TRUNC]
                subtypes = Counter(human1[segment])
                for subtype in subtypes:
                    # Skip subtypes with less than 15 sequences
                    if subtypes[subtype] &lt; 15:
                        continue                    
                    # Use only unique sequences for inference
                    df = human1[human1[segment] == subtype].drop_duplicates(subset=[&#39;sequence&#39;])
                    # Sample from human sequences if needed
                    if risk_sample_size is not None:
                        if isinstance(risk_sample_size, int):
                            sample_size = min(risk_sample_size, len(df))
                        elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                            sample_size = int(risk_sample_size * len(df))
                        df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                    # Load Enet and compute risks
                    enet = load_model(os.path.join(self.pretrained_enet_path, subtype + &#39;.joblib&#39;))
                    df = self._compute_risks(segment, df, enet)
                    if self.save_data is not None:
                        df.to_csv(os.path.join(self.save_data, subtype + &#39;.csv&#39;), index=False)
                    # Save minimum risk for current subtype
                    risks[subtype] = [np.min(df[&#39;risk&#39;])]
                # Save overall minimum risk
                if self.save_data is not None:
                    risks.to_csv(os.path.join(self.save_data, segment + &#39;_min_risks.csv&#39;), index=False)
                if segment == &#39;HA&#39;:
                    ha_risk = risks.min(axis=1).values[0] + 1e-5
                elif segment == &#39;NA&#39;:
                    na_risk = risks.min(axis=1).values[0] + 1e-5
            return ha_risk, na_risk
        
        else:
            human = self._load_sequences(yearsbefore)
            for segment in [&#39;HA&#39;, &#39;NA&#39;]:
                risks = pd.DataFrame()
                if segment == &#39;HA&#39;:
                    TRUNC = HA_TRUNC
                elif segment == &#39;NA&#39;:
                    TRUNC = NA_TRUNC
                human1 = human[human[&#39;segment&#39;] == segment]
                human1 = human1[human1[&#39;sequence&#39;].str.len() &gt;= TRUNC]
                subtypes = Counter(human1[segment])
                for subtype in subtypes:
                    # Skip subtypes with less than 15 sequences
                    if subtypes[subtype] &lt; 15:
                        continue
                    # Load human strains for constructing enet, sampling if needed
                    df = human1[human1[segment] == subtype]
                    if enet_sample_size is not None:
                        if isinstance(enet_sample_size, int):
                            sample_size = min(enet_sample_size, len(df))
                        elif isinstance(enet_sample_size, float) and enet_sample_size &lt;= 1:
                            sample_size = int(enet_sample_size * len(df))
                        df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                    if self.save_data is not None:
                        df.to_csv(os.path.join(self.save_sequences, subtype + &#39;.csv&#39;), index=False)
                    # Train Enet
                    enet = self.train(segment, df)
                    if self.save_data is not None:
                        save_model(enet, os.path.join(self.save_model, subtype + &#39;.joblib&#39;))
                    # Use only unique sequences for inference
                    df = df.drop_duplicates(subset=[&#39;sequence&#39;])
                    # Sample from human sequences if needed (only if we did not already sample for training Enet)
                    if risk_sample_size is not None and enet_sample_size is None:
                        if isinstance(risk_sample_size, int):
                            sample_size = min(risk_sample_size, len(df))
                        elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                            sample_size = int(risk_sample_size * len(df))
                        df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                    # Compute risks
                    df = self._compute_risks(segment, df, enet)
                    if self.save_data is not None:
                        df.to_csv(os.path.join(self.save_results, subtype + &#39;.csv&#39;), index=False)
                    # Save minimum risk for current subtype
                    risks[subtype] = [np.min(df[&#39;risk&#39;])]
                # Save overall minimum risk
                if self.save_data is not None:
                    risks.to_csv(os.path.join(self.save_results, segment + &#39;_min_risks.csv&#39;), index=False)
                if segment == &#39;HA&#39;:
                    ha_risk = risks.min(axis=1).values[0] + 1e-5
                elif segment == &#39;NA&#39;:
                    na_risk = risks.min(axis=1).values[0] + 1e-5
            return ha_risk, na_risk
        

def predict_irat_emergence(ha_risk:float, na_risk:float) -&gt; Tuple[float, float, float]:
    &#39;&#39;&#39; Computes IRAT emergence risk score.

    Parameters
    ----------
    ha_risk - Risk score for HA segment

    na_risk - Risk score for NA segment

    Returns
    -------
    irat_emergence - Predicted IRAT emergence risk score

    irat_emergence_low - Lower bound IRAT emergence risk score

    irat_emergence_high - Upper bound IRAT emergence risk score
    &#39;&#39;&#39;
    geom_mean = np.sqrt(ha_risk * na_risk)
    x = -np.log(geom_mean + 5e-4)
    emergence_model = joblib.load(resource_filename(&#39;emergenet&#39;, &#39;models/emergence_model.joblib&#39;))
    emergence_low_model = joblib.load(resource_filename(&#39;emergenet&#39;, &#39;models/emergence_low_model.joblib&#39;))
    emergence_high_model = joblib.load(resource_filename(&#39;emergenet&#39;, &#39;models/emergence_high_model.joblib&#39;))
    irat_emergence = emergence_model[&#39;intercept&#39;] + emergence_model[&#39;slope&#39;] * x
    irat_emergence_low = emergence_low_model[&#39;intercept&#39;] + emergence_low_model[&#39;slope&#39;] * x
    irat_emergence_high = emergence_high_model[&#39;intercept&#39;] + emergence_high_model[&#39;slope&#39;] * x
    return irat_emergence, irat_emergence_low, irat_emergence_high
        </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="emergenet.emergenet.predict_irat_emergence"><code class="name flex">
<span>def <span class="ident">predict_irat_emergence</span></span>(<span>ha_risk: float, na_risk: float) ‑> Tuple[float, float, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Computes IRAT emergence risk score.</p>
<h2 id="parameters">Parameters</h2>
<p>ha_risk - Risk score for HA segment</p>
<p>na_risk - Risk score for NA segment</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>irat_emergence - Predicted IRAT emergence risk score</code></dt>
<dd>&nbsp;</dd>
<dt><code>irat_emergence_low - Lower bound IRAT emergence risk score</code></dt>
<dd>&nbsp;</dd>
<dt><code>irat_emergence_high - Upper bound IRAT emergence risk score</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_irat_emergence(ha_risk:float, na_risk:float) -&gt; Tuple[float, float, float]:
    &#39;&#39;&#39; Computes IRAT emergence risk score.

    Parameters
    ----------
    ha_risk - Risk score for HA segment

    na_risk - Risk score for NA segment

    Returns
    -------
    irat_emergence - Predicted IRAT emergence risk score

    irat_emergence_low - Lower bound IRAT emergence risk score

    irat_emergence_high - Upper bound IRAT emergence risk score
    &#39;&#39;&#39;
    geom_mean = np.sqrt(ha_risk * na_risk)
    x = -np.log(geom_mean + 5e-4)
    emergence_model = joblib.load(resource_filename(&#39;emergenet&#39;, &#39;models/emergence_model.joblib&#39;))
    emergence_low_model = joblib.load(resource_filename(&#39;emergenet&#39;, &#39;models/emergence_low_model.joblib&#39;))
    emergence_high_model = joblib.load(resource_filename(&#39;emergenet&#39;, &#39;models/emergence_high_model.joblib&#39;))
    irat_emergence = emergence_model[&#39;intercept&#39;] + emergence_model[&#39;slope&#39;] * x
    irat_emergence_low = emergence_low_model[&#39;intercept&#39;] + emergence_low_model[&#39;slope&#39;] * x
    irat_emergence_high = emergence_high_model[&#39;intercept&#39;] + emergence_high_model[&#39;slope&#39;] * x
    return irat_emergence, irat_emergence_low, irat_emergence_high</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="emergenet.emergenet.Enet"><code class="flex name class">
<span>class <span class="ident">Enet</span></span>
<span>(</span><span>analysis_date: str, ha_seq: str, na_seq: str, pretrained_enet_path: str = None, save_data: str = None, random_state: int = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Emergenet architecture for predicting emergence risk.</p>
<p>Initializes an Emergenet instance.</p>
<h2 id="parameters">Parameters</h2>
<p>analysis_date - <code>PRESENT</code> or date of analysis (YYYY-MM-DD), supported from 2010-01-01 to 2024-01-01</p>
<p>ha_seq - The target's HA sequence to be analysed by Emergenet</p>
<p>na_seq - The target's NA sequence to be analysed by Emergenet</p>
<p>save_data - Directory to save data to (Enet models, sequences used for training, etc.)</p>
<p>random_state - Sets seed for random number generator</p>
<p>pretrained_enet_path - Base path for all pretrained Enet models</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Enet(object):
    &#39;&#39;&#39; Emergenet architecture for predicting emergence risk.
    &#39;&#39;&#39; 

    def __init__(self, analysis_date:str, ha_seq:str, na_seq:str, 
                 pretrained_enet_path:str=None, save_data:str=None, random_state:int=None):
        &#39;&#39;&#39; Initializes an Emergenet instance.

        Parameters
        ----------
        analysis_date - `PRESENT` or date of analysis (YYYY-MM-DD), supported from 2010-01-01 to 2024-01-01

        ha_seq - The target&#39;s HA sequence to be analysed by Emergenet
            
        na_seq - The target&#39;s NA sequence to be analysed by Emergenet

        save_data - Directory to save data to (Enet models, sequences used for training, etc.)

        random_state - Sets seed for random number generator
        
        pretrained_enet_path - Base path for all pretrained Enet models
        &#39;&#39;&#39;
        # Date
        if analysis_date != &#39;PRESENT&#39;:
            if not re.match(r&#39;^[0-9]{4}-[0-9]{2}-[0-9]{2}$&#39;, analysis_date):
                raise ValueError(&#39;Date must be in format YYYY-MM-DD! or &#34;PRESENT&#34;&#39;)
            if analysis_date &gt; &#39;2024-01-01&#39; or analysis_date &lt; &#39;2010-01-01&#39;:
                raise ValueError(&#39;Emergenet only supports sequences from 2010-01-01 to 2024-01-01!&#39;)
        self.analysis_date = analysis_date
        # Sequences
        if HA_TRUNC &gt; len(ha_seq):
            print(&#39;HA sequence is shorter than required length (560), padding the end with Xs&#39;)
            ha_seq = ha_seq.ljust(HA_TRUNC, &#39;X&#39;)
        self.ha_seq = ha_seq.upper()[:HA_TRUNC]
        if NA_TRUNC &gt; len(na_seq):
            print(&#39;NA sequence is shorter than required length (460), padding the end with Xs&#39;)
            na_seq = na_seq.ljust(NA_TRUNC, &#39;X&#39;)
        self.na_seq = na_seq.upper()[:NA_TRUNC]
        # Pretrained Enet path
        self.pretrained_enet_path = pretrained_enet_path
        # Save data
        self.save_data = save_data
        if save_data is not None:
            if not os.path.exists(save_data):
                os.makedirs(save_data, exist_ok=True)
            if self.analysis_date != &#39;PRESENT&#39; and self.pretrained_enet_path is None:
                self.save_model = os.path.join(save_data, &#39;enet_models&#39;)
                self.save_sequences = os.path.join(save_data, &#39;data&#39;)
                self.save_results = os.path.join(save_data, &#39;results&#39;)
                os.makedirs(self.save_model, exist_ok=True)
                os.makedirs(self.save_sequences, exist_ok=True)
                os.makedirs(self.save_results, exist_ok=True)
        # Random state
        if random_state is not None and random_state &lt; 0:
            raise ValueError(&#39;Seed must be between 0 and 2**32 - 1!&#39;)
        self.random_state = random_state

        
    def __repr__(self):
        return &#39;emergenet.Emergenet&#39;


    def __str__(self):
        return self.__repr__()
    

    def _load_sequences(self, yearsbefore:int) -&gt; pd.DataFrame:
        &#39;&#39;&#39; Loads human sequences within yearsbefore years of the analysis date.

        Parameters
        ----------
        yearsbefore - Number of years prior to analysis_date to consider 

        Returns
        -------
        filtered - DataFrame of human sequences within one year of the analysis date
        &#39;&#39;&#39;
        filepath = resource_filename(&#39;emergenet&#39;, &#39;data/human.csv.gz&#39;)
        human = pd.read_csv(filepath, na_filter=False)
        end = datetime.strptime(self.analysis_date, &#39;%Y-%m-%d&#39;).date()
        start = date(end.year - yearsbefore, end.month, end.day)
        filtered = filter_by_date_range(human, &#39;date&#39;, str(start), str(end))
        print(&#39;Number of human sequences:&#39;, len(filtered))
        print(Counter(filtered[filtered[&#39;segment&#39;] == &#39;HA&#39;][&#39;HA&#39;]))
        print(Counter(filtered[filtered[&#39;segment&#39;] == &#39;NA&#39;][&#39;NA&#39;]))
        return filtered
    

    def _sequence_array(self, segment:str, seq_df:pd.DataFrame, 
                        sample_size:int=None, include_target:bool=True) -&gt; np.ndarray:
        &#39;&#39;&#39; Extracts array of sequence arrays from DataFrame.

        Parameters
        ----------
        segment - Either &#39;HA&#39; or &#39;NA&#39;
            
        seq_df - DataFrame containing sequences

        sample_size - Number of sequences to sample randomly
            
        include_target - If true, includes target sequence

        Returns
        -------
        seq_lst - Array of sequence arrays
        &#39;&#39;&#39; 
        if &#39;sequence&#39; not in seq_df.columns:
            raise ValueError(&#39;The DataFrame must store sequences in `sequence` column!&#39;)
        if sample_size is not None:
            sample_size = min(sample_size, len(seq_df))
            seq_df = seq_df.sample(sample_size, random_state=self.random_state)
        seqs = seq_df[&#39;sequence&#39;].values
        seq_lst = []
        if segment == &#39;HA&#39;:
            TRUNC = HA_TRUNC
            if include_target:
                seq_lst.append(np.array(list(self.ha_seq[:TRUNC])))
        elif segment == &#39;NA&#39;:
            TRUNC = NA_TRUNC
            if include_target:
                seq_lst.append(np.array(list(self.na_seq[:TRUNC])))
        for seq in seqs:
            if len(seq) &lt; TRUNC:
                continue
            seq_lst.append(np.array(list(seq[:TRUNC])))
        seq_lst = np.array(seq_lst)
        return seq_lst

    
    def _compute_risks(self, segment:str, seq_df:pd.DataFrame, enet:Qnet) -&gt; pd.DataFrame:
        &#39;&#39;&#39; Computes risk score with qdistance.

        Parameters
        ----------
        segment - Either &#39;HA&#39; or &#39;NA&#39;

        seq_df - DataFrame of sequences

        enet - Emergenet that sequences in `seq_df` belong to

        Returns
        -------
        seq_df - The input `seq_df` with extra risk column
        &#39;&#39;&#39; 
        if len(seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        seq_arr = self._sequence_array(segment, seq_df, include_target=False)
        if segment == &#39;HA&#39;:
            TRUNC = HA_TRUNC
            target_seq = np.array(list(self.ha_seq[:TRUNC]))
        elif segment == &#39;NA&#39;:
            TRUNC = NA_TRUNC
            target_seq = np.array(list(self.na_seq[:TRUNC]))
        qdist = qdistance_matrix(seq_arr, np.array([target_seq]), enet, enet)
        seq_df[&#39;risk&#39;] = qdist.ravel() 
        return seq_df
    

    def train(self, segment:str, seq_df:pd.DataFrame, sample_size:int=None, 
              include_target:bool=True, n_jobs:int=1) -&gt; Qnet:
        &#39;&#39;&#39; Trains an Emergenet model.

        Parameters
        ----------
        segment - Either &#39;HA&#39; or &#39;NA&#39;

        seq_df - DataFrame of sequences

        sample_size - Number of sequences to train Emergenet on, sampled randomly

        include_target - If true, includes target sequence

        n_jobs - Number of CPUs to use when training

        Returns
        -------
        enet - Trained Emergenet
        &#39;&#39;&#39; 
        if len(seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        if segment not in [&#39;HA&#39;, &#39;NA&#39;]:
            raise ValueError(&#39;Segment must be either HA or NA!&#39;)
        if segment == &#39;HA&#39;:
            TRUNC = HA_TRUNC
        elif segment == &#39;NA&#39;:
            TRUNC = NA_TRUNC
        seq_arr = self._sequence_array(segment, seq_df, sample_size, include_target)
        enet = Qnet(feature_names=[&#39;x&#39; + str(i) for i in np.arange(TRUNC)],
                    random_state=self.random_state, n_jobs=n_jobs)
        enet.fit(seq_arr)
        return enet
    

    def risk(self, yearsbefore:int=1, enet_sample_size:Union[int, float]=None, 
             risk_sample_size:Union[int, float]=None) -&gt; Tuple[float, float]:
        &#39;&#39;&#39; Computes risk scores for the target sequence.
        If `save_data` is not None, `analysis_date` is not &#39;PRESENT&#39; and pretrained_enet_path is None, saves the following:
        1. Emergenet models: `save_data/enet_models/&lt;subtype&gt;.joblib`
        2. DataFrames of sequences used for training: `save_data/data/&lt;subtype&gt;.csv`
        3. Results (sequence DataFrames with extra `risk_score` column): `save_data/results/&lt;subtype&gt;.csv`
        4. Minimum risks for each HA and NA subtype: `save_data/results/&lt;segment&gt;_min_risks.csv`

        If `save_data` is not None, and `analysis_date` is &#39;PRESENT&#39; or pretrained_enet_path is not None, saves the following:
        1. Results (sequence DataFrames with extra `risk_score` column): `save_data/&lt;subtype&gt;.csv`
        2. Minimum risks for each HA and NA subtype: `save_data/&lt;segment&gt;_min_risks.csv`

        Parameters
        ----------
        yearsbefore - Number of years prior to analysis_date to consider 
        
        enet_sample_size - Number of or proportion sequences of each subtype to train Emergenet on
        
        risk_sample_size - Number or proportion of unique sequences of each subtype to sample for risk estimation

        Returns
        -------
        ha_risk - Risk score for HA segment
        
        na_risk - Risk score for NA segment
        &#39;&#39;&#39;
        if self.analysis_date == &#39;PRESENT&#39;:
            filepath = resource_filename(&#39;emergenet&#39;, &#39;data/current_subtypes.json&#39;)
            with open(filepath, &#39;r&#39;) as file:
                current_subtypes = json.load(file)
            for segment in [&#39;HA&#39;, &#39;NA&#39;]:
                risks = pd.DataFrame()
                if segment == &#39;HA&#39;:
                    TRUNC = HA_TRUNC
                elif segment == &#39;NA&#39;:
                    TRUNC = NA_TRUNC
                for subtype in current_subtypes[segment]:
                    # Load human sequences for and pretrained Enet models for current subtype
                    human_filepath = resource_filename(&#39;emergenet&#39;, f&#39;data/current/{subtype}.csv&#39;)
                    model_filepath = resource_filename(&#39;emergenet&#39;, f&#39;models/{subtype}.joblib.gz&#39;)
                    df = pd.read_csv(human_filepath, na_filter=False)
                    # Sample from human sequences if needed
                    if risk_sample_size is not None:
                        if isinstance(risk_sample_size, int):
                            sample_size = min(risk_sample_size, len(df))
                        elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                            sample_size = int(risk_sample_size * len(df))
                        df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                    # Load Enet and compute risks
                    enet = load_model(model_filepath, gz=True)
                    df = self._compute_risks(segment, df, enet)
                    if self.save_data is not None:
                        df.to_csv(os.path.join(self.save_data, subtype + &#39;.csv&#39;), index=False)
                    # Save minimum risk for current subtype
                    risks[subtype] = [np.min(df[&#39;risk&#39;])]
                # Save overall minimum risk
                if self.save_data is not None:
                    risks.to_csv(os.path.join(self.save_data, segment + &#39;_min_risks.csv&#39;), index=False)
                if segment == &#39;HA&#39;:
                    ha_risk = risks.min(axis=1).values[0] + 1e-5
                elif segment == &#39;NA&#39;:
                    na_risk = risks.min(axis=1).values[0] + 1e-5
            return ha_risk, na_risk

        elif self.pretrained_enet_path is not None:
            human = self._load_sequences(yearsbefore)
            for segment in [&#39;HA&#39;, &#39;NA&#39;]:
                risks = pd.DataFrame()
                if segment == &#39;HA&#39;:
                    TRUNC = HA_TRUNC
                elif segment == &#39;NA&#39;:
                    TRUNC = NA_TRUNC
                human1 = human[human[&#39;segment&#39;] == segment]
                human1 = human1[human1[&#39;sequence&#39;].str.len() &gt;= TRUNC]
                subtypes = Counter(human1[segment])
                for subtype in subtypes:
                    # Skip subtypes with less than 15 sequences
                    if subtypes[subtype] &lt; 15:
                        continue                    
                    # Use only unique sequences for inference
                    df = human1[human1[segment] == subtype].drop_duplicates(subset=[&#39;sequence&#39;])
                    # Sample from human sequences if needed
                    if risk_sample_size is not None:
                        if isinstance(risk_sample_size, int):
                            sample_size = min(risk_sample_size, len(df))
                        elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                            sample_size = int(risk_sample_size * len(df))
                        df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                    # Load Enet and compute risks
                    enet = load_model(os.path.join(self.pretrained_enet_path, subtype + &#39;.joblib&#39;))
                    df = self._compute_risks(segment, df, enet)
                    if self.save_data is not None:
                        df.to_csv(os.path.join(self.save_data, subtype + &#39;.csv&#39;), index=False)
                    # Save minimum risk for current subtype
                    risks[subtype] = [np.min(df[&#39;risk&#39;])]
                # Save overall minimum risk
                if self.save_data is not None:
                    risks.to_csv(os.path.join(self.save_data, segment + &#39;_min_risks.csv&#39;), index=False)
                if segment == &#39;HA&#39;:
                    ha_risk = risks.min(axis=1).values[0] + 1e-5
                elif segment == &#39;NA&#39;:
                    na_risk = risks.min(axis=1).values[0] + 1e-5
            return ha_risk, na_risk
        
        else:
            human = self._load_sequences(yearsbefore)
            for segment in [&#39;HA&#39;, &#39;NA&#39;]:
                risks = pd.DataFrame()
                if segment == &#39;HA&#39;:
                    TRUNC = HA_TRUNC
                elif segment == &#39;NA&#39;:
                    TRUNC = NA_TRUNC
                human1 = human[human[&#39;segment&#39;] == segment]
                human1 = human1[human1[&#39;sequence&#39;].str.len() &gt;= TRUNC]
                subtypes = Counter(human1[segment])
                for subtype in subtypes:
                    # Skip subtypes with less than 15 sequences
                    if subtypes[subtype] &lt; 15:
                        continue
                    # Load human strains for constructing enet, sampling if needed
                    df = human1[human1[segment] == subtype]
                    if enet_sample_size is not None:
                        if isinstance(enet_sample_size, int):
                            sample_size = min(enet_sample_size, len(df))
                        elif isinstance(enet_sample_size, float) and enet_sample_size &lt;= 1:
                            sample_size = int(enet_sample_size * len(df))
                        df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                    if self.save_data is not None:
                        df.to_csv(os.path.join(self.save_sequences, subtype + &#39;.csv&#39;), index=False)
                    # Train Enet
                    enet = self.train(segment, df)
                    if self.save_data is not None:
                        save_model(enet, os.path.join(self.save_model, subtype + &#39;.joblib&#39;))
                    # Use only unique sequences for inference
                    df = df.drop_duplicates(subset=[&#39;sequence&#39;])
                    # Sample from human sequences if needed (only if we did not already sample for training Enet)
                    if risk_sample_size is not None and enet_sample_size is None:
                        if isinstance(risk_sample_size, int):
                            sample_size = min(risk_sample_size, len(df))
                        elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                            sample_size = int(risk_sample_size * len(df))
                        df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                    # Compute risks
                    df = self._compute_risks(segment, df, enet)
                    if self.save_data is not None:
                        df.to_csv(os.path.join(self.save_results, subtype + &#39;.csv&#39;), index=False)
                    # Save minimum risk for current subtype
                    risks[subtype] = [np.min(df[&#39;risk&#39;])]
                # Save overall minimum risk
                if self.save_data is not None:
                    risks.to_csv(os.path.join(self.save_results, segment + &#39;_min_risks.csv&#39;), index=False)
                if segment == &#39;HA&#39;:
                    ha_risk = risks.min(axis=1).values[0] + 1e-5
                elif segment == &#39;NA&#39;:
                    na_risk = risks.min(axis=1).values[0] + 1e-5
            return ha_risk, na_risk</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="emergenet.emergenet.Enet.risk"><code class="name flex">
<span>def <span class="ident">risk</span></span>(<span>self, yearsbefore: int = 1, enet_sample_size: Union[int, float] = None, risk_sample_size: Union[int, float] = None) ‑> Tuple[float, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Computes risk scores for the target sequence.
If <code>save_data</code> is not None, <code>analysis_date</code> is not 'PRESENT' and pretrained_enet_path is None, saves the following:
1. Emergenet models: <code>save_data/enet_models/&lt;subtype&gt;.joblib</code>
2. DataFrames of sequences used for training: <code>save_data/data/&lt;subtype&gt;.csv</code>
3. Results (sequence DataFrames with extra <code>risk_score</code> column): <code>save_data/results/&lt;subtype&gt;.csv</code>
4. Minimum risks for each HA and NA subtype: <code>save_data/results/&lt;segment&gt;_min_risks.csv</code></p>
<p>If <code>save_data</code> is not None, and <code>analysis_date</code> is 'PRESENT' or pretrained_enet_path is not None, saves the following:
1. Results (sequence DataFrames with extra <code>risk_score</code> column): <code>save_data/&lt;subtype&gt;.csv</code>
2. Minimum risks for each HA and NA subtype: <code>save_data/&lt;segment&gt;_min_risks.csv</code></p>
<h2 id="parameters">Parameters</h2>
<p>yearsbefore - Number of years prior to analysis_date to consider </p>
<p>enet_sample_size - Number of or proportion sequences of each subtype to train Emergenet on</p>
<p>risk_sample_size - Number or proportion of unique sequences of each subtype to sample for risk estimation</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ha_risk - Risk score for HA segment</code></dt>
<dd>&nbsp;</dd>
<dt><code>na_risk - Risk score for NA segment</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def risk(self, yearsbefore:int=1, enet_sample_size:Union[int, float]=None, 
         risk_sample_size:Union[int, float]=None) -&gt; Tuple[float, float]:
    &#39;&#39;&#39; Computes risk scores for the target sequence.
    If `save_data` is not None, `analysis_date` is not &#39;PRESENT&#39; and pretrained_enet_path is None, saves the following:
    1. Emergenet models: `save_data/enet_models/&lt;subtype&gt;.joblib`
    2. DataFrames of sequences used for training: `save_data/data/&lt;subtype&gt;.csv`
    3. Results (sequence DataFrames with extra `risk_score` column): `save_data/results/&lt;subtype&gt;.csv`
    4. Minimum risks for each HA and NA subtype: `save_data/results/&lt;segment&gt;_min_risks.csv`

    If `save_data` is not None, and `analysis_date` is &#39;PRESENT&#39; or pretrained_enet_path is not None, saves the following:
    1. Results (sequence DataFrames with extra `risk_score` column): `save_data/&lt;subtype&gt;.csv`
    2. Minimum risks for each HA and NA subtype: `save_data/&lt;segment&gt;_min_risks.csv`

    Parameters
    ----------
    yearsbefore - Number of years prior to analysis_date to consider 
    
    enet_sample_size - Number of or proportion sequences of each subtype to train Emergenet on
    
    risk_sample_size - Number or proportion of unique sequences of each subtype to sample for risk estimation

    Returns
    -------
    ha_risk - Risk score for HA segment
    
    na_risk - Risk score for NA segment
    &#39;&#39;&#39;
    if self.analysis_date == &#39;PRESENT&#39;:
        filepath = resource_filename(&#39;emergenet&#39;, &#39;data/current_subtypes.json&#39;)
        with open(filepath, &#39;r&#39;) as file:
            current_subtypes = json.load(file)
        for segment in [&#39;HA&#39;, &#39;NA&#39;]:
            risks = pd.DataFrame()
            if segment == &#39;HA&#39;:
                TRUNC = HA_TRUNC
            elif segment == &#39;NA&#39;:
                TRUNC = NA_TRUNC
            for subtype in current_subtypes[segment]:
                # Load human sequences for and pretrained Enet models for current subtype
                human_filepath = resource_filename(&#39;emergenet&#39;, f&#39;data/current/{subtype}.csv&#39;)
                model_filepath = resource_filename(&#39;emergenet&#39;, f&#39;models/{subtype}.joblib.gz&#39;)
                df = pd.read_csv(human_filepath, na_filter=False)
                # Sample from human sequences if needed
                if risk_sample_size is not None:
                    if isinstance(risk_sample_size, int):
                        sample_size = min(risk_sample_size, len(df))
                    elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                        sample_size = int(risk_sample_size * len(df))
                    df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                # Load Enet and compute risks
                enet = load_model(model_filepath, gz=True)
                df = self._compute_risks(segment, df, enet)
                if self.save_data is not None:
                    df.to_csv(os.path.join(self.save_data, subtype + &#39;.csv&#39;), index=False)
                # Save minimum risk for current subtype
                risks[subtype] = [np.min(df[&#39;risk&#39;])]
            # Save overall minimum risk
            if self.save_data is not None:
                risks.to_csv(os.path.join(self.save_data, segment + &#39;_min_risks.csv&#39;), index=False)
            if segment == &#39;HA&#39;:
                ha_risk = risks.min(axis=1).values[0] + 1e-5
            elif segment == &#39;NA&#39;:
                na_risk = risks.min(axis=1).values[0] + 1e-5
        return ha_risk, na_risk

    elif self.pretrained_enet_path is not None:
        human = self._load_sequences(yearsbefore)
        for segment in [&#39;HA&#39;, &#39;NA&#39;]:
            risks = pd.DataFrame()
            if segment == &#39;HA&#39;:
                TRUNC = HA_TRUNC
            elif segment == &#39;NA&#39;:
                TRUNC = NA_TRUNC
            human1 = human[human[&#39;segment&#39;] == segment]
            human1 = human1[human1[&#39;sequence&#39;].str.len() &gt;= TRUNC]
            subtypes = Counter(human1[segment])
            for subtype in subtypes:
                # Skip subtypes with less than 15 sequences
                if subtypes[subtype] &lt; 15:
                    continue                    
                # Use only unique sequences for inference
                df = human1[human1[segment] == subtype].drop_duplicates(subset=[&#39;sequence&#39;])
                # Sample from human sequences if needed
                if risk_sample_size is not None:
                    if isinstance(risk_sample_size, int):
                        sample_size = min(risk_sample_size, len(df))
                    elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                        sample_size = int(risk_sample_size * len(df))
                    df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                # Load Enet and compute risks
                enet = load_model(os.path.join(self.pretrained_enet_path, subtype + &#39;.joblib&#39;))
                df = self._compute_risks(segment, df, enet)
                if self.save_data is not None:
                    df.to_csv(os.path.join(self.save_data, subtype + &#39;.csv&#39;), index=False)
                # Save minimum risk for current subtype
                risks[subtype] = [np.min(df[&#39;risk&#39;])]
            # Save overall minimum risk
            if self.save_data is not None:
                risks.to_csv(os.path.join(self.save_data, segment + &#39;_min_risks.csv&#39;), index=False)
            if segment == &#39;HA&#39;:
                ha_risk = risks.min(axis=1).values[0] + 1e-5
            elif segment == &#39;NA&#39;:
                na_risk = risks.min(axis=1).values[0] + 1e-5
        return ha_risk, na_risk
    
    else:
        human = self._load_sequences(yearsbefore)
        for segment in [&#39;HA&#39;, &#39;NA&#39;]:
            risks = pd.DataFrame()
            if segment == &#39;HA&#39;:
                TRUNC = HA_TRUNC
            elif segment == &#39;NA&#39;:
                TRUNC = NA_TRUNC
            human1 = human[human[&#39;segment&#39;] == segment]
            human1 = human1[human1[&#39;sequence&#39;].str.len() &gt;= TRUNC]
            subtypes = Counter(human1[segment])
            for subtype in subtypes:
                # Skip subtypes with less than 15 sequences
                if subtypes[subtype] &lt; 15:
                    continue
                # Load human strains for constructing enet, sampling if needed
                df = human1[human1[segment] == subtype]
                if enet_sample_size is not None:
                    if isinstance(enet_sample_size, int):
                        sample_size = min(enet_sample_size, len(df))
                    elif isinstance(enet_sample_size, float) and enet_sample_size &lt;= 1:
                        sample_size = int(enet_sample_size * len(df))
                    df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                if self.save_data is not None:
                    df.to_csv(os.path.join(self.save_sequences, subtype + &#39;.csv&#39;), index=False)
                # Train Enet
                enet = self.train(segment, df)
                if self.save_data is not None:
                    save_model(enet, os.path.join(self.save_model, subtype + &#39;.joblib&#39;))
                # Use only unique sequences for inference
                df = df.drop_duplicates(subset=[&#39;sequence&#39;])
                # Sample from human sequences if needed (only if we did not already sample for training Enet)
                if risk_sample_size is not None and enet_sample_size is None:
                    if isinstance(risk_sample_size, int):
                        sample_size = min(risk_sample_size, len(df))
                    elif isinstance(risk_sample_size, float) and risk_sample_size &lt;= 1:
                        sample_size = int(risk_sample_size * len(df))
                    df = df.sample(n=sample_size, replace=False, random_state=self.random_state)
                # Compute risks
                df = self._compute_risks(segment, df, enet)
                if self.save_data is not None:
                    df.to_csv(os.path.join(self.save_results, subtype + &#39;.csv&#39;), index=False)
                # Save minimum risk for current subtype
                risks[subtype] = [np.min(df[&#39;risk&#39;])]
            # Save overall minimum risk
            if self.save_data is not None:
                risks.to_csv(os.path.join(self.save_results, segment + &#39;_min_risks.csv&#39;), index=False)
            if segment == &#39;HA&#39;:
                ha_risk = risks.min(axis=1).values[0] + 1e-5
            elif segment == &#39;NA&#39;:
                na_risk = risks.min(axis=1).values[0] + 1e-5
        return ha_risk, na_risk</code></pre>
</details>
</dd>
<dt id="emergenet.emergenet.Enet.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, segment: str, seq_df: pandas.core.frame.DataFrame, sample_size: int = None, include_target: bool = True, n_jobs: int = 1) ‑> quasinet.qnet.Qnet</span>
</code></dt>
<dd>
<div class="desc"><p>Trains an Emergenet model.</p>
<h2 id="parameters">Parameters</h2>
<p>segment - Either 'HA' or 'NA'</p>
<p>seq_df - DataFrame of sequences</p>
<p>sample_size - Number of sequences to train Emergenet on, sampled randomly</p>
<p>include_target - If true, includes target sequence</p>
<p>n_jobs - Number of CPUs to use when training</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>enet - Trained Emergenet</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, segment:str, seq_df:pd.DataFrame, sample_size:int=None, 
          include_target:bool=True, n_jobs:int=1) -&gt; Qnet:
    &#39;&#39;&#39; Trains an Emergenet model.

    Parameters
    ----------
    segment - Either &#39;HA&#39; or &#39;NA&#39;

    seq_df - DataFrame of sequences

    sample_size - Number of sequences to train Emergenet on, sampled randomly

    include_target - If true, includes target sequence

    n_jobs - Number of CPUs to use when training

    Returns
    -------
    enet - Trained Emergenet
    &#39;&#39;&#39; 
    if len(seq_df) &lt; 1:
        raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
    if segment not in [&#39;HA&#39;, &#39;NA&#39;]:
        raise ValueError(&#39;Segment must be either HA or NA!&#39;)
    if segment == &#39;HA&#39;:
        TRUNC = HA_TRUNC
    elif segment == &#39;NA&#39;:
        TRUNC = NA_TRUNC
    seq_arr = self._sequence_array(segment, seq_df, sample_size, include_target)
    enet = Qnet(feature_names=[&#39;x&#39; + str(i) for i in np.arange(TRUNC)],
                random_state=self.random_state, n_jobs=n_jobs)
    enet.fit(seq_arr)
    return enet</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<img src="logozed_nowhite.png" alt="drawing" style="width:200px;"/>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="emergenet" href="index.html">emergenet</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="emergenet.emergenet.predict_irat_emergence" href="#emergenet.emergenet.predict_irat_emergence">predict_irat_emergence</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="emergenet.emergenet.Enet" href="#emergenet.emergenet.Enet">Enet</a></code></h4>
<ul class="">
<li><code><a title="emergenet.emergenet.Enet.risk" href="#emergenet.emergenet.Enet.risk">risk</a></code></li>
<li><code><a title="emergenet.emergenet.Enet.train" href="#emergenet.emergenet.Enet.train">train</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
Author: <a href="https://zed.uchicago.edu"> Zero Knowledge Discovery Lab</a>. Email: ishanu.chattopadhyay@gmail.com
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>