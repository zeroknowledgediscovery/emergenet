<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>emergenet.domseq API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#666666;background-color:black;//mix-blend-mode:difference;color:#bbbbbb;z-index:3}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#66bb66;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#66FF66}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:transparent;padding:1px 4px;color:#FFA500;overflow-wrap:break-word}h1 code{background:transparent}pre{overflow-wrap:break-word;background:#111111;word-wrap:break-word;border:0;border-top:1px solid #666;border-bottom:1px solid #666;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#333333;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#aaeeaa;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;color:#bbbbbb;background-color:black;overflow-wrap:break-word}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>emergenet.domseq</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import numpy as np
import pandas as pd
from Bio import SeqIO
from Levenshtein import distance
from quasinet.qnet import Qnet, qdistance_matrix, save_qnet, load_qnet, membership_degree
from sklearn.cluster import MeanShift, estimate_bandwidth
from sklearn.manifold import MDS
from collections import Counter


class DomSeq(object):
    &#34;&#34;&#34;Find and predict dominant sequences.

    Parameters
    ----------
    seq_trunc_length : int
        Length to truncate sequences in Emergenet analysis
        (Sequences used to train Emergenet and compute E-distance must be of same length)

    random_state : int
        Sets seed for random number generator
    &#34;&#34;&#34;

    def __init__(self, seq_trunc_length, random_state=42):
        if seq_trunc_length &lt;= 0:
            raise ValueError(&#39;Length to truncate sequences must be positive!&#39;)
        self.seq_trunc_length = seq_trunc_length

        if random_state &lt; 0:
            raise ValueError(&#39;Seed must be between 0 and 2**32 - 1!&#39;)
        self.random_state = random_state

    def __repr__(self):
        return &#34;emergenet.DomSeq&#34;

    def __str__(self):
        return self.__repr__()
    
    @staticmethod
    def _count_seqs(filepath):
        &#34;&#34;&#34;Returns number of sequences in a fasta file.

        Parameters
        ----------
        filepath : str
            File name

        Returns
        -------
        seq_df : int
            Number of sequences
        &#34;&#34;&#34;
        with open(filepath, &#39;r&#39;) as f:
            fasta = SeqIO.parse(f, &#39;fasta&#39;)
            if not any(fasta):
                raise ValueError(&#39;The infile must be in fasta format!&#39;)
        with open(filepath, &#39;r&#39;) as f:
            lines = f.read()
        num_sequences = lines.count(&#39;&gt;&#39;)
        return num_sequences
    
    @staticmethod
    def _get_acc(ID):
        &#34;&#34;&#34;Returns accession code of a sequence.

        Parameters
        ----------
        ID : str
            Sequence metadata

        Returns
        -------
        acc : str
            Accession code
        &#34;&#34;&#34;
        ids = ID.split(&#39;|&#39;)
        # NCBI format
        if len(ids) == 3: 
            acc = ids[0]
            return acc
        # GISAID format
        else: 
            acc = ids[4]
            return acc

    @staticmethod
    def _get_name(ID):
        &#34;&#34;&#34;Returns name of a sequence.

        Parameters
        ----------
        ID : str
            Sequence metadata

        Returns
        -------
        name : str
            Name
        &#34;&#34;&#34;
        ids = ID.split(&#39;|&#39;)
        # NCBI format
        if len(ids) == 3: 
            name = &#39;&#39;
            start = False
            for c in ids[1]:
                if c == &#39;(&#39; and not start:
                    start = True
                elif c == &#39;(&#39; and start:
                    break
                elif start == True:
                    name += c
            return name
        # GISAID format
        else: 
            name = ids[0]
            return name
        
    @staticmethod
    def _get_date(ID):
        &#34;&#34;&#34;Returns collection date of a sequence.

        Parameters
        ----------
        ID : str
            Sequence metadata

        Returns
        -------
        date : str
            Collection date
        &#34;&#34;&#34;
        ids = ID.split(&#39;|&#39;)
        # NCBI format
        if len(ids) == 3: 
            date = ids[2]
            return date
        # GISAID format
        else:
            date = ids[3]
            return date
    
    @staticmethod
    def _dm_to_df(dm):
        &#34;&#34;&#34;Converts a distance matrix to a DataFrame.

        Parameters
        ----------
        dm : numpy.ndarray
            Distance matrix as 2D array

        Returns
        -------
        dm : pd.Dataframe
            Distance matrix as DataFrame
        &#34;&#34;&#34;
        columns = np.arange(0, dm.shape[1])
        index = np.arange(0, dm.shape[0])
        df = pd.DataFrame(dm, columns=columns, index=index)
        return df
    
    def _parse_fasta(self, filepath):
        &#34;&#34;&#34;Parses a fasta file and returns DataFrame with four columns.
        FASTA metadata must be in the format:
            NCBI: Accession | GenBank Title | Collection Date
            GISAID: Isolate name | Type | Segment | Collection date | Protein Accession no. | Protein INSDC
        `acc` contains sequence accession.
        `name` contains sequence name.
        `date` contains collection date.
        `sequence` contains sequences truncated to `seq_trunc_length`.

        Parameters
        ----------
        filepath : str
            File name

        Returns
        -------
        seq_df : pd.DataFrame
            DataFrame of sequences
        &#34;&#34;&#34;
        if self._count_seqs(filepath) == 0:
            raise ValueError(&#39;The file contains no sequences!&#39;)
        accs = []
        names = []
        dates = []
        seqs = []
        for record in SeqIO.parse(filepath, &#39;fasta&#39;):
            date = self._get_date(str(record.description))
            if len(record.seq) &lt; self.seq_trunc_length:
                continue
            if len(date) == 4:
                date += &#39;-09-25&#39;
            elif len(date) == 7:
                date += &#39;-15&#39;
            accs.append(self._get_acc(str(record.description)))
            names.append(self._get_name(str(record.description)))
            dates.append(date)
            seqs.append(&#39;&#39;.join(record.seq[:self.seq_trunc_length].upper()))
        seq_df = pd.DataFrame({&#39;acc&#39;:accs, &#39;name&#39;:names, &#39;date&#39;:dates, &#39;sequence&#39;:seqs})
        return seq_df

    def _sequence_array(self, seq_df, sample_size=None):
        &#34;&#34;&#34;Extracts array of sequence arrays from DataFrame; includes target sequence.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame containing sequences

        sample_size : int
            Number of strains to sample randomly

        Returns
        -------
        seq_lst: numpy.ndarray
            Array of sequence arrays
        &#34;&#34;&#34;
        if &#39;sequence&#39; not in seq_df.columns:
            raise ValueError(&#39;The DataFrame must store sequences in `sequence` column!&#39;)
        if sample_size is not None and sample_size &lt; len(seq_df):
            seq_df = seq_df.sample(sample_size, random_state=self.random_state)
        seqs = seq_df[&#39;sequence&#39;].apply(lambda x: np.array(list(x[:self.seq_trunc_length])))
        seq_lst = []
        for seq in seqs:
            seq_lst.append(seq)
        seq_lst = np.array(seq_lst)
        return seq_lst

    def load_data(self, filepath, outfile=None):
        &#34;&#34;&#34;Loads fasta file data and optionally saves to CSV.

        Parameters
        ----------
        filepath : str
            File name

        outfile : str
            File name to save to (&#39;.csv&#39;)

        Returns
        -------
        seq_df : pd.DataFrame
            DataFrame of sequences
        &#34;&#34;&#34;
        seq_df = self._parse_fasta(filepath)
        if outfile is not None:
            if not outfile.endswith(&#39;.csv&#39;):
                raise ValueError(&#39;The outfile must end with `.csv`!&#39;)
            seq_df.to_csv(outfile, index=False)
        return seq_df

    def train(self, seq_df, sample_size=None, n_jobs=1):
        &#34;&#34;&#34;Trains an Emergenet model.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of sequences

        sample_size : int
            Number of strains to train Emergenet on, sampled randomly

        n_jobs : int
            Number of CPUs to use when training

        Returns
        -------
        enet : Qnet
            Trained Emergenet
        &#34;&#34;&#34;
        if len(seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        seq_arr = self._sequence_array(seq_df, sample_size)
        enet = Qnet(feature_names=[&#39;x&#39; + str(i) for i in np.arange(self.seq_trunc_length)],
                    random_state=self.random_state, n_jobs=n_jobs)
        enet.fit(seq_arr)
        return enet
    
    def _compute_domseq_distance_matrix(self, seq_df):
        &#34;&#34;&#34;Computes distance matrix in the Levenshtein distance.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of sequences

        Returns
        -------
        dm : pd.DataFrame
            Distance Matrix
        &#34;&#34;&#34;
        if &#39;sequence&#39; not in seq_df.columns:
            raise ValueError(&#39;The DataFrame must store sequences in `sequence` column!&#39;)
        seqs = seq_df[&#39;sequence&#39;].values
        n = len(seqs)
        dist_matrix = np.zeros((n, n))
        for i in range(n):
            for j in range(i+1, n):
                dist_matrix[i, j] = distance(seqs[i][:self.seq_trunc_length], seqs[j][:self.seq_trunc_length])
        dist_matrix += dist_matrix.T
        dm = self._dm_to_df(dist_matrix)
        return dm
    
    def compute_domseq(self, seq_df, sample_size=None, save_data=None):
        &#34;&#34;&#34;Computes distance matrix in the Levenshtein distance.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of sequences
            
        sample_size : int
            Number of strains to sample randomly from seq_df
            
        save_data : string
            If directory is given, save the following files:
            1. seq_df.csv (post-sampling, if sample_size is given)
            2. dm.csv (the distance matrix corresponding to seq_df)

        Returns
        -------
        dom_seqs : pd.DataFrame
            Dominant sequences, with additional column for cluster sizes
        &#34;&#34;&#34;
        if len(seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        if sample_size is not None and sample_size &lt; len(seq_df):
            seq_df = seq_df.sample(sample_size, random_state=self.random_state)
        # distance matrix
        dm = self._compute_domseq_distance_matrix(seq_df)
        if save_data is not None and os.path.isdir(save_data):
            seq_df.to_csv(save_data+&#39;seq_df.csv&#39;, index=False)
            dm.to_csv(save_data+&#39;dm.csv&#39;, index=False)
        # clustering
        embedding = MDS(n_components=2, dissimilarity=&#34;precomputed&#34;, random_state=self.random_state)
        dm_embed = embedding.fit_transform(dm)
        bandwidth = estimate_bandwidth(dm_embed, quantile=0.3, random_state=self.random_state)
        clustering = MeanShift(bandwidth=bandwidth)
        clustering_predictions = clustering.fit_predict(dm_embed)
        unique_clusters = np.unique(clustering_predictions)
        # dominant sequences
        dom_seqs = pd.DataFrame(columns=seq_df.columns)
        cluster_sizes = []
        for class_ in unique_clusters:
            wanted_names = dm.columns[clustering_predictions == class_]
            # find the centroid in this cluster
            cluster_seq_df = seq_df.iloc[wanted_names]
            cluster_dm = dm.iloc[wanted_names, wanted_names]
            argmin = np.argmin(cluster_dm.sum(axis=&#39;columns&#39;).values)
            # save sequence
            dom_seqs = dom_seqs.append(cluster_seq_df.iloc[argmin])
            cluster_sizes.append(len(wanted_names))
        dom_seqs[&#39;cluster_size&#39;] = cluster_sizes
        return dom_seqs
    
    def _compute_risk_for_predict_domseq(self, seq_df, pred_seq_df, enet):
        &#34;&#34;&#34;Computes risk scores for potential prediction sequences.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of current population sequences
            
        pred_seq_df : pd.DataFrame
            DataFrame of candidate sequences

        enet : Qnet
            Emergenet that sequences in seq_df belong to

        Returns
        -------
        pred_seq_df : pd.DataFrame
            Potential prediction sequences, with additional columns for risk score

        &#34;&#34;&#34;
        # distance matrix for computing prediction
        seq_arr = self._sequence_array(seq_df)
        pred_seq_arr = self._sequence_array(pred_seq_df)
        dist_matrix = qdistance_matrix(pred_seq_arr, seq_arr, enet, enet) 
        # convert dist_matrix to dataframe
        dm = self._dm_to_df(dist_matrix)
        # find centroid data (sum across rows)
        first_term = dm.sum(axis=&#39;columns&#39;).values
        H = len(seq_df)
        A = 0.95/(np.sqrt(8) * self.seq_trunc_length**2)
        second_term = []
        for i in range(len(pred_seq_arr)):
            second_term.append(membership_degree(pred_seq_arr[i], enet) * H * A)
        sums = first_term - second_term
        pred_seq_df[&#39;first_term&#39;] = first_term
        pred_seq_df[&#39;second_term&#39;] = second_term
        pred_seq_df[&#39;sum&#39;] = sums
        pred_seq_df = pred_seq_df.sort_values(by=&#39;sum&#39;,ascending=True)
        return pred_seq_df
    
    def predict_domseq(self, seq_df, pred_seq_df, enet, n_clusters=3, sample_size=None, save_data=None):
        &#34;&#34;&#34;Predicts the future dominant sequence.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of current population sequences
            
        pred_seq_df : pd.DataFrame
            DataFrame of candidate sequences

        enet : Qnet
            Emergenet that sequences in seq_df belong to
            
        n_clusters : int
            Number of clusters to predict dominant strain on; default 3

        sample_size : int
            Number of strains to sample randomly from seq_df
            
        save_data : string
            If directory is given, save the following files:
            1. seq_df.csv (post-sampling, if sample_size is given)
            2. dm.csv (the distance matrix corresponding to seq_df)
            3. pred_seq_df_i.csv (pred_seq_df with additional columns for risk score, i = 1, 2, ... n_clusters)
            4. clusters.txt (clusters and cluster sizes)

        Returns
        -------
        pred_seqs : pd.DataFrame
            Emergenet recommended sequences, with additional column for cluster sizes

        &#34;&#34;&#34;
        if len(seq_df) &lt; 1 or len(pred_seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        if sample_size is not None and sample_size &lt; len(seq_df):
            seq_df = seq_df.sample(sample_size, random_state=self.random_state)
        # distance matrix for clustering strains from current season
        seq_arr = self._sequence_array(seq_df)
        dist_matrix = qdistance_matrix(seq_arr, seq_arr, enet, enet)
        dm = self._dm_to_df(dist_matrix)
        if save_data is not None and os.path.isdir(save_data):
            seq_df.to_csv(save_data+&#39;seq_df.csv&#39;, index=False)
            dm.to_csv(save_data+&#39;dm.csv&#39;, index=False)
        # clustering
        embedding = MDS(n_components=2, dissimilarity=&#34;precomputed&#34;, random_state=self.random_state)
        dm_embed = embedding.fit_transform(dm)
        bandwidth = estimate_bandwidth(dm_embed, quantile=0.3, random_state=self.random_state)
        clustering = MeanShift(bandwidth=bandwidth)
        clustering_predictions = clustering.fit_predict(dm_embed)
        # sort unique clusters by size
        label_counts = Counter(clustering_predictions)
        unique_clusters = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)
        if save_data is not None and os.path.isdir(save_data):
            with open(save_data + &#39;clusters.txt&#39;, &#39;w&#39;) as file:
                for item in unique_clusters:
                    file.write(str(item) + &#39;\n&#39;)
        # predictions
        pred_seqs = pd.DataFrame(columns=pred_seq_df.columns)
        cluster_sizes = []
        for class_ in unique_clusters[:n_clusters]:
            wanted_names = dm.columns[clustering_predictions == class_[0]]
            # take riskiest strain using this cluster
            cluster_seq_df = seq_df.iloc[wanted_names]
            pred_seq_df_with_risk = self._compute_risk_for_predict_domseq(cluster_seq_df, pred_seq_df, enet)
            if save_data is not None and os.path.isdir(save_data):
                pred_seq_df_with_risk.to_csv(save_data+&#39;pred_seq_df_&#39; + str(class_) + &#39;.csv&#39;, index=False)
            # save predictions
            pred_seqs = pred_seqs.append(pred_seq_df_with_risk.iloc[0])
            cluster_sizes.append(len(wanted_names))
        pred_seqs[&#39;cluster_size&#39;] = cluster_sizes
        return pred_seqs

def save_model(enet, outfile, low_mem=False):
    &#34;&#34;&#34;Saves an Emergenet model.

    Parameters
    ----------
    enet : Qnet
        An Emergenet instance

    outfile : str
        File name to save to (&#39;.joblib&#39;)

    low_mem : bool
        If True, save the Emergenet with low memory by deleting all data attributes except the tree structure

    Returns
    -------
    None
    &#34;&#34;&#34;
    save_qnet(enet, outfile, low_mem)
    
def load_model(filepath):
    &#34;&#34;&#34;Loads an Emergenet model.

    Parameters
    ----------
    filepath : str
        File name

    Returns
    -------
    enet : Qnet
        An Emergenet instance
    &#34;&#34;&#34;
    enet = load_qnet(filepath)
    return enet</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="emergenet.domseq.load_model"><code class="name flex">
<span>def <span class="ident">load_model</span></span>(<span>filepath)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads an Emergenet model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>File name</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>enet</code></strong> :&ensp;<code>Qnet</code></dt>
<dd>An Emergenet instance</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_model(filepath):
    &#34;&#34;&#34;Loads an Emergenet model.

    Parameters
    ----------
    filepath : str
        File name

    Returns
    -------
    enet : Qnet
        An Emergenet instance
    &#34;&#34;&#34;
    enet = load_qnet(filepath)
    return enet</code></pre>
</details>
</dd>
<dt id="emergenet.domseq.save_model"><code class="name flex">
<span>def <span class="ident">save_model</span></span>(<span>enet, outfile, low_mem=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Saves an Emergenet model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>enet</code></strong> :&ensp;<code>Qnet</code></dt>
<dd>An Emergenet instance</dd>
<dt><strong><code>outfile</code></strong> :&ensp;<code>str</code></dt>
<dd>File name to save to ('.joblib')</dd>
<dt><strong><code>low_mem</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, save the Emergenet with low memory by deleting all data attributes except the tree structure</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_model(enet, outfile, low_mem=False):
    &#34;&#34;&#34;Saves an Emergenet model.

    Parameters
    ----------
    enet : Qnet
        An Emergenet instance

    outfile : str
        File name to save to (&#39;.joblib&#39;)

    low_mem : bool
        If True, save the Emergenet with low memory by deleting all data attributes except the tree structure

    Returns
    -------
    None
    &#34;&#34;&#34;
    save_qnet(enet, outfile, low_mem)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="emergenet.domseq.DomSeq"><code class="flex name class">
<span>class <span class="ident">DomSeq</span></span>
<span>(</span><span>seq_trunc_length, random_state=42)</span>
</code></dt>
<dd>
<div class="desc"><p>Find and predict dominant sequences.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>seq_trunc_length</code></strong> :&ensp;<code>int</code></dt>
<dd>Length to truncate sequences in Emergenet analysis
(Sequences used to train Emergenet and compute E-distance must be of same length)</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code></dt>
<dd>Sets seed for random number generator</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DomSeq(object):
    &#34;&#34;&#34;Find and predict dominant sequences.

    Parameters
    ----------
    seq_trunc_length : int
        Length to truncate sequences in Emergenet analysis
        (Sequences used to train Emergenet and compute E-distance must be of same length)

    random_state : int
        Sets seed for random number generator
    &#34;&#34;&#34;

    def __init__(self, seq_trunc_length, random_state=42):
        if seq_trunc_length &lt;= 0:
            raise ValueError(&#39;Length to truncate sequences must be positive!&#39;)
        self.seq_trunc_length = seq_trunc_length

        if random_state &lt; 0:
            raise ValueError(&#39;Seed must be between 0 and 2**32 - 1!&#39;)
        self.random_state = random_state

    def __repr__(self):
        return &#34;emergenet.DomSeq&#34;

    def __str__(self):
        return self.__repr__()
    
    @staticmethod
    def _count_seqs(filepath):
        &#34;&#34;&#34;Returns number of sequences in a fasta file.

        Parameters
        ----------
        filepath : str
            File name

        Returns
        -------
        seq_df : int
            Number of sequences
        &#34;&#34;&#34;
        with open(filepath, &#39;r&#39;) as f:
            fasta = SeqIO.parse(f, &#39;fasta&#39;)
            if not any(fasta):
                raise ValueError(&#39;The infile must be in fasta format!&#39;)
        with open(filepath, &#39;r&#39;) as f:
            lines = f.read()
        num_sequences = lines.count(&#39;&gt;&#39;)
        return num_sequences
    
    @staticmethod
    def _get_acc(ID):
        &#34;&#34;&#34;Returns accession code of a sequence.

        Parameters
        ----------
        ID : str
            Sequence metadata

        Returns
        -------
        acc : str
            Accession code
        &#34;&#34;&#34;
        ids = ID.split(&#39;|&#39;)
        # NCBI format
        if len(ids) == 3: 
            acc = ids[0]
            return acc
        # GISAID format
        else: 
            acc = ids[4]
            return acc

    @staticmethod
    def _get_name(ID):
        &#34;&#34;&#34;Returns name of a sequence.

        Parameters
        ----------
        ID : str
            Sequence metadata

        Returns
        -------
        name : str
            Name
        &#34;&#34;&#34;
        ids = ID.split(&#39;|&#39;)
        # NCBI format
        if len(ids) == 3: 
            name = &#39;&#39;
            start = False
            for c in ids[1]:
                if c == &#39;(&#39; and not start:
                    start = True
                elif c == &#39;(&#39; and start:
                    break
                elif start == True:
                    name += c
            return name
        # GISAID format
        else: 
            name = ids[0]
            return name
        
    @staticmethod
    def _get_date(ID):
        &#34;&#34;&#34;Returns collection date of a sequence.

        Parameters
        ----------
        ID : str
            Sequence metadata

        Returns
        -------
        date : str
            Collection date
        &#34;&#34;&#34;
        ids = ID.split(&#39;|&#39;)
        # NCBI format
        if len(ids) == 3: 
            date = ids[2]
            return date
        # GISAID format
        else:
            date = ids[3]
            return date
    
    @staticmethod
    def _dm_to_df(dm):
        &#34;&#34;&#34;Converts a distance matrix to a DataFrame.

        Parameters
        ----------
        dm : numpy.ndarray
            Distance matrix as 2D array

        Returns
        -------
        dm : pd.Dataframe
            Distance matrix as DataFrame
        &#34;&#34;&#34;
        columns = np.arange(0, dm.shape[1])
        index = np.arange(0, dm.shape[0])
        df = pd.DataFrame(dm, columns=columns, index=index)
        return df
    
    def _parse_fasta(self, filepath):
        &#34;&#34;&#34;Parses a fasta file and returns DataFrame with four columns.
        FASTA metadata must be in the format:
            NCBI: Accession | GenBank Title | Collection Date
            GISAID: Isolate name | Type | Segment | Collection date | Protein Accession no. | Protein INSDC
        `acc` contains sequence accession.
        `name` contains sequence name.
        `date` contains collection date.
        `sequence` contains sequences truncated to `seq_trunc_length`.

        Parameters
        ----------
        filepath : str
            File name

        Returns
        -------
        seq_df : pd.DataFrame
            DataFrame of sequences
        &#34;&#34;&#34;
        if self._count_seqs(filepath) == 0:
            raise ValueError(&#39;The file contains no sequences!&#39;)
        accs = []
        names = []
        dates = []
        seqs = []
        for record in SeqIO.parse(filepath, &#39;fasta&#39;):
            date = self._get_date(str(record.description))
            if len(record.seq) &lt; self.seq_trunc_length:
                continue
            if len(date) == 4:
                date += &#39;-09-25&#39;
            elif len(date) == 7:
                date += &#39;-15&#39;
            accs.append(self._get_acc(str(record.description)))
            names.append(self._get_name(str(record.description)))
            dates.append(date)
            seqs.append(&#39;&#39;.join(record.seq[:self.seq_trunc_length].upper()))
        seq_df = pd.DataFrame({&#39;acc&#39;:accs, &#39;name&#39;:names, &#39;date&#39;:dates, &#39;sequence&#39;:seqs})
        return seq_df

    def _sequence_array(self, seq_df, sample_size=None):
        &#34;&#34;&#34;Extracts array of sequence arrays from DataFrame; includes target sequence.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame containing sequences

        sample_size : int
            Number of strains to sample randomly

        Returns
        -------
        seq_lst: numpy.ndarray
            Array of sequence arrays
        &#34;&#34;&#34;
        if &#39;sequence&#39; not in seq_df.columns:
            raise ValueError(&#39;The DataFrame must store sequences in `sequence` column!&#39;)
        if sample_size is not None and sample_size &lt; len(seq_df):
            seq_df = seq_df.sample(sample_size, random_state=self.random_state)
        seqs = seq_df[&#39;sequence&#39;].apply(lambda x: np.array(list(x[:self.seq_trunc_length])))
        seq_lst = []
        for seq in seqs:
            seq_lst.append(seq)
        seq_lst = np.array(seq_lst)
        return seq_lst

    def load_data(self, filepath, outfile=None):
        &#34;&#34;&#34;Loads fasta file data and optionally saves to CSV.

        Parameters
        ----------
        filepath : str
            File name

        outfile : str
            File name to save to (&#39;.csv&#39;)

        Returns
        -------
        seq_df : pd.DataFrame
            DataFrame of sequences
        &#34;&#34;&#34;
        seq_df = self._parse_fasta(filepath)
        if outfile is not None:
            if not outfile.endswith(&#39;.csv&#39;):
                raise ValueError(&#39;The outfile must end with `.csv`!&#39;)
            seq_df.to_csv(outfile, index=False)
        return seq_df

    def train(self, seq_df, sample_size=None, n_jobs=1):
        &#34;&#34;&#34;Trains an Emergenet model.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of sequences

        sample_size : int
            Number of strains to train Emergenet on, sampled randomly

        n_jobs : int
            Number of CPUs to use when training

        Returns
        -------
        enet : Qnet
            Trained Emergenet
        &#34;&#34;&#34;
        if len(seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        seq_arr = self._sequence_array(seq_df, sample_size)
        enet = Qnet(feature_names=[&#39;x&#39; + str(i) for i in np.arange(self.seq_trunc_length)],
                    random_state=self.random_state, n_jobs=n_jobs)
        enet.fit(seq_arr)
        return enet
    
    def _compute_domseq_distance_matrix(self, seq_df):
        &#34;&#34;&#34;Computes distance matrix in the Levenshtein distance.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of sequences

        Returns
        -------
        dm : pd.DataFrame
            Distance Matrix
        &#34;&#34;&#34;
        if &#39;sequence&#39; not in seq_df.columns:
            raise ValueError(&#39;The DataFrame must store sequences in `sequence` column!&#39;)
        seqs = seq_df[&#39;sequence&#39;].values
        n = len(seqs)
        dist_matrix = np.zeros((n, n))
        for i in range(n):
            for j in range(i+1, n):
                dist_matrix[i, j] = distance(seqs[i][:self.seq_trunc_length], seqs[j][:self.seq_trunc_length])
        dist_matrix += dist_matrix.T
        dm = self._dm_to_df(dist_matrix)
        return dm
    
    def compute_domseq(self, seq_df, sample_size=None, save_data=None):
        &#34;&#34;&#34;Computes distance matrix in the Levenshtein distance.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of sequences
            
        sample_size : int
            Number of strains to sample randomly from seq_df
            
        save_data : string
            If directory is given, save the following files:
            1. seq_df.csv (post-sampling, if sample_size is given)
            2. dm.csv (the distance matrix corresponding to seq_df)

        Returns
        -------
        dom_seqs : pd.DataFrame
            Dominant sequences, with additional column for cluster sizes
        &#34;&#34;&#34;
        if len(seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        if sample_size is not None and sample_size &lt; len(seq_df):
            seq_df = seq_df.sample(sample_size, random_state=self.random_state)
        # distance matrix
        dm = self._compute_domseq_distance_matrix(seq_df)
        if save_data is not None and os.path.isdir(save_data):
            seq_df.to_csv(save_data+&#39;seq_df.csv&#39;, index=False)
            dm.to_csv(save_data+&#39;dm.csv&#39;, index=False)
        # clustering
        embedding = MDS(n_components=2, dissimilarity=&#34;precomputed&#34;, random_state=self.random_state)
        dm_embed = embedding.fit_transform(dm)
        bandwidth = estimate_bandwidth(dm_embed, quantile=0.3, random_state=self.random_state)
        clustering = MeanShift(bandwidth=bandwidth)
        clustering_predictions = clustering.fit_predict(dm_embed)
        unique_clusters = np.unique(clustering_predictions)
        # dominant sequences
        dom_seqs = pd.DataFrame(columns=seq_df.columns)
        cluster_sizes = []
        for class_ in unique_clusters:
            wanted_names = dm.columns[clustering_predictions == class_]
            # find the centroid in this cluster
            cluster_seq_df = seq_df.iloc[wanted_names]
            cluster_dm = dm.iloc[wanted_names, wanted_names]
            argmin = np.argmin(cluster_dm.sum(axis=&#39;columns&#39;).values)
            # save sequence
            dom_seqs = dom_seqs.append(cluster_seq_df.iloc[argmin])
            cluster_sizes.append(len(wanted_names))
        dom_seqs[&#39;cluster_size&#39;] = cluster_sizes
        return dom_seqs
    
    def _compute_risk_for_predict_domseq(self, seq_df, pred_seq_df, enet):
        &#34;&#34;&#34;Computes risk scores for potential prediction sequences.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of current population sequences
            
        pred_seq_df : pd.DataFrame
            DataFrame of candidate sequences

        enet : Qnet
            Emergenet that sequences in seq_df belong to

        Returns
        -------
        pred_seq_df : pd.DataFrame
            Potential prediction sequences, with additional columns for risk score

        &#34;&#34;&#34;
        # distance matrix for computing prediction
        seq_arr = self._sequence_array(seq_df)
        pred_seq_arr = self._sequence_array(pred_seq_df)
        dist_matrix = qdistance_matrix(pred_seq_arr, seq_arr, enet, enet) 
        # convert dist_matrix to dataframe
        dm = self._dm_to_df(dist_matrix)
        # find centroid data (sum across rows)
        first_term = dm.sum(axis=&#39;columns&#39;).values
        H = len(seq_df)
        A = 0.95/(np.sqrt(8) * self.seq_trunc_length**2)
        second_term = []
        for i in range(len(pred_seq_arr)):
            second_term.append(membership_degree(pred_seq_arr[i], enet) * H * A)
        sums = first_term - second_term
        pred_seq_df[&#39;first_term&#39;] = first_term
        pred_seq_df[&#39;second_term&#39;] = second_term
        pred_seq_df[&#39;sum&#39;] = sums
        pred_seq_df = pred_seq_df.sort_values(by=&#39;sum&#39;,ascending=True)
        return pred_seq_df
    
    def predict_domseq(self, seq_df, pred_seq_df, enet, n_clusters=3, sample_size=None, save_data=None):
        &#34;&#34;&#34;Predicts the future dominant sequence.

        Parameters
        ----------
        seq_df : pd.DataFrame
            DataFrame of current population sequences
            
        pred_seq_df : pd.DataFrame
            DataFrame of candidate sequences

        enet : Qnet
            Emergenet that sequences in seq_df belong to
            
        n_clusters : int
            Number of clusters to predict dominant strain on; default 3

        sample_size : int
            Number of strains to sample randomly from seq_df
            
        save_data : string
            If directory is given, save the following files:
            1. seq_df.csv (post-sampling, if sample_size is given)
            2. dm.csv (the distance matrix corresponding to seq_df)
            3. pred_seq_df_i.csv (pred_seq_df with additional columns for risk score, i = 1, 2, ... n_clusters)
            4. clusters.txt (clusters and cluster sizes)

        Returns
        -------
        pred_seqs : pd.DataFrame
            Emergenet recommended sequences, with additional column for cluster sizes

        &#34;&#34;&#34;
        if len(seq_df) &lt; 1 or len(pred_seq_df) &lt; 1:
            raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
        if sample_size is not None and sample_size &lt; len(seq_df):
            seq_df = seq_df.sample(sample_size, random_state=self.random_state)
        # distance matrix for clustering strains from current season
        seq_arr = self._sequence_array(seq_df)
        dist_matrix = qdistance_matrix(seq_arr, seq_arr, enet, enet)
        dm = self._dm_to_df(dist_matrix)
        if save_data is not None and os.path.isdir(save_data):
            seq_df.to_csv(save_data+&#39;seq_df.csv&#39;, index=False)
            dm.to_csv(save_data+&#39;dm.csv&#39;, index=False)
        # clustering
        embedding = MDS(n_components=2, dissimilarity=&#34;precomputed&#34;, random_state=self.random_state)
        dm_embed = embedding.fit_transform(dm)
        bandwidth = estimate_bandwidth(dm_embed, quantile=0.3, random_state=self.random_state)
        clustering = MeanShift(bandwidth=bandwidth)
        clustering_predictions = clustering.fit_predict(dm_embed)
        # sort unique clusters by size
        label_counts = Counter(clustering_predictions)
        unique_clusters = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)
        if save_data is not None and os.path.isdir(save_data):
            with open(save_data + &#39;clusters.txt&#39;, &#39;w&#39;) as file:
                for item in unique_clusters:
                    file.write(str(item) + &#39;\n&#39;)
        # predictions
        pred_seqs = pd.DataFrame(columns=pred_seq_df.columns)
        cluster_sizes = []
        for class_ in unique_clusters[:n_clusters]:
            wanted_names = dm.columns[clustering_predictions == class_[0]]
            # take riskiest strain using this cluster
            cluster_seq_df = seq_df.iloc[wanted_names]
            pred_seq_df_with_risk = self._compute_risk_for_predict_domseq(cluster_seq_df, pred_seq_df, enet)
            if save_data is not None and os.path.isdir(save_data):
                pred_seq_df_with_risk.to_csv(save_data+&#39;pred_seq_df_&#39; + str(class_) + &#39;.csv&#39;, index=False)
            # save predictions
            pred_seqs = pred_seqs.append(pred_seq_df_with_risk.iloc[0])
            cluster_sizes.append(len(wanted_names))
        pred_seqs[&#39;cluster_size&#39;] = cluster_sizes
        return pred_seqs</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="emergenet.domseq.DomSeq.compute_domseq"><code class="name flex">
<span>def <span class="ident">compute_domseq</span></span>(<span>self, seq_df, sample_size=None, save_data=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes distance matrix in the Levenshtein distance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>seq_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>DataFrame of sequences</dd>
<dt><strong><code>sample_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of strains to sample randomly from seq_df</dd>
<dt><strong><code>save_data</code></strong> :&ensp;<code>string</code></dt>
<dd>If directory is given, save the following files:
1. seq_df.csv (post-sampling, if sample_size is given)
2. dm.csv (the distance matrix corresponding to seq_df)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dom_seqs</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Dominant sequences, with additional column for cluster sizes</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_domseq(self, seq_df, sample_size=None, save_data=None):
    &#34;&#34;&#34;Computes distance matrix in the Levenshtein distance.

    Parameters
    ----------
    seq_df : pd.DataFrame
        DataFrame of sequences
        
    sample_size : int
        Number of strains to sample randomly from seq_df
        
    save_data : string
        If directory is given, save the following files:
        1. seq_df.csv (post-sampling, if sample_size is given)
        2. dm.csv (the distance matrix corresponding to seq_df)

    Returns
    -------
    dom_seqs : pd.DataFrame
        Dominant sequences, with additional column for cluster sizes
    &#34;&#34;&#34;
    if len(seq_df) &lt; 1:
        raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
    if sample_size is not None and sample_size &lt; len(seq_df):
        seq_df = seq_df.sample(sample_size, random_state=self.random_state)
    # distance matrix
    dm = self._compute_domseq_distance_matrix(seq_df)
    if save_data is not None and os.path.isdir(save_data):
        seq_df.to_csv(save_data+&#39;seq_df.csv&#39;, index=False)
        dm.to_csv(save_data+&#39;dm.csv&#39;, index=False)
    # clustering
    embedding = MDS(n_components=2, dissimilarity=&#34;precomputed&#34;, random_state=self.random_state)
    dm_embed = embedding.fit_transform(dm)
    bandwidth = estimate_bandwidth(dm_embed, quantile=0.3, random_state=self.random_state)
    clustering = MeanShift(bandwidth=bandwidth)
    clustering_predictions = clustering.fit_predict(dm_embed)
    unique_clusters = np.unique(clustering_predictions)
    # dominant sequences
    dom_seqs = pd.DataFrame(columns=seq_df.columns)
    cluster_sizes = []
    for class_ in unique_clusters:
        wanted_names = dm.columns[clustering_predictions == class_]
        # find the centroid in this cluster
        cluster_seq_df = seq_df.iloc[wanted_names]
        cluster_dm = dm.iloc[wanted_names, wanted_names]
        argmin = np.argmin(cluster_dm.sum(axis=&#39;columns&#39;).values)
        # save sequence
        dom_seqs = dom_seqs.append(cluster_seq_df.iloc[argmin])
        cluster_sizes.append(len(wanted_names))
    dom_seqs[&#39;cluster_size&#39;] = cluster_sizes
    return dom_seqs</code></pre>
</details>
</dd>
<dt id="emergenet.domseq.DomSeq.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>self, filepath, outfile=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads fasta file data and optionally saves to CSV.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code></dt>
<dd>File name</dd>
<dt><strong><code>outfile</code></strong> :&ensp;<code>str</code></dt>
<dd>File name to save to ('.csv')</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>seq_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>DataFrame of sequences</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(self, filepath, outfile=None):
    &#34;&#34;&#34;Loads fasta file data and optionally saves to CSV.

    Parameters
    ----------
    filepath : str
        File name

    outfile : str
        File name to save to (&#39;.csv&#39;)

    Returns
    -------
    seq_df : pd.DataFrame
        DataFrame of sequences
    &#34;&#34;&#34;
    seq_df = self._parse_fasta(filepath)
    if outfile is not None:
        if not outfile.endswith(&#39;.csv&#39;):
            raise ValueError(&#39;The outfile must end with `.csv`!&#39;)
        seq_df.to_csv(outfile, index=False)
    return seq_df</code></pre>
</details>
</dd>
<dt id="emergenet.domseq.DomSeq.predict_domseq"><code class="name flex">
<span>def <span class="ident">predict_domseq</span></span>(<span>self, seq_df, pred_seq_df, enet, n_clusters=3, sample_size=None, save_data=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Predicts the future dominant sequence.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>seq_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>DataFrame of current population sequences</dd>
<dt><strong><code>pred_seq_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>DataFrame of candidate sequences</dd>
<dt><strong><code>enet</code></strong> :&ensp;<code>Qnet</code></dt>
<dd>Emergenet that sequences in seq_df belong to</dd>
<dt><strong><code>n_clusters</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of clusters to predict dominant strain on; default 3</dd>
<dt><strong><code>sample_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of strains to sample randomly from seq_df</dd>
<dt><strong><code>save_data</code></strong> :&ensp;<code>string</code></dt>
<dd>If directory is given, save the following files:
1. seq_df.csv (post-sampling, if sample_size is given)
2. dm.csv (the distance matrix corresponding to seq_df)
3. pred_seq_df_i.csv (pred_seq_df with additional columns for risk score, i = 1, 2, &hellip; n_clusters)
4. clusters.txt (clusters and cluster sizes)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>pred_seqs</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Emergenet recommended sequences, with additional column for cluster sizes</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict_domseq(self, seq_df, pred_seq_df, enet, n_clusters=3, sample_size=None, save_data=None):
    &#34;&#34;&#34;Predicts the future dominant sequence.

    Parameters
    ----------
    seq_df : pd.DataFrame
        DataFrame of current population sequences
        
    pred_seq_df : pd.DataFrame
        DataFrame of candidate sequences

    enet : Qnet
        Emergenet that sequences in seq_df belong to
        
    n_clusters : int
        Number of clusters to predict dominant strain on; default 3

    sample_size : int
        Number of strains to sample randomly from seq_df
        
    save_data : string
        If directory is given, save the following files:
        1. seq_df.csv (post-sampling, if sample_size is given)
        2. dm.csv (the distance matrix corresponding to seq_df)
        3. pred_seq_df_i.csv (pred_seq_df with additional columns for risk score, i = 1, 2, ... n_clusters)
        4. clusters.txt (clusters and cluster sizes)

    Returns
    -------
    pred_seqs : pd.DataFrame
        Emergenet recommended sequences, with additional column for cluster sizes

    &#34;&#34;&#34;
    if len(seq_df) &lt; 1 or len(pred_seq_df) &lt; 1:
        raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
    if sample_size is not None and sample_size &lt; len(seq_df):
        seq_df = seq_df.sample(sample_size, random_state=self.random_state)
    # distance matrix for clustering strains from current season
    seq_arr = self._sequence_array(seq_df)
    dist_matrix = qdistance_matrix(seq_arr, seq_arr, enet, enet)
    dm = self._dm_to_df(dist_matrix)
    if save_data is not None and os.path.isdir(save_data):
        seq_df.to_csv(save_data+&#39;seq_df.csv&#39;, index=False)
        dm.to_csv(save_data+&#39;dm.csv&#39;, index=False)
    # clustering
    embedding = MDS(n_components=2, dissimilarity=&#34;precomputed&#34;, random_state=self.random_state)
    dm_embed = embedding.fit_transform(dm)
    bandwidth = estimate_bandwidth(dm_embed, quantile=0.3, random_state=self.random_state)
    clustering = MeanShift(bandwidth=bandwidth)
    clustering_predictions = clustering.fit_predict(dm_embed)
    # sort unique clusters by size
    label_counts = Counter(clustering_predictions)
    unique_clusters = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)
    if save_data is not None and os.path.isdir(save_data):
        with open(save_data + &#39;clusters.txt&#39;, &#39;w&#39;) as file:
            for item in unique_clusters:
                file.write(str(item) + &#39;\n&#39;)
    # predictions
    pred_seqs = pd.DataFrame(columns=pred_seq_df.columns)
    cluster_sizes = []
    for class_ in unique_clusters[:n_clusters]:
        wanted_names = dm.columns[clustering_predictions == class_[0]]
        # take riskiest strain using this cluster
        cluster_seq_df = seq_df.iloc[wanted_names]
        pred_seq_df_with_risk = self._compute_risk_for_predict_domseq(cluster_seq_df, pred_seq_df, enet)
        if save_data is not None and os.path.isdir(save_data):
            pred_seq_df_with_risk.to_csv(save_data+&#39;pred_seq_df_&#39; + str(class_) + &#39;.csv&#39;, index=False)
        # save predictions
        pred_seqs = pred_seqs.append(pred_seq_df_with_risk.iloc[0])
        cluster_sizes.append(len(wanted_names))
    pred_seqs[&#39;cluster_size&#39;] = cluster_sizes
    return pred_seqs</code></pre>
</details>
</dd>
<dt id="emergenet.domseq.DomSeq.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, seq_df, sample_size=None, n_jobs=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Trains an Emergenet model.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>seq_df</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>DataFrame of sequences</dd>
<dt><strong><code>sample_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of strains to train Emergenet on, sampled randomly</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of CPUs to use when training</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>enet</code></strong> :&ensp;<code>Qnet</code></dt>
<dd>Trained Emergenet</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, seq_df, sample_size=None, n_jobs=1):
    &#34;&#34;&#34;Trains an Emergenet model.

    Parameters
    ----------
    seq_df : pd.DataFrame
        DataFrame of sequences

    sample_size : int
        Number of strains to train Emergenet on, sampled randomly

    n_jobs : int
        Number of CPUs to use when training

    Returns
    -------
    enet : Qnet
        Trained Emergenet
    &#34;&#34;&#34;
    if len(seq_df) &lt; 1:
        raise ValueError(&#39;The DataFrame contains no sequences!&#39;)
    seq_arr = self._sequence_array(seq_df, sample_size)
    enet = Qnet(feature_names=[&#39;x&#39; + str(i) for i in np.arange(self.seq_trunc_length)],
                random_state=self.random_state, n_jobs=n_jobs)
    enet.fit(seq_arr)
    return enet</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<img src="logozed_nowhite.png" alt="drawing" style="width:400px;"/>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="emergenet" href="index.html">emergenet</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="emergenet.domseq.load_model" href="#emergenet.domseq.load_model">load_model</a></code></li>
<li><code><a title="emergenet.domseq.save_model" href="#emergenet.domseq.save_model">save_model</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="emergenet.domseq.DomSeq" href="#emergenet.domseq.DomSeq">DomSeq</a></code></h4>
<ul class="">
<li><code><a title="emergenet.domseq.DomSeq.compute_domseq" href="#emergenet.domseq.DomSeq.compute_domseq">compute_domseq</a></code></li>
<li><code><a title="emergenet.domseq.DomSeq.load_data" href="#emergenet.domseq.DomSeq.load_data">load_data</a></code></li>
<li><code><a title="emergenet.domseq.DomSeq.predict_domseq" href="#emergenet.domseq.DomSeq.predict_domseq">predict_domseq</a></code></li>
<li><code><a title="emergenet.domseq.DomSeq.train" href="#emergenet.domseq.DomSeq.train">train</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
Author: <a href="https://zed.uchicago.edu"> Zero Knowledge Discovery, University of Chicago</a>. Email: ishanu@uchicago.edu
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>