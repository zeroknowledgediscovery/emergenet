{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from quasinet.qnet import qdistance, load_qnet\n",
    "from emergenet.domseq import DomSeq, save_model, load_model\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_PATH='../../paper_data_v2//irat_enet/enet_models/current_enets/h1n1_ha.joblib.gz'\n",
    "qnet__=load_qnet(Q_PATH,gz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mulpro\n",
    "import itertools\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../../paper_data_v2/irat_enet/results/animal_predictions/combined_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=df[df.subtype=='H1N1'][['ha_accession','ha','emergence_risk']].set_index('ha_accession').sort_values('emergence_risk')\n",
    "low_risk_seq=df_[df_.emergence_risk<6].ha.values\n",
    "high_risk_seq=df_[df_.emergence_risk>6.5].ha.values\n",
    "\n",
    "S0=[np.array(list(x)) for x in low_risk_seq]\n",
    "slow=pd.DataFrame(S0).mode().values[0]\n",
    "shigh=np.array([np.array(list(x)) for x in high_risk_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0__=slow\n",
    "def fpar(s):\n",
    "    return qdistance(s0__,s,qnet__,qnet__)\n",
    "def f(s_array):\n",
    "    pool = mulpro.Pool(processes=10)\n",
    "    return np.array(pool.map(fpar, s_array))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(f,np.array([slow]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_=np.array([x for x in shigh if np.random.rand()<.5 ])\n",
    "shap_values = explainer.shap_values(S_, nsamples=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp1=pd.DataFrame(pd.DataFrame(shap_values).abs().mean().sort_values(ascending=False),columns=['shp_h1n1'])\n",
    "shp1.index.name='H1N1_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_PATH='../../paper_data_v2//irat_enet/enet_models/current_enets/h3n2_ha.joblib.gz'\n",
    "qnet__=load_qnet(Q_PATH,gz=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=df[df.subtype=='H3N2'][['ha_accession','ha','emergence_risk']].set_index('ha_accession').sort_values('emergence_risk')\n",
    "low_risk_seq=df_[df_.emergence_risk<6].ha.values\n",
    "high_risk_seq=df_[df_.emergence_risk>6.5].ha.values\n",
    "\n",
    "S0=[np.array(list(x)) for x in low_risk_seq]\n",
    "slow=pd.DataFrame(S0).mode().values[0]\n",
    "shigh=np.array([np.array(list(x)) for x in high_risk_seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0__=slow\n",
    "def fpar(s):\n",
    "    return qdistance(s0__,s,qnet__,qnet__)\n",
    "def f(s_array):\n",
    "    pool = mulpro.Pool(processes=10)\n",
    "    return np.array(pool.map(fpar, s_array))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(f,np.array([slow]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_=np.array([x for x in shigh if np.random.rand()<.5 ])\n",
    "shap_values = explainer.shap_values(S_, nsamples=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp2=pd.DataFrame(pd.DataFrame(shap_values).abs().mean().sort_values(ascending=False),columns=['shp_h3n2'])\n",
    "shp2.index.name='H3N2_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp1.to_csv('lowhighrisk_H1N1.csv')\n",
    "shp2.to_csv('lowhighrisk_H3N2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=shp2.sort_index().ewm(alpha=.95).mean().plot(logy=False)\n",
    "shp1.sort_index().ewm(alpha=.95).mean().plot(logy=False,ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp1=pd.read_csv('lowhighrisk_H1N1.csv',index_col=0)\n",
    "shp2=pd.read_csv('lowhighrisk_H3N2.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=shp1.sort_index().ewm(alpha=.85).mean()\n",
    "s1=s1/s1.max()\n",
    "s2=shp2.sort_index().ewm(alpha=.85).mean()\n",
    "s2=s2/s2.max()\n",
    "ax=s2.plot(logy=False)\n",
    "#ax.set_ylim(0,0.005)\n",
    "s1.plot(logy=False,ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2[s2>0.05].dropna().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(s1[s1>0.05].dropna().index.values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(s1[s1.shp_h1n1.between(0.01,0.05)].dropna().index.values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls *SHAP*csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_n_h1n1=pd.read_csv('north_h1n1_ha_SHAP.csv',index_col=0)\n",
    "sf_n_h1n1=sf_n_h1n1.sort_index().ewm(alpha=.85).mean()\n",
    "sf_n_h1n1=sf_n_h1n1/sf_n_h1n1.max()\n",
    "sf_n_h1n1[sf_n_h1n1>0.03].dropna().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_n_h1n1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_s_h1n1=pd.read_csv('south_h1n1_ha_SHAP.csv',index_col=0)\n",
    "sf_s_h1n1=sf_s_h1n1.sort_index().ewm(alpha=.85).mean()\n",
    "sf_s_h1n1=sf_s_h1n1/sf_s_h1n1.max()\n",
    "sf_s_h1n1[sf_s_h1n1>0.03].dropna().index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_s_h1n1.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
