{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "valid-violence",
   "metadata": {},
   "source": [
    "# Influenza Qnet Predictions 2022-2023\n",
    "- Predicting dominant strain for the 2022-2023 flu season using Qnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "refined-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tqdm\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# other\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.manifold import MDS\n",
    "import Levenshtein as lev\n",
    "\n",
    "# qnet\n",
    "from quasinet.qnet import Qnet, qdistance, qdistance_matrix, membership_degree, save_qnet, load_qnet\n",
    "from quasinet.qseqtools import list_trained_qnets, load_trained_qnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-scheduling",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "- NCBI: https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Protein\n",
    "- GISAID: https://platform.epicov.org/epi3/cfrontend#586f5f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-cargo",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "**GISAID (NCBI has few strains for this season): For creating 2021-2022 Qnets:**\n",
    "1. Download amino acid data from both sources with the following filters:\n",
    "    - Host: Human\n",
    "    - Flu Season: \n",
    "        - Northern strains from 10/01/2021 - 5/01/2022\n",
    "        - Southern strains from 04/01/2021 - 10/1/2021\n",
    "        - Flu season dates from [CDC](https://www.cdc.gov/flu/school-business/travelersfacts.htm)\n",
    "    - Segment: HA (4) and NA (6)\n",
    "2. File names for raw data: HEMISPHERE_SEQUENCE_SEGMENT_SEASON\n",
    "    - HEMISPHERE: \"north\" or \"south\"\n",
    "    - SEQUENCE: \"h1n1\" or \"h3n2\"\n",
    "    - SEGMENT: \"ha\" or \"na\"\n",
    "    - SEASON: year the season begins in (ex. 21 for 2021-2022)\n",
    "    \n",
    "**NCBI (less duplicates): For finding centroid (need all strains):**\n",
    "1. Download amino acid data from both sources with the following filters:\n",
    "    - H1N1 HA: [Link](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Protein&VirusLineage_ss=H1N1%20subtype,%20taxid:114727&HostLineage_ss=Homo%20sapiens%20(human),%20taxid:9606&ProtNames_ss=hemagglutinin&LabHost_s=include&SLen_i=550%20TO%20600&QualNum_i=0&CollectionDate_dr=2000-01-01T00:00:00.00Z%20TO%202022-05-01T23:59:59.00Z)\n",
    "    - H1N1 NA: [Link](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Protein&VirusLineage_ss=H1N1%20subtype,%20taxid:114727&HostLineage_ss=Homo%20sapiens%20(human),%20taxid:9606&LabHost_s=include&QualNum_i=0&CollectionDate_dr=2000-01-01T00:00:00.00Z%20TO%202022-05-01T23:59:59.00Z&SLen_i=450%20TO%20500&ProtNames_ss=neuraminidase)\n",
    "    - H3N2 HA: [Link](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Protein&HostLineage_ss=Homo%20sapiens%20(human),%20taxid:9606&LabHost_s=include&QualNum_i=0&CollectionDate_dr=2000-01-01T00:00:00.00Z%20TO%202022-05-01T23:59:59.00Z&VirusLineage_ss=H3N2%20subtype,%20taxid:119210&SLen_i=550%20TO%20650&ProtNames_ss=hemagglutinin)\n",
    "    - H3N2 NA: [Link](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Protein&HostLineage_ss=Homo%20sapiens%20(human),%20taxid:9606&LabHost_s=include&QualNum_i=0&CollectionDate_dr=2000-01-01T00:00:00.00Z%20TO%202022-05-01T23:59:59.00Z&SLen_i=450%20TO%20500&ProtNames_ss=neuraminidase&VirusLineage_ss=H3N2%20subtype,%20taxid:119210)\n",
    "    \n",
    "2. File names for raw data: SEQUENCE_SEGMENT\n",
    "    - SEQUENCE: \"h1n1\" or \"h3n2\"\n",
    "    - SEGMENT: \"ha\" or \"na\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "willing-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCBI_PATH = 'raw_data/ncbi/'\n",
    "GISAID_PATH = 'raw_data/gisaid/'\n",
    "\n",
    "FILES = ['north_h1n1_ha_21', 'north_h1n1_na_21', 'north_h3n2_ha_21', 'north_h3n2_na_21',\n",
    "         'south_h1n1_ha_21', 'south_h1n1_na_21', 'south_h3n2_ha_21', 'south_h3n2_na_21']\n",
    "\n",
    "FILES_3CLUSTER = ['north_h1n1_na_21', 'north_h3n2_na_21',\n",
    "                  'south_h1n1_na_21', 'south_h3n2_na_21']\n",
    "\n",
    "NA_TRUNC = 469\n",
    "HA_TRUNC = 566"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-letters",
   "metadata": {},
   "source": [
    "## Creating New Qnet\n",
    "- FASTA Header: Isolate name | Type | Segment | Collection date\n",
    "- Truncate NA at 469 amino acids, HA at 566 amino acids\n",
    "- Create Qnet from previous season and hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "recent-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: fasta file name, length to truncate each sequence\n",
    "# output: dataframe of sequences\n",
    "def parse_fasta(file_name, trunc):\n",
    "    acc = []\n",
    "    seq = []\n",
    "    for record in SeqIO.parse(file_name, 'fasta'):\n",
    "        if len(record.seq) < trunc:\n",
    "            continue\n",
    "        acc.append(record.id.split('|')[0])\n",
    "        seq.append(np.array(record.seq[:trunc].upper()))\n",
    "    df = pd.DataFrame({'name':acc, 'sequence':seq})\n",
    "    return df\n",
    "\n",
    "\n",
    "# input: fasta file name, length to truncate each sequence\n",
    "# output: dataframe of sequences, including date as a column\n",
    "def parse_fasta_withdate(file_name, trunc):\n",
    "    acc = []\n",
    "    seq = []\n",
    "    dat = []\n",
    "    for record in SeqIO.parse(file_name, 'fasta'):\n",
    "        if len(record.seq) < trunc:\n",
    "            continue\n",
    "        acc.append(record.id)\n",
    "        dat.append(int(record.description.split('|')[2][:4]))\n",
    "        seq.append(np.array(record.seq[:trunc].upper()))\n",
    "    df = pd.DataFrame({'name':acc, 'sequence':seq, 'year':dat})\n",
    "    return df\n",
    "\n",
    "\n",
    "# input: dataframe of sequences, number of samples\n",
    "# output: array of nucleotide lists\n",
    "def sequence_array(seq_df, sample_size):\n",
    "    seqs = seq_df['sequence'].sample(sample_size, random_state = 42).values\n",
    "    seq_lst = []\n",
    "    for seq in seqs:\n",
    "        seq_lst.append(seq)\n",
    "    return np.array(seq_lst)\n",
    "\n",
    "\n",
    "# input: name to call qnet, array of nucleotide lists, number of nucleotides\n",
    "# output: save qnet as joblib\n",
    "def train_save_qnet(name, seq_arr, num_nuc):\n",
    "    myqnet = Qnet(feature_names=['x'+str(i) for i in np.arange(num_nuc)],n_jobs=1)\n",
    "    myqnet.fit(seq_arr)\n",
    "    save_qnet(myqnet, 'qnet_models/' + name + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qnets for each dataset\n",
    "for FILE in tqdm(FILES):\n",
    "    TRUNC = HA_TRUNC\n",
    "    if 'na' in FILE:\n",
    "        TRUNC = NA_TRUNC\n",
    "    seq_df = parse_fasta(GISAID_PATH + FILE + \".fasta\", TRUNC) \n",
    "    seq_arr = sequence_array(seq_df, min(1000, len(seq_df)))\n",
    "    train_save_qnet(FILE, seq_arr, TRUNC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e241b304",
   "metadata": {},
   "source": [
    "## Loading Past Qnet\n",
    "- Show possible Qnets with `list_trained_qnets()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "43d17013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: virus, protein, year\n",
    "# output: qnet \n",
    "def load_influenza_qnet(virus, protein, year):\n",
    "    myqnet = load_trained_qnet('influenza', virus + ';' + protein + ';' + str(year))\n",
    "    TRUNC = HA_TRUNC\n",
    "    if protein == 'na':\n",
    "        TRUNC = NA_TRUNC\n",
    "    # add feature names\n",
    "    myqnet.feature_names=['x'+str(i) for i in np.arange(TRUNC)]\n",
    "    return myqnet\n",
    "\n",
    "\n",
    "# input: list of available years, virus, protein\n",
    "# output: dict of qnets\n",
    "def make_qnet_dict(years, virus, protein):\n",
    "    qnet_dict = {}\n",
    "    for year in years:\n",
    "        qnet_dict[year] = load_influenza_qnet(virus, protein, year)\n",
    "    return qnet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "cfe5d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "H1N1_HA_YEARS = [2000, 2001, 2003, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "H1N1_NA_YEARS = [2000, 2001, 2003, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "H3N2_HA_YEARS = [2004, 2005, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "H3N2_NA_YEARS = [2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "\n",
    "# dict of qnets and years\n",
    "# qnet_dict['h1n1_na']['qnets'][year] accesses a qnet\n",
    "# qnet_dict['h1n1_na']['years'] accesses list of years available\n",
    "qnet_dict = {\n",
    "    'h1n1_ha':{'qnets':make_qnet_dict(H1N1_HA_YEARS, 'h1n1', 'ha'), 'years':H1N1_HA_YEARS},\n",
    "    'h1n1_na':{'qnets':make_qnet_dict(H1N1_NA_YEARS, 'h1n1', 'na'), 'years':H1N1_NA_YEARS},\n",
    "    'h3n2_ha':{'qnets':make_qnet_dict(H3N2_HA_YEARS, 'h3n2', 'ha'), 'years':H3N2_HA_YEARS},\n",
    "    'h3n2_na':{'qnets':make_qnet_dict(H3N2_NA_YEARS, 'h3n2', 'na'), 'years':H3N2_NA_YEARS}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205231a",
   "metadata": {},
   "source": [
    "## Create Dictionary of Sequence Data and Distance Matrices\n",
    "- `seq_dict[STRAIN]` contains a dataframe for strains of that variety `data` and the corresponding distance matrix `dist_matrix`\n",
    "- If combined north and south data for that strain exceeds 1000, randomly sample 1000 sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ba91462d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e995e4589e74bce8484b59f28e34e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_dict = {}\n",
    "\n",
    "for i in trange(len(FILES)):\n",
    "    FILE = FILES[i]\n",
    "    FILE1 = FILES[(i+4)%8]\n",
    "    NAME = FILE[6:13] # ex. 'h1n1_ha'\n",
    "    \n",
    "    # load this years qnet\n",
    "    myqnet = load_qnet('qnet_models/' + FILE + '.joblib')\n",
    "    \n",
    "    # adjust trunc\n",
    "    TRUNC = HA_TRUNC\n",
    "    if 'na' in FILE:\n",
    "        TRUNC = NA_TRUNC\n",
    "        \n",
    "    # load gisaid data (P^t - population at time t)\n",
    "    gisaid_df1 = parse_fasta(GISAID_PATH + FILE + \".fasta\", TRUNC)\n",
    "    gisaid_df2 = parse_fasta(GISAID_PATH + FILE1 + \".fasta\", TRUNC)\n",
    "    gisaid_df = pd.concat([gisaid_df1, gisaid_df2]).sample(min(1000, len(gisaid_df1) + len(gisaid_df2)), random_state = 42)\n",
    "    # make sequence matrix with gisaid data\n",
    "    seqs_matrix = np.array(list(gisaid_df['sequence'].values))\n",
    "    dist_matrix = qdistance_matrix(seqs_matrix, seqs_matrix, myqnet, myqnet)\n",
    "    \n",
    "    # save to dict\n",
    "    seq_dict[FILE] = {'data':gisaid_df, 'dist_matrix':dist_matrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9054f0",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Q-Centroid: $$\\widehat{x}^{t+1} = argmin_{x\\in P} \\sum_{y \\in P^t} \\theta(x,y)$$\n",
    "- Where $P^t$ is the sequence population at time $t$ and $P = P^t \\cup P^{t-1} \\cup P^{t-2} \\cup \\dots \\cup P^1$.\n",
    "- $\\theta(x,y)$ is the qdistance between x and y in their respective Qnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "89412cfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c547417a664e2b8013ad973e9c62f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rec_files = []\n",
    "rec_names = []\n",
    "rec_seqs = []\n",
    "\n",
    "# set to True to include sequences from P^t-1 U P^t-2 U ... U P^1 - previous populations\n",
    "PAST = False\n",
    "\n",
    "for FILE in tqdm(FILES):\n",
    "    NAME = FILE[6:13] # ex. 'h1n1_ha'\n",
    "    \n",
    "    # load this years qnet\n",
    "    myqnet = load_qnet('qnet_models/' + FILE + '.joblib')\n",
    "    \n",
    "    # adjust trunc\n",
    "    TRUNC = HA_TRUNC\n",
    "    if 'na' in FILE:\n",
    "        TRUNC = NA_TRUNC\n",
    "        \n",
    "    # load gisaid data (P^t - population at time t)\n",
    "    gisaid_df = seq_dict[FILE]['data']\n",
    "    # make sequence matrix with gisaid data\n",
    "    cur_seqs_matrix = np.array(list(gisaid_df['sequence'].values))\n",
    "    \n",
    "    cur_rec_names = []\n",
    "    cur_rec_seqs = []\n",
    "    cur_rec_qdist_sums = []\n",
    "    \n",
    "    # loop through available past data\n",
    "    if PAST:\n",
    "        # load ncbi data (P^t-1 U P^t-2 U ... U P^1 - previous populations)\n",
    "        ncbi_df = parse_fasta_withdate(NCBI_PATH + NAME + \".fasta\", TRUNC)\n",
    "        # loops through years with qnet available\n",
    "        for yr in tqdm(qnet_dict[NAME]['years']):\n",
    "            # filter ncbi df by year and drop the year column\n",
    "            df = ncbi_df[ncbi_df['year'] == yr].drop(columns = 'year')\n",
    "            if len(df) == 0:\n",
    "                continue\n",
    "            seq_df = df.sample(min(1000, len(df)), random_state = 42)\n",
    "\n",
    "            # compute qdistance matrix\n",
    "            past_seqs_matrix = np.array(list(seq_df['sequence'].values))\n",
    "            dist_matrix = qdistance_matrix(past_seqs_matrix, cur_seqs_matrix, qnet_dict[NAME]['qnets'][yr], myqnet)\n",
    "\n",
    "            # compute q-centroid using formula\n",
    "            sums = list(dist_matrix.sum(axis=1))\n",
    "            cur_min_ind = np.argmin(sums)\n",
    "            cur_rec_name = seq_df.iloc[cur_min_ind].values[0]\n",
    "            cur_rec_seq = seq_df.iloc[cur_min_ind].values[1]\n",
    "\n",
    "            # save to current results\n",
    "            cur_rec_names.append(cur_rec_name)\n",
    "            cur_rec_seqs.append(cur_rec_seq)\n",
    "            cur_rec_qdist_sums.append(min(sums))\n",
    "    \n",
    "    # find centroid of sequences in P^t\n",
    "    dist_matrix = seq_dict[FILE]['dist_matrix']\n",
    "    sums = list(dist_matrix.sum(axis=1))\n",
    "    cur_rec_names.append(gisaid_df.iloc[np.argmin(sums)].values[0])\n",
    "    cur_rec_seqs.append(gisaid_df.iloc[np.argmin(sums)].values[1])\n",
    "    cur_rec_qdist_sums.append(min(sums))\n",
    "    \n",
    "    # find centroid among current results\n",
    "    min_ind = np.argmin(cur_rec_qdist_sums)\n",
    "    rec_name = cur_rec_names[min_ind]\n",
    "    rec_seq = cur_rec_seqs[min_ind]\n",
    "    \n",
    "    # save results\n",
    "    rec_files.append(FILE[:13])\n",
    "    rec_names.append(rec_name)\n",
    "    rec_seqs.append(rec_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0ca636ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>north_h1n1_ha</td>\n",
       "      <td>A/Netherlands/00068/2022</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north_h1n1_na</td>\n",
       "      <td>A/Lyon/820/2021</td>\n",
       "      <td>MNPNQKIITIGSICMAIGTANLILQIGNIISIWVSHSIQIGNQSQI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>north_h3n2_ha</td>\n",
       "      <td>A/Denmark/370/2022</td>\n",
       "      <td>MKTIIALSNILCLVFAQKIPGNDNSTATLCLGHHAVPNGTIVKTIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>north_h3n2_na</td>\n",
       "      <td>A/Michigan/UOM10042819294/2021</td>\n",
       "      <td>MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>south_h1n1_ha</td>\n",
       "      <td>A/Cote_D'Ivoire/1270/2021</td>\n",
       "      <td>MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>south_h1n1_na</td>\n",
       "      <td>A/Dakar/35/2021</td>\n",
       "      <td>MNPNQKIITIGSICMAIGTANLILQIGNIISIWVSHSIQIGNQSQI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>south_h3n2_ha</td>\n",
       "      <td>A/Saint-Martin/00754/2022</td>\n",
       "      <td>MKTIIALSNILCLVFAQKIPGNDNSTATLCLGHHAVPNGTIVKTIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>south_h3n2_na</td>\n",
       "      <td>A/Texas/12723/2022</td>\n",
       "      <td>MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain                            name  \\\n",
       "0  north_h1n1_ha        A/Netherlands/00068/2022   \n",
       "1  north_h1n1_na                 A/Lyon/820/2021   \n",
       "2  north_h3n2_ha              A/Denmark/370/2022   \n",
       "3  north_h3n2_na  A/Michigan/UOM10042819294/2021   \n",
       "4  south_h1n1_ha       A/Cote_D'Ivoire/1270/2021   \n",
       "5  south_h1n1_na                 A/Dakar/35/2021   \n",
       "6  south_h3n2_ha       A/Saint-Martin/00754/2022   \n",
       "7  south_h3n2_na              A/Texas/12723/2022   \n",
       "\n",
       "                                            sequence  \n",
       "0  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...  \n",
       "1  MNPNQKIITIGSICMAIGTANLILQIGNIISIWVSHSIQIGNQSQI...  \n",
       "2  MKTIIALSNILCLVFAQKIPGNDNSTATLCLGHHAVPNGTIVKTIT...  \n",
       "3  MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...  \n",
       "4  MKAILVVLLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHS...  \n",
       "5  MNPNQKIITIGSICMAIGTANLILQIGNIISIWVSHSIQIGNQSQI...  \n",
       "6  MKTIIALSNILCLVFAQKIPGNDNSTATLCLGHHAVPNGTIVKTIT...  \n",
       "7  MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(rec_seqs)):\n",
    "    rec_seqs[i] = ''.join(rec_seqs[i])\n",
    "    \n",
    "predictions = pd.DataFrame({'strain':rec_files, 'name':rec_names, 'sequence':rec_seqs})\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2d8d90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe as csv\n",
    "os.makedirs('results', exist_ok=True)  \n",
    "predictions.to_csv('results/influenza_qnet_predictions_2022_2023.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924eedf",
   "metadata": {},
   "source": [
    "## Multi-Cluster Predictions\n",
    "- Compute distance matrix between sequences in $P^t$\n",
    "- Create three clusters, then find the dominant strain of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "10f423c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: dataframe of sequences, qdistance matrix, number of clusters\n",
    "# output: recommended names, corresponding sequences\n",
    "def multiple_cluster_predictions(seq_df, qdist_matrix, n_clusters = 3):\n",
    "    # convert qdist_matrix to dataframe\n",
    "    columns = np.arange(0, qdist_matrix.shape[1])\n",
    "    index = np.arange(0, qdist_matrix.shape[0])\n",
    "    dm = pd.DataFrame(qdist_matrix, columns=columns, index=index)\n",
    "        \n",
    "    # convert distance matrix to embedding\n",
    "    embedding = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
    "    dm_embed = embedding.fit_transform(dm)\n",
    "    \n",
    "    # cluster the distance matrix\n",
    "    clustering = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clustering_predictions = clustering.fit_predict(dm_embed)\n",
    "    \n",
    "    # find unique clusters\n",
    "    unique_clusters = np.unique(clustering_predictions)\n",
    "    \n",
    "    rec_names = []\n",
    "    rec_seqs = []\n",
    "    for class_ in unique_clusters:\n",
    "        # separate distance matrix into submatrices\n",
    "        wanted_names = dm.columns[clustering_predictions == class_]\n",
    "        sub_dist_matrix = dm.loc[wanted_names, wanted_names]\n",
    "        # find centroid\n",
    "        pred_ind = sub_dist_matrix.median(axis=1).idxmin()\n",
    "        rec_name = seq_df.iloc[int(pred_ind)].values[0]\n",
    "        rec_seq = seq_df.iloc[int(pred_ind)].values[1]\n",
    "        rec_names.append(rec_name)\n",
    "        rec_seqs.append(''.join(rec_seq))\n",
    "        \n",
    "    return rec_names, rec_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "be872d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124482465d5b49faa8012f2b754a2675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rec_files = []\n",
    "rec_names_0 = []\n",
    "rec_seqs_0 = []\n",
    "rec_names_1 = []\n",
    "rec_seqs_1 = []\n",
    "rec_names_2 = []\n",
    "rec_seqs_2 = []\n",
    "\n",
    "for FILE in tqdm(FILES_3CLUSTER):\n",
    "    # find centroid for each of 3 clusters\n",
    "    rec_names, rec_seqs = multiple_cluster_predictions(seq_dict[FILE]['data'], seq_dict[FILE]['dist_matrix'], 3)\n",
    "    rec_files.append(FILE[:13])\n",
    "    rec_names_0.append(rec_names[0])\n",
    "    rec_seqs_0.append(rec_seqs[0])\n",
    "    rec_names_1.append(rec_names[1])\n",
    "    rec_seqs_1.append(rec_seqs[1])\n",
    "    rec_names_2.append(rec_names[2])\n",
    "    rec_seqs_2.append(rec_seqs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e285437f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>name 0</th>\n",
       "      <th>sequence 0</th>\n",
       "      <th>name 1</th>\n",
       "      <th>sequence 1</th>\n",
       "      <th>name 2</th>\n",
       "      <th>sequence 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>north_h1n1_na</td>\n",
       "      <td>A/Netherlands/10646/2022</td>\n",
       "      <td>MNPNQKIITIGSICMAIGTANLILQIGNTISIWVSHSIQIGNQSQI...</td>\n",
       "      <td>A/Sydney/234/2022</td>\n",
       "      <td>MNPNQKIITIGSICMTIGTANLILQIGNMISIWVSHSIQIGNQSQI...</td>\n",
       "      <td>A/Wisconsin/03/2021</td>\n",
       "      <td>MNTNQRIITIGTVCLIVGIISLLLQIGNIVSLWVSHSIQTRWENHT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north_h3n2_na</td>\n",
       "      <td>A/Maine/02/2022</td>\n",
       "      <td>MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...</td>\n",
       "      <td>A/Michigan/UOM10042819294/2021</td>\n",
       "      <td>MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...</td>\n",
       "      <td>A/Netherlands/10082/2022</td>\n",
       "      <td>MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>south_h1n1_na</td>\n",
       "      <td>A/Switzerland/86136/2022</td>\n",
       "      <td>MNPNQKIITIGSICMAIGTANLILQIGNIISIWVSHSIQIGNQSQI...</td>\n",
       "      <td>A/Wisconsin/04/2021</td>\n",
       "      <td>MNTNQRIITIGTVCLIVGIISLLLQIGNIVSLWVSHSIQTKWENHT...</td>\n",
       "      <td>A/Wisconsin/05/2021</td>\n",
       "      <td>MNTNQRIITIGTVCLIVGIISLLLQIGNIVSLWVSHSIQTKWENHT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>south_h3n2_na</td>\n",
       "      <td>A/Congo/313/2021</td>\n",
       "      <td>MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNPPP...</td>\n",
       "      <td>A/Texas/12723/2022</td>\n",
       "      <td>MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...</td>\n",
       "      <td>A/Netherlands/00037/2022</td>\n",
       "      <td>MNPNQKIITIGSVSLTISTICFLMQIAILITTVTLHFKQYEFNSPX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain                    name 0  \\\n",
       "0  north_h1n1_na  A/Netherlands/10646/2022   \n",
       "1  north_h3n2_na           A/Maine/02/2022   \n",
       "2  south_h1n1_na  A/Switzerland/86136/2022   \n",
       "3  south_h3n2_na          A/Congo/313/2021   \n",
       "\n",
       "                                          sequence 0  \\\n",
       "0  MNPNQKIITIGSICMAIGTANLILQIGNTISIWVSHSIQIGNQSQI...   \n",
       "1  MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...   \n",
       "2  MNPNQKIITIGSICMAIGTANLILQIGNIISIWVSHSIQIGNQSQI...   \n",
       "3  MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNPPP...   \n",
       "\n",
       "                           name 1  \\\n",
       "0               A/Sydney/234/2022   \n",
       "1  A/Michigan/UOM10042819294/2021   \n",
       "2             A/Wisconsin/04/2021   \n",
       "3              A/Texas/12723/2022   \n",
       "\n",
       "                                          sequence 1  \\\n",
       "0  MNPNQKIITIGSICMTIGTANLILQIGNMISIWVSHSIQIGNQSQI...   \n",
       "1  MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...   \n",
       "2  MNTNQRIITIGTVCLIVGIISLLLQIGNIVSLWVSHSIQTKWENHT...   \n",
       "3  MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...   \n",
       "\n",
       "                     name 2                                         sequence 2  \n",
       "0       A/Wisconsin/03/2021  MNTNQRIITIGTVCLIVGIISLLLQIGNIVSLWVSHSIQTRWENHT...  \n",
       "1  A/Netherlands/10082/2022  MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPP...  \n",
       "2       A/Wisconsin/05/2021  MNTNQRIITIGTVCLIVGIISLLLQIGNIVSLWVSHSIQTKWENHT...  \n",
       "3  A/Netherlands/00037/2022  MNPNQKIITIGSVSLTISTICFLMQIAILITTVTLHFKQYEFNSPX...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_3cluster = pd.DataFrame({'strain':rec_files, \n",
    "                                     'name 0':rec_names_0, \n",
    "                                     'sequence 0':rec_seqs_0, \n",
    "                                     'name 1':rec_names_1, \n",
    "                                     'sequence 1':rec_seqs_1, \n",
    "                                     'name 2':rec_names_2, \n",
    "                                     'sequence 2':rec_seqs_2})\n",
    "predictions_3cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7fdc6190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe as csv\n",
    "os.makedirs('results', exist_ok=True)  \n",
    "predictions_3cluster.to_csv('results/influenza_qnet_predictions_3cluster_2022_2023.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7231e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
