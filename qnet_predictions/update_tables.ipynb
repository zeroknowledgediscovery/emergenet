{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e61463",
   "metadata": {},
   "source": [
    "# Results\n",
    "- See `results/influenza_qnet_predictions_YEAR.csv` and `results/dominant_sequences_YEAR.csv`\n",
    "- Save to DataFrames located in `tables` directory\n",
    "- See this [link](https://www.fludb.org/brc/vaccineRecommend.spg?decorator=influenza#:~:text=From%20these%20data%2C%20the%20WHO,recommendation%20are%20also%20usually%20suggested.) for WHO recommendations and this [link](https://platform.epicov.org/epi3/frontend#507f8c) to search the sequences\n",
    "- Tables 4 - 15 in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d925e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from Bio import SeqIO\n",
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "808d7da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCBI_PATH = 'raw_data/ncbi/'\n",
    "GISAID_PATH = 'raw_data/gisaid/'\n",
    "\n",
    "\n",
    "FILES = ['north_h1n1_ha', 'north_h1n1_na', 'north_h3n2_ha', 'north_h3n2_na',\n",
    "         'south_h1n1_ha', 'south_h1n1_na', 'south_h3n2_ha', 'south_h3n2_na']\n",
    "table_dict = {}\n",
    "for FILE in FILES:\n",
    "    table_dict[FILE] = pd.read_csv('tables/' + FILE + '.csv')\n",
    "\n",
    "\n",
    "FILES_3CLUSTER = ['north_h1n1_na', 'north_h3n2_na',\n",
    "                  'south_h1n1_na', 'south_h3n2_na']\n",
    "table_dict_3cluster = {}\n",
    "for FILE in FILES_3CLUSTER:\n",
    "    table_dict_3cluster[FILE] = pd.read_csv('tables/' + FILE + '_3cluster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "15a00002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: results table\n",
    "# output: updated table with blank row\n",
    "def add_new_row(df, year, multi_cluster = False):\n",
    "    if len(df.loc[df['year'] == year]) == 0:\n",
    "        if not multi_cluster:\n",
    "            df.loc[df.shape[0]] = [year] + (df.shape[1] - 1) * [-1]\n",
    "        else:\n",
    "            df.loc[df.shape[0]] = (df.shape[1] - 1) * [-1] + [year]\n",
    "\n",
    "        \n",
    "# input: results table, name of strain, year\n",
    "# output: updated table with dominant sequence\n",
    "def add_dominant_sequence(df, name, year):\n",
    "    dom_df = pd.read_csv('results/dominant_sequences_' + year + '.csv')\n",
    "    dom_row = dom_df.loc[dom_df['strain'] == name]\n",
    "    dom_name = dom_row['name'].values[0]\n",
    "    dom_seq = dom_row['sequence'].values[0]\n",
    "    df.loc[df['year'] == year, ['dominant_strain_accession_name']] = dom_name\n",
    "    df.loc[df['year'] == year, ['dominant_strain_sequence']] = dom_seq\n",
    "    \n",
    "\n",
    "# input: results table, name of strain, year\n",
    "# output: updated table with qnet predicted sequence\n",
    "def add_predicted_sequence(df, name, year, multi_cluster = False):\n",
    "    if not multi_cluster:\n",
    "        pred_df = pd.read_csv('results/influenza_qnet_predictions_' + year + '.csv')\n",
    "        pred_row = pred_df.loc[pred_df['strain'] == name]\n",
    "        pred_name = pred_row['name'].values[0]\n",
    "        pred_seq = pred_row['sequence'].values[0]\n",
    "        df.loc[df['year'] == year, ['qdistance_recommendation_accession_name']] = pred_name\n",
    "        df.loc[df['year'] == year, ['qdistance_recommendation_sequence']] = pred_seq\n",
    "    else:\n",
    "        pred_df = pd.read_csv('results/influenza_qnet_predictions_3cluster_' + year + '.csv')\n",
    "        pred_row = pred_df.loc[pred_df['strain'] == name]\n",
    "        pred_name_0 = pred_row['name 0'].values[0]\n",
    "        pred_name_1 = pred_row['name 1'].values[0]\n",
    "        pred_name_2 = pred_row['name 2'].values[0]\n",
    "        pred_seq_0 = pred_row['sequence 0'].values[0]\n",
    "        pred_seq_1 = pred_row['sequence 1'].values[0]\n",
    "        pred_seq_2 = pred_row['sequence 2'].values[0]\n",
    "        df.loc[df['year'] == year, ['qdistance_recommendation_accession_name_0']] = pred_name_0\n",
    "        df.loc[df['year'] == year, ['qdistance_recommendation_accession_name_1']] = pred_name_1\n",
    "        df.loc[df['year'] == year, ['qdistance_recommendation_accession_name_2']] = pred_name_2\n",
    "        df.loc[df['year'] == year, ['qdistance_recommendation_sequence_0']] = pred_seq_0\n",
    "        df.loc[df['year'] == year, ['qdistance_recommendation_sequence_1']] = pred_seq_1\n",
    "        df.loc[df['year'] == year, ['qdistance_recommendation_sequence_2']] = pred_seq_2\n",
    "    \n",
    "    \n",
    "# input: results table, name of strain, year\n",
    "# output: updated table with who and qnet errors\n",
    "def add_who_qnet_errors(df, year, multi_cluster = False):\n",
    "    if not multi_cluster:\n",
    "        dom_seq = df.loc[df['year'] == year]['dominant_strain_sequence'].values[0]\n",
    "        who_seq = df.loc[df['year'] == year]['WHO_recommendation_sequence'].values[0]\n",
    "        qnet_seq = df.loc[df['year'] == year]['qdistance_recommendation_sequence'].values[0]\n",
    "        trunc = min(len(dom_seq), len(qnet_seq), len(who_seq))\n",
    "        who_error = lev.distance(dom_seq[:trunc], who_seq[:trunc])\n",
    "        qnet_error = lev.distance(dom_seq[:trunc], qnet_seq[:trunc])\n",
    "        df.loc[df['year'] == year, ['ldistance_WHO']] = who_error\n",
    "        df.loc[df['year'] == year, ['ldistance_Qnet_recommendation']] = qnet_error\n",
    "    else:\n",
    "        dom_seq = df.loc[df['year'] == year]['dominant_strain_sequence'].values[0]\n",
    "        who_seq = df.loc[df['year'] == year]['WHO_recommendation_sequence'].values[0]\n",
    "        qnet_seq_0 = df.loc[df['year'] == year]['qdistance_recommendation_sequence_0'].values[0]\n",
    "        qnet_seq_1 = df.loc[df['year'] == year]['qdistance_recommendation_sequence_1'].values[0]\n",
    "        qnet_seq_2 = df.loc[df['year'] == year]['qdistance_recommendation_sequence_2'].values[0]\n",
    "        trunc = min(len(dom_seq), len(qnet_seq_0), len(qnet_seq_1), len(qnet_seq_2), len(who_seq))\n",
    "        who_error = lev.distance(dom_seq[:trunc], who_seq[:trunc])\n",
    "        qnet_error_0 = lev.distance(dom_seq[:trunc], qnet_seq_0[:trunc])\n",
    "        qnet_error_1 = lev.distance(dom_seq[:trunc], qnet_seq_1[:trunc])\n",
    "        qnet_error_2 = lev.distance(dom_seq[:trunc], qnet_seq_2[:trunc])\n",
    "        df.loc[df['year'] == year, ['ldistance_WHO']] = who_error\n",
    "        df.loc[df['year'] == year, ['ldistance_Qnet_recommendation_0']] = qnet_error_0\n",
    "        df.loc[df['year'] == year, ['ldistance_Qnet_recommendation_1']] = qnet_error_1\n",
    "        df.loc[df['year'] == year, ['ldistance_Qnet_recommendation_2']] = qnet_error_2\n",
    "    \n",
    "    \n",
    "# input: results table, name of strain, year\n",
    "# output: updated table with qnet sample size\n",
    "def add_qnet_sample_size(df, name, year):\n",
    "    DIR = GISAID_PATH + name + '_' + str(int(year[2:4]) - 1) + '.fasta'\n",
    "    data = SeqIO.parse(DIR, 'fasta')\n",
    "    length = 0\n",
    "    for record in data:\n",
    "        length += 1\n",
    "    df.loc[df['year'] == year, ['qnet_sample_size']] = min(1000, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1649a28",
   "metadata": {},
   "source": [
    "## 2020-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-window",
   "metadata": {},
   "source": [
    "### Single Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fd46c2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>who</th>\n",
       "      <th>dominant</th>\n",
       "      <th>qnet</th>\n",
       "      <th>who err</th>\n",
       "      <th>qnet err</th>\n",
       "      <th>qnet sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>north_h1n1_ha</td>\n",
       "      <td>A/Hawaii/70/2019</td>\n",
       "      <td>A/Togo/905/2020</td>\n",
       "      <td>A/Italy/8949/2019</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north_h1n1_na</td>\n",
       "      <td>A/Hawaii/70/2019</td>\n",
       "      <td>A/Ghana/119/2020</td>\n",
       "      <td>A/Texas/112/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>north_h3n2_ha</td>\n",
       "      <td>A/Hong Kong/2671/2019</td>\n",
       "      <td>A/India/Pun-NIV300460/2021_Apr</td>\n",
       "      <td>A/California/NHRC-OID_FDX100215/2019</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>north_h3n2_na</td>\n",
       "      <td>A/Hong Kong/2671/2019</td>\n",
       "      <td>A/Kenya/122/2021</td>\n",
       "      <td>A/Maryland/02/2019</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>south_h1n1_ha</td>\n",
       "      <td>A/Brisbane/02/2018</td>\n",
       "      <td>A/Cote_d'Ivoire/951/2020</td>\n",
       "      <td>A/Italy/8451/2019</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>south_h1n1_na</td>\n",
       "      <td>A/Brisbane/02/2018</td>\n",
       "      <td>A/Srinagar/AG_659/2020</td>\n",
       "      <td>A/Texas/7939/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>south_h3n2_ha</td>\n",
       "      <td>A/South Australia/34/2019</td>\n",
       "      <td>A/Timor-Leste/2/2020</td>\n",
       "      <td>A/Kentucky/27/2019</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>south_h3n2_na</td>\n",
       "      <td>A/South Australia/34/2019</td>\n",
       "      <td>A/Bangladesh/3009/2020</td>\n",
       "      <td>A/Washington/9757/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain                        who                        dominant  \\\n",
       "0  north_h1n1_ha           A/Hawaii/70/2019                 A/Togo/905/2020   \n",
       "1  north_h1n1_na           A/Hawaii/70/2019                A/Ghana/119/2020   \n",
       "2  north_h3n2_ha      A/Hong Kong/2671/2019  A/India/Pun-NIV300460/2021_Apr   \n",
       "3  north_h3n2_na      A/Hong Kong/2671/2019                A/Kenya/122/2021   \n",
       "4  south_h1n1_ha         A/Brisbane/02/2018        A/Cote_d'Ivoire/951/2020   \n",
       "5  south_h1n1_na         A/Brisbane/02/2018          A/Srinagar/AG_659/2020   \n",
       "6  south_h3n2_ha  A/South Australia/34/2019            A/Timor-Leste/2/2020   \n",
       "7  south_h3n2_na  A/South Australia/34/2019          A/Bangladesh/3009/2020   \n",
       "\n",
       "                                   qnet  who err  qnet err  qnet sample  \n",
       "0                     A/Italy/8949/2019        4         8           -1  \n",
       "1                      A/Texas/112/2019        0         5           -1  \n",
       "2  A/California/NHRC-OID_FDX100215/2019       16        14           -1  \n",
       "3                    A/Maryland/02/2019        3        13           -1  \n",
       "4                     A/Italy/8451/2019        8         6           -1  \n",
       "5                     A/Texas/7939/2019        5         4           -1  \n",
       "6                    A/Kentucky/27/2019        9        11           -1  \n",
       "7                A/Washington/9757/2019        1        13           -1  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YEAR = '2020_2021'\n",
    "\n",
    "who_seqs = []\n",
    "dom_seqs = []\n",
    "pred_seqs = []\n",
    "who_errs = []\n",
    "qnet_errs = []\n",
    "qnet_sample_size = []\n",
    "\n",
    "for FILE in FILES:\n",
    "    df = table_dict[FILE]\n",
    "    add_new_row(df, YEAR)\n",
    "    add_dominant_sequence(df, FILE, YEAR)\n",
    "    # add_predicted_sequence(df, FILE, YEAR)\n",
    "    add_who_qnet_errors(df, YEAR)\n",
    "    # add_qnet_sample_size(df, FILE, YEAR)\n",
    "    # items to display\n",
    "    who_seqs.append(df.loc[df['year'] == YEAR]['WHO_recommendation_name'].values[0])\n",
    "    dom_seqs.append(df.loc[df['year'] == YEAR]['dominant_strain_accession_name'].values[0])\n",
    "    pred_seqs.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name'].values[0])\n",
    "    who_errs.append(df.loc[df['year'] == YEAR]['ldistance_WHO'].values[0])\n",
    "    qnet_errs.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation'].values[0])\n",
    "    qnet_sample_size.append(df.loc[df['year'] == YEAR]['qnet_sample_size'].values[0])\n",
    "    \n",
    "pd.DataFrame({'strain':FILES, \n",
    "              'who':who_seqs, \n",
    "              'dominant':dom_seqs, \n",
    "              'qnet':pred_seqs,\n",
    "              'who err':who_errs,\n",
    "              'qnet err':qnet_errs,\n",
    "              'qnet sample':qnet_sample_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-green",
   "metadata": {},
   "source": [
    "### Multi-Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "sexual-copper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>who</th>\n",
       "      <th>dominant</th>\n",
       "      <th>qnet 0</th>\n",
       "      <th>qnet 1</th>\n",
       "      <th>qnet 2</th>\n",
       "      <th>who err</th>\n",
       "      <th>qnet err 0</th>\n",
       "      <th>qnet err 1</th>\n",
       "      <th>qnet err 2</th>\n",
       "      <th>qnet sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>north_h1n1_na</td>\n",
       "      <td>A/Hawaii/70/2019</td>\n",
       "      <td>A/Ghana/119/2020</td>\n",
       "      <td>A/California/NHRC-OID_BOX-ILI-0012/2019</td>\n",
       "      <td>A/Indiana/30/2019</td>\n",
       "      <td>A/Germany/9488/2019</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north_h3n2_na</td>\n",
       "      <td>A/Hong Kong/2671/2019</td>\n",
       "      <td>A/Kenya/122/2021</td>\n",
       "      <td>A/England/9738/2019</td>\n",
       "      <td>A/Washington/9757/2019</td>\n",
       "      <td>A/Minnesota/06/2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>south_h1n1_na</td>\n",
       "      <td>A/Brisbane/02/2018</td>\n",
       "      <td>A/Srinagar/AG_659/2020</td>\n",
       "      <td>A/California/NHRC-OID_BOX-ILI-0012/2019</td>\n",
       "      <td>A/Indiana/30/2019</td>\n",
       "      <td>A/Germany/9488/2019</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>south_h3n2_na</td>\n",
       "      <td>A/South Australia/34/2019</td>\n",
       "      <td>A/Bangladesh/3009/2020</td>\n",
       "      <td>A/England/9738/2019</td>\n",
       "      <td>A/Washington/9757/2019</td>\n",
       "      <td>A/Minnesota/06/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain                        who                dominant  \\\n",
       "0  north_h1n1_na           A/Hawaii/70/2019        A/Ghana/119/2020   \n",
       "1  north_h3n2_na      A/Hong Kong/2671/2019        A/Kenya/122/2021   \n",
       "2  south_h1n1_na         A/Brisbane/02/2018  A/Srinagar/AG_659/2020   \n",
       "3  south_h3n2_na  A/South Australia/34/2019  A/Bangladesh/3009/2020   \n",
       "\n",
       "                                    qnet 0                  qnet 1  \\\n",
       "0  A/California/NHRC-OID_BOX-ILI-0012/2019       A/Indiana/30/2019   \n",
       "1                      A/England/9738/2019  A/Washington/9757/2019   \n",
       "2  A/California/NHRC-OID_BOX-ILI-0012/2019       A/Indiana/30/2019   \n",
       "3                      A/England/9738/2019  A/Washington/9757/2019   \n",
       "\n",
       "                qnet 2  who err  qnet err 0  qnet err 1  qnet err 2  \\\n",
       "0  A/Germany/9488/2019        0           3           8           4   \n",
       "1  A/Minnesota/06/2019        3           1          13           9   \n",
       "2  A/Germany/9488/2019        5           2           7           3   \n",
       "3  A/Minnesota/06/2019        1           1          13           9   \n",
       "\n",
       "   qnet sample  \n",
       "0           -1  \n",
       "1           -1  \n",
       "2           -1  \n",
       "3           -1  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_seqs = []\n",
    "dom_seqs = []\n",
    "pred_seqs_0 = []\n",
    "pred_seqs_1 = []\n",
    "pred_seqs_2 = []\n",
    "who_errs = []\n",
    "qnet_errs_0 = []\n",
    "qnet_errs_1 = []\n",
    "qnet_errs_2 = []\n",
    "qnet_sample_size = []\n",
    "\n",
    "for FILE in FILES_3CLUSTER:\n",
    "    df = table_dict_3cluster[FILE]\n",
    "    add_new_row(df, YEAR, multi_cluster=True)\n",
    "    add_dominant_sequence(df, FILE[:13], YEAR)\n",
    "    # add_predicted_sequence(df, FILE, YEAR, multi_cluster=True)\n",
    "    add_who_qnet_errors(df, YEAR, multi_cluster=True)\n",
    "    # add_qnet_sample_size(df, FILE[:13], YEAR)\n",
    "    # items to display\n",
    "    who_seqs.append(df.loc[df['year'] == YEAR]['WHO_recommendation_name'].values[0])\n",
    "    dom_seqs.append(df.loc[df['year'] == YEAR]['dominant_strain_accession_name'].values[0])\n",
    "    pred_seqs_0.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_0'].values[0])\n",
    "    pred_seqs_1.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_1'].values[0])\n",
    "    pred_seqs_2.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_2'].values[0])\n",
    "    who_errs.append(df.loc[df['year'] == YEAR]['ldistance_WHO'].values[0])\n",
    "    qnet_errs_0.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_0'].values[0])\n",
    "    qnet_errs_1.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_1'].values[0])\n",
    "    qnet_errs_2.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_2'].values[0])\n",
    "    qnet_sample_size.append(df.loc[df['year'] == YEAR]['qnet_sample_size'].values[0])\n",
    "    \n",
    "pd.DataFrame({'strain':FILES_3CLUSTER, \n",
    "              'who':who_seqs, \n",
    "              'dominant':dom_seqs, \n",
    "              'qnet 0':pred_seqs_0,\n",
    "              'qnet 1':pred_seqs_1,\n",
    "              'qnet 2':pred_seqs_2,\n",
    "              'who err':who_errs,\n",
    "              'qnet err 0':qnet_errs_0,\n",
    "              'qnet err 1':qnet_errs_1,\n",
    "              'qnet err 2':qnet_errs_2,\n",
    "              'qnet sample':qnet_sample_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c23eb6",
   "metadata": {},
   "source": [
    "## 2021-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-correspondence",
   "metadata": {},
   "source": [
    "### Single Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b9697706",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2021_2022'\n",
    "\n",
    "# Manually add WHO recommendations\n",
    "table_dict['north_h1n1_ha'].loc[table_dict['north_h1n1_ha']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Victoria/2570/2019'\n",
    "table_dict['north_h1n1_ha'].loc[table_dict['north_h1n1_ha']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MKAILVVMLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKHNGKLCKLRGVAPLHLGKCNIAGWILGNPECESLSTARSWSYIVETSNSDNGTCYPGDFINYEELREQLSSVSSFERFEIFPKTSSWPNHDSDNGVTAACPHAGAKSFYKNLIWLVKKGKSYPKINQTYINDKGKEVLVLWGIHHPPTIADQQSLYQNADAYVFVGTSRYSKKFKPEIATRPKVRDREGRMNYYWTLVEPGDKITFEATGNLVAPRYAFTMERDAGSGIIISDTPVHDCNTTCQTPEGAINTSLPFQNVHPITIGKCPKYVKSTKLRLATGLRNVPSIQSRGLFGAIAGFIEGGWTGMVDGWYGYHHQNEQGSGYAADLKSTQNAIDKITNKVNSVIEKMNTQFTAVGKEFNHLEKRIENLNKKVDDGFLDIWTYNAELLVLLENERTLDYHDSNVKNLYEKVRNQLKNNAKEIGNGCFEFYHKCDNTCMESVKNGTYDYPKYSEEAKLNREKIDGVKLDSTRIYQILAIYSTVASSLVLVVSLGAISFWMCSNGSLQCRICI'\n",
    "table_dict['north_h1n1_na'].loc[table_dict['north_h1n1_na']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Victoria/2570/2019'\n",
    "table_dict['north_h1n1_na'].loc[table_dict['north_h1n1_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MNPNQKIITIGSICMTIGTANLILQIGNIISIWVSHSIQIGNQSQIETCNKSVITYENNTWVNQTFVNISNTNSAARQSVASVKLAGNSSLCPVSGWAIYSKDNSVRIGSKGDVFVIREPFISCSPLECRTFFLTQGALLNDKHSNGTIKDRSPYRTLMSCPIGEVPSPYNSRFESVAWSASACHDGTNWLTIGISGPDSGAVAVLKYNGIITDTIKSWRNKILRTQESECACVNGSCFTIMTDGPSDGQASYKIFRIEKGKIIKSVEMKAPNYHYEECSCYPDSSEITCVCRDNWHGSNRPWVSFNQNLEYQMGYICSGVFGDNPRPNDKTGSCGPVSSNGANGVKGFSFKYGNGVWIGRTKSISSRKGFEMIWDPNGWTGTDNKFSKKQDIVGINEWSGYSGSFVQHPELTGLNCIRPCFWVELIRGRPEENTIWTSGSSISFCGVDSDIVGWSWPDGAELPFTIDK'\n",
    "table_dict['north_h3n2_ha'].loc[table_dict['north_h3n2_ha']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Cambodia/e0826360/2020'\n",
    "table_dict['north_h3n2_ha'].loc[table_dict['north_h3n2_ha']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MKTIIALSYILCLVFAQKIPGNDNSTATLCLGHHAVPNGTIVKTITNDRIEVTNATELVQNSSIGEICDSPHQILDGGNCTLIDALLGDPQCDGFQNKEWDLFVERSRANSNCYPYDVPDYASLRSLVASSGTLEFKNESFNWTGVKQNGTSSACIRGSSSSFFSRLNWLTHLNYKYPALNVTMPNNEQFDKLYIWGVHHPRTDKDQIFLFAQPSGRITVSTKRSQQAVIPNIGSRPRIRDIPSRISIYWTIVKPGDILLINSTGNLIAPRGYFKIRSGKSSIMRSDAPIGKCKSECITPNGSIPNDKPFQNVNRITYGACPRYVKQSTLKLATGMRNVPEKQTRGIFGAIAGFIENGWEGMVDGWYGFKHQNSEGRGQAADLKSTQAAIDQINGKLNRLIGKTNEKFHQIEKEFSEVEGRVQDLEKYVEDTKIDLWSYNAELLVALENQHTIDLTDSEMNKLFEKTKKQLRENAEDMGNGCFKIYHKCDNACIGSIRNETYDHNVYRDEALNNRFQIKGVELKSGYKDWILWISFAMSCFLLCIALLGFIMWACQKGNIRCNICI'\n",
    "table_dict['north_h3n2_na'].loc[table_dict['north_h3n2_na']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Cambodia/e0826360/2020'\n",
    "table_dict['north_h3n2_na'].loc[table_dict['north_h3n2_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPPNNQVMLCEPTIIERNMTEIVYLTNTTIEKEICPKPAEYRNWSKPQCGITGFAPFSKDNSIRLSAGGDIWVTREPYVSCDLDKCYQFALGQGTTLNNVHSNNTVRDRTPYRTLLMNELGVPFHLGTKQVCIAWSSSSCHDGKAWLHVCITGDDKNATASFIYNGRLVDSVVSWSNDILRTQESECVCINGTCTVVMTDGNATGKADTKILFIEEGKIVHTSKLSGSAQHVEECSCYPRYPGVRCVCRDNWKGSNRPIIDINIKDHSIVSRYVCSGLVGDTPRKSDSSSSSHCLNPNNEKGDHGVKGWAFDDGNDVWMGRTINETSRLGYETFKVVEGWSNPKSKLQINRQVIVDRGDRSGYSGIFSVEGKSCINRCFYVELIRGRKEETEVLWTSNSIVVFCGTSGTYGTGSWPDGANLSLMHI'\n",
    "table_dict['south_h1n1_ha'].loc[table_dict['south_h1n1_ha']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Victoria/2570/2019'\n",
    "table_dict['south_h1n1_ha'].loc[table_dict['south_h1n1_ha']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MKAILVVMLYTFTTANADTLCIGYHANNSTDTVDTVLEKNVTVTHSVNLLEDKHNGKLCKLRGVAPLHLGKCNIAGWILGNPECESLSTARSWSYIVETSNSDNGTCYPGDFINYEELREQLSSVSSFERFEIFPKTSSWPNHDSDNGVTAACPHAGAKSFYKNLIWLVKKGKSYPKINQTYINDKGKEVLVLWGIHHPPTIADQQSLYQNADAYVFVGTSRYSKKFKPEIATRPKVRDREGRMNYYWTLVEPGDKITFEATGNLVAPRYAFTMERDAGSGIIISDTPVHDCNTTCQTPEGAINTSLPFQNVHPITIGKCPKYVKSTKLRLATGLRNVPSIQSRGLFGAIAGFIEGGWTGMVDGWYGYHHQNEQGSGYAADLKSTQNAIDKITNKVNSVIEKMNTQFTAVGKEFNHLEKRIENLNKKVDDGFLDIWTYNAELLVLLENERTLDYHDSNVKNLYEKVRNQLKNNAKEIGNGCFEFYHKCDNTCMESVKNGTYDYPKYSEEAKLNREKIDGVKLDSTRIYQILAIYSTVASSLVLVVSLGAISFWMCSNGSLQCRICI'\n",
    "table_dict['south_h1n1_na'].loc[table_dict['south_h1n1_na']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Victoria/2570/2019'\n",
    "table_dict['south_h1n1_na'].loc[table_dict['south_h1n1_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MNPNQKIITIGSICMTIGTANLILQIGNIISIWVSHSIQIGNQSQIETCNKSVITYENNTWVNQTFVNISNTNSAARQSVASVKLAGNSSLCPVSGWAIYSKDNSVRIGSKGDVFVIREPFISCSPLECRTFFLTQGALLNDKHSNGTIKDRSPYRTLMSCPIGEVPSPYNSRFESVAWSASACHDGTNWLTIGISGPDSGAVAVLKYNGIITDTIKSWRNKILRTQESECACVNGSCFTIMTDGPSDGQASYKIFRIEKGKIIKSVEMKAPNYHYEECSCYPDSSEITCVCRDNWHGSNRPWVSFNQNLEYQMGYICSGVFGDNPRPNDKTGSCGPVSSNGANGVKGFSFKYGNGVWIGRTKSISSRKGFEMIWDPNGWTGTDNKFSKKQDIVGINEWSGYSGSFVQHPELTGLNCIRPCFWVELIRGRPEENTIWTSGSSISFCGVDSDIVGWSWPDGAELPFTIDK'\n",
    "table_dict['south_h3n2_ha'].loc[table_dict['south_h3n2_ha']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Hong Kong/2671/2019'\n",
    "table_dict['south_h3n2_ha'].loc[table_dict['south_h3n2_ha']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MKTIIALSYILCLVFTQKIPGNDNSTATLCLGHHAVPNGTIVKTITNDRIEVTNATELVQNSSIGEICDSPHQILDGGNCTLIDALLGDPQCDGFQNKKWDLFVERSRAYSNCYPYDVPDYASLRSLVASSGTLEFKNESFNWAGVTQNGKSFSCIRGSSSSFFSRLNWLTHLNYIYPALNVTMPNKEQFDKLYIWGVHHPVTDKDQISLYAQSSGRITVSTKRSQQAVIPNIGFRPRIRNIPSRISIYWTIVKPGDILLINSTGNLIAPRGYFKIRSGKSSIMRSDAPIGKCKSECITPNGSIPNDKPFQNVNRITYGACPRYVKQSTLKLATGMRNVPEKQTRGIFGAIAGFIENGWEGMVDGWYGFRHQNSEGRGQAADLKSTQAAIDQINGKLNRLIGKTNEKFHQIEKEFSEVEGRVQDLEKYVEDTKIDLWSYNAELLVALENQHTIDLTDSEMNKLFEKTKKQLRENAEDMGNGCFKIYHKCDNACIGSIRNETYDHNVYRDEALNNRFQIKGVELKSGYKDWILWISFAISCFLLCVALLGFIMWACQKGNIRCNICI'\n",
    "table_dict['south_h3n2_na'].loc[table_dict['south_h3n2_na']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Hong Kong/2671/2019'\n",
    "table_dict['south_h3n2_na'].loc[table_dict['south_h3n2_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPPNNQVMLCEPTIIERNITEIVYLTNTTIEKEICPKPAEYRNWSKPQCGITGFAPFSKDNSIRLSAGGDIWVTREPYVSCDLDKCYQFALGQGTTLNNVHSNNTVRDRTPYRTLLMNELGVPFHLGTKQVCIAWSSSSCHDGKAWLHVCITGDDKNATASFIYNGRLVDSVVSWSNDILRTQESECVCINGTCTVVMTDGNATGKADTKILFIEEGKIVHTSKLSGSAQHVEECSCYPRYPGVRCVCRDNWKGSNRPIIDINIKDHSIVSSYVCSGLVGDTPRKSDSSSSSHCLNPNNEEGGHGVKGWAFDDGNDVWMGRTINETSRLGYETFKVVEGWSNPKSKLQINRQVIVDRGDRSGYSGIFSVEGKSCINRCFYVELIRGRKEETEVLWTSNSIVVFCGTSGTYGTGSWPDGADLNLMHT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1b11e178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>who</th>\n",
       "      <th>dominant</th>\n",
       "      <th>qnet</th>\n",
       "      <th>who err</th>\n",
       "      <th>qnet err</th>\n",
       "      <th>qnet sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>north_h1n1_ha</td>\n",
       "      <td>A/Victoria/2570/2019</td>\n",
       "      <td>A/Ireland/20935/2022</td>\n",
       "      <td>A/Togo/45/2021</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north_h1n1_na</td>\n",
       "      <td>A/Victoria/2570/2019</td>\n",
       "      <td>A/Cote_d'Ivoire/3729/2021</td>\n",
       "      <td>A/Togo/0071/2021</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>north_h3n2_ha</td>\n",
       "      <td>A/Cambodia/e0826360/2020</td>\n",
       "      <td>A/Human/New_York/PV60641/2022</td>\n",
       "      <td>A/India/Pun-NIV291000/2021_Jan</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>north_h3n2_na</td>\n",
       "      <td>A/Cambodia/e0826360/2020</td>\n",
       "      <td>A/Stockholm/10/2022</td>\n",
       "      <td>A/Darwin/9/2021</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>south_h1n1_ha</td>\n",
       "      <td>A/Victoria/2570/2019</td>\n",
       "      <td>A/Abidjan/457/2021</td>\n",
       "      <td>A/Togo/35/2021</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>south_h1n1_na</td>\n",
       "      <td>A/Victoria/2570/2019</td>\n",
       "      <td>A/Cote_D'Ivoire/1496/2021</td>\n",
       "      <td>A/Togo/0155/2021</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>south_h3n2_ha</td>\n",
       "      <td>A/Hong Kong/2671/2019</td>\n",
       "      <td>A/Darwin/9a/2021</td>\n",
       "      <td>A/India/PUN-NIV301718/2021</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>south_h3n2_na</td>\n",
       "      <td>A/Hong Kong/2671/2019</td>\n",
       "      <td>A/India/PUN-NIV301718/2021</td>\n",
       "      <td>A/Darwin/11/2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain                       who                       dominant  \\\n",
       "0  north_h1n1_ha      A/Victoria/2570/2019           A/Ireland/20935/2022   \n",
       "1  north_h1n1_na      A/Victoria/2570/2019      A/Cote_d'Ivoire/3729/2021   \n",
       "2  north_h3n2_ha  A/Cambodia/e0826360/2020  A/Human/New_York/PV60641/2022   \n",
       "3  north_h3n2_na  A/Cambodia/e0826360/2020            A/Stockholm/10/2022   \n",
       "4  south_h1n1_ha      A/Victoria/2570/2019             A/Abidjan/457/2021   \n",
       "5  south_h1n1_na      A/Victoria/2570/2019      A/Cote_D'Ivoire/1496/2021   \n",
       "6  south_h3n2_ha     A/Hong Kong/2671/2019               A/Darwin/9a/2021   \n",
       "7  south_h3n2_na     A/Hong Kong/2671/2019     A/India/PUN-NIV301718/2021   \n",
       "\n",
       "                             qnet  who err  qnet err  qnet sample  \n",
       "0                  A/Togo/45/2021        9         3          240  \n",
       "1                A/Togo/0071/2021        1         5          236  \n",
       "2  A/India/Pun-NIV291000/2021_Jan       14         5          446  \n",
       "3                 A/Darwin/9/2021        2         2          421  \n",
       "4                  A/Togo/35/2021        9         4           31  \n",
       "5                A/Togo/0155/2021        1         7           29  \n",
       "6      A/India/PUN-NIV301718/2021       19         1          224  \n",
       "7                A/Darwin/11/2021        6         1          218  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_seqs = []\n",
    "dom_seqs = []\n",
    "pred_seqs = []\n",
    "who_errs = []\n",
    "qnet_errs = []\n",
    "qnet_sample_size = []\n",
    "\n",
    "for FILE in FILES:\n",
    "    df = table_dict[FILE]\n",
    "    add_new_row(df, YEAR)\n",
    "    add_dominant_sequence(df, FILE, YEAR)\n",
    "    add_predicted_sequence(df, FILE, YEAR)\n",
    "    add_who_qnet_errors(df, YEAR)\n",
    "    add_qnet_sample_size(df, FILE, YEAR)\n",
    "    # items to display\n",
    "    who_seqs.append(df.loc[df['year'] == YEAR]['WHO_recommendation_name'].values[0])\n",
    "    dom_seqs.append(df.loc[df['year'] == YEAR]['dominant_strain_accession_name'].values[0])\n",
    "    pred_seqs.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name'].values[0])\n",
    "    who_errs.append(df.loc[df['year'] == YEAR]['ldistance_WHO'].values[0])\n",
    "    qnet_errs.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation'].values[0])\n",
    "    qnet_sample_size.append(df.loc[df['year'] == YEAR]['qnet_sample_size'].values[0])\n",
    "    \n",
    "pd.DataFrame({'strain':FILES, \n",
    "              'who':who_seqs, \n",
    "              'dominant':dom_seqs, \n",
    "              'qnet':pred_seqs,\n",
    "              'who err':who_errs,\n",
    "              'qnet err':qnet_errs,\n",
    "              'qnet sample':qnet_sample_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-world",
   "metadata": {},
   "source": [
    "### Multi-Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8c07865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2021_2022'\n",
    "\n",
    "# Manually add WHO recommendations\n",
    "for FILE in FILES_3CLUSTER:\n",
    "    df = table_dict_3cluster[FILE]\n",
    "    add_new_row(df, YEAR, multi_cluster=True)\n",
    "    \n",
    "table_dict_3cluster['north_h1n1_na'].loc[table_dict_3cluster['north_h1n1_na']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Victoria/2570/2019'\n",
    "table_dict_3cluster['north_h1n1_na'].loc[table_dict_3cluster['north_h1n1_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MNPNQKIITIGSICMTIGTANLILQIGNIISIWVSHSIQIGNQSQIETCNKSVITYENNTWVNQTFVNISNTNSAARQSVASVKLAGNSSLCPVSGWAIYSKDNSVRIGSKGDVFVIREPFISCSPLECRTFFLTQGALLNDKHSNGTIKDRSPYRTLMSCPIGEVPSPYNSRFESVAWSASACHDGTNWLTIGISGPDSGAVAVLKYNGIITDTIKSWRNKILRTQESECACVNGSCFTIMTDGPSDGQASYKIFRIEKGKIIKSVEMKAPNYHYEECSCYPDSSEITCVCRDNWHGSNRPWVSFNQNLEYQMGYICSGVFGDNPRPNDKTGSCGPVSSNGANGVKGFSFKYGNGVWIGRTKSISSRKGFEMIWDPNGWTGTDNKFSKKQDIVGINEWSGYSGSFVQHPELTGLNCIRPCFWVELIRGRPEENTIWTSGSSISFCGVDSDIVGWSWPDGAELPFTIDK'\n",
    "table_dict_3cluster['north_h3n2_na'].loc[table_dict_3cluster['north_h3n2_na']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Cambodia/e0826360/2020'\n",
    "table_dict_3cluster['north_h3n2_na'].loc[table_dict_3cluster['north_h3n2_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPPNNQVMLCEPTIIERNMTEIVYLTNTTIEKEICPKPAEYRNWSKPQCGITGFAPFSKDNSIRLSAGGDIWVTREPYVSCDLDKCYQFALGQGTTLNNVHSNNTVRDRTPYRTLLMNELGVPFHLGTKQVCIAWSSSSCHDGKAWLHVCITGDDKNATASFIYNGRLVDSVVSWSNDILRTQESECVCINGTCTVVMTDGNATGKADTKILFIEEGKIVHTSKLSGSAQHVEECSCYPRYPGVRCVCRDNWKGSNRPIIDINIKDHSIVSRYVCSGLVGDTPRKSDSSSSSHCLNPNNEKGDHGVKGWAFDDGNDVWMGRTINETSRLGYETFKVVEGWSNPKSKLQINRQVIVDRGDRSGYSGIFSVEGKSCINRCFYVELIRGRKEETEVLWTSNSIVVFCGTSGTYGTGSWPDGANLSLMHI'\n",
    "table_dict_3cluster['south_h1n1_na'].loc[table_dict_3cluster['south_h1n1_na']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Victoria/2570/2019'\n",
    "table_dict_3cluster['south_h1n1_na'].loc[table_dict_3cluster['south_h1n1_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MNPNQKIITIGSICMTIGTANLILQIGNIISIWVSHSIQIGNQSQIETCNKSVITYENNTWVNQTFVNISNTNSAARQSVASVKLAGNSSLCPVSGWAIYSKDNSVRIGSKGDVFVIREPFISCSPLECRTFFLTQGALLNDKHSNGTIKDRSPYRTLMSCPIGEVPSPYNSRFESVAWSASACHDGTNWLTIGISGPDSGAVAVLKYNGIITDTIKSWRNKILRTQESECACVNGSCFTIMTDGPSDGQASYKIFRIEKGKIIKSVEMKAPNYHYEECSCYPDSSEITCVCRDNWHGSNRPWVSFNQNLEYQMGYICSGVFGDNPRPNDKTGSCGPVSSNGANGVKGFSFKYGNGVWIGRTKSISSRKGFEMIWDPNGWTGTDNKFSKKQDIVGINEWSGYSGSFVQHPELTGLNCIRPCFWVELIRGRPEENTIWTSGSSISFCGVDSDIVGWSWPDGAELPFTIDK'\n",
    "table_dict_3cluster['south_h3n2_na'].loc[table_dict_3cluster['south_h3n2_na']['year'] == YEAR, ['WHO_recommendation_name']] = 'A/Hong Kong/2671/2019'\n",
    "table_dict_3cluster['south_h3n2_na'].loc[table_dict_3cluster['south_h3n2_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = 'MNPNQKIITIGSVSLTISTICFFMQIAILITTVTLHFKQYEFNSPPNNQVMLCEPTIIERNITEIVYLTNTTIEKEICPKPAEYRNWSKPQCGITGFAPFSKDNSIRLSAGGDIWVTREPYVSCDLDKCYQFALGQGTTLNNVHSNNTVRDRTPYRTLLMNELGVPFHLGTKQVCIAWSSSSCHDGKAWLHVCITGDDKNATASFIYNGRLVDSVVSWSNDILRTQESECVCINGTCTVVMTDGNATGKADTKILFIEEGKIVHTSKLSGSAQHVEECSCYPRYPGVRCVCRDNWKGSNRPIIDINIKDHSIVSSYVCSGLVGDTPRKSDSSSSSHCLNPNNEEGGHGVKGWAFDDGNDVWMGRTINETSRLGYETFKVVEGWSNPKSKLQINRQVIVDRGDRSGYSGIFSVEGKSCINRCFYVELIRGRKEETEVLWTSNSIVVFCGTSGTYGTGSWPDGADLNLMHT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3e6e0a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>who</th>\n",
       "      <th>dominant</th>\n",
       "      <th>qnet 0</th>\n",
       "      <th>qnet 1</th>\n",
       "      <th>qnet 2</th>\n",
       "      <th>who err</th>\n",
       "      <th>qnet err 0</th>\n",
       "      <th>qnet err 1</th>\n",
       "      <th>qnet err 2</th>\n",
       "      <th>qnet sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>north_h1n1_na</td>\n",
       "      <td>A/Victoria/2570/2019</td>\n",
       "      <td>A/Cote_d'Ivoire/3729/2021</td>\n",
       "      <td>A/Togo/0071/2021</td>\n",
       "      <td>A/Yunnan-Mengzi/1462/2020</td>\n",
       "      <td>A/North_Carolina/15/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>98</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north_h3n2_na</td>\n",
       "      <td>A/Cambodia/e0826360/2020</td>\n",
       "      <td>A/Stockholm/10/2022</td>\n",
       "      <td>A/Laos/527/2021</td>\n",
       "      <td>A/Michigan/UOM10045655748/2020</td>\n",
       "      <td>A/Wisconsin/01/2021</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>south_h1n1_na</td>\n",
       "      <td>A/Victoria/2570/2019</td>\n",
       "      <td>A/Cote_D'Ivoire/1496/2021</td>\n",
       "      <td>A/Togo/0155/2021</td>\n",
       "      <td>A/Shandong/00204/2021</td>\n",
       "      <td>A/North_Carolina/15/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>58</td>\n",
       "      <td>98</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>south_h3n2_na</td>\n",
       "      <td>A/Hong Kong/2671/2019</td>\n",
       "      <td>A/India/PUN-NIV301718/2021</td>\n",
       "      <td>A/Darwin/11/2021</td>\n",
       "      <td>A/Hawaii/28/2020</td>\n",
       "      <td>A/South_Australia/1/2021</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain                       who                    dominant  \\\n",
       "0  north_h1n1_na      A/Victoria/2570/2019   A/Cote_d'Ivoire/3729/2021   \n",
       "1  north_h3n2_na  A/Cambodia/e0826360/2020         A/Stockholm/10/2022   \n",
       "2  south_h1n1_na      A/Victoria/2570/2019   A/Cote_D'Ivoire/1496/2021   \n",
       "3  south_h3n2_na     A/Hong Kong/2671/2019  A/India/PUN-NIV301718/2021   \n",
       "\n",
       "             qnet 0                          qnet 1                    qnet 2  \\\n",
       "0  A/Togo/0071/2021       A/Yunnan-Mengzi/1462/2020  A/North_Carolina/15/2020   \n",
       "1   A/Laos/527/2021  A/Michigan/UOM10045655748/2020       A/Wisconsin/01/2021   \n",
       "2  A/Togo/0155/2021           A/Shandong/00204/2021  A/North_Carolina/15/2020   \n",
       "3  A/Darwin/11/2021                A/Hawaii/28/2020  A/South_Australia/1/2021   \n",
       "\n",
       "   who err  qnet err 0  qnet err 1  qnet err 2  qnet sample  \n",
       "0        1           5          51          98          236  \n",
       "1        2           3           7          58          421  \n",
       "2        1           7          58          98           29  \n",
       "3        6           1          49          57          218  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_seqs = []\n",
    "dom_seqs = []\n",
    "pred_seqs_0 = []\n",
    "pred_seqs_1 = []\n",
    "pred_seqs_2 = []\n",
    "who_errs = []\n",
    "qnet_errs_0 = []\n",
    "qnet_errs_1 = []\n",
    "qnet_errs_2 = []\n",
    "qnet_sample_size = []\n",
    "\n",
    "for FILE in FILES_3CLUSTER:\n",
    "    df = table_dict_3cluster[FILE]\n",
    "    add_new_row(df, YEAR, multi_cluster=True)\n",
    "    add_dominant_sequence(df, FILE, YEAR)\n",
    "    add_predicted_sequence(df, FILE, YEAR, multi_cluster=True)\n",
    "    add_who_qnet_errors(df, YEAR, multi_cluster=True)\n",
    "    add_qnet_sample_size(df, FILE, YEAR)\n",
    "    # items to display\n",
    "    who_seqs.append(df.loc[df['year'] == YEAR]['WHO_recommendation_name'].values[0])\n",
    "    dom_seqs.append(df.loc[df['year'] == YEAR]['dominant_strain_accession_name'].values[0])\n",
    "    pred_seqs_0.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_0'].values[0])\n",
    "    pred_seqs_1.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_1'].values[0])\n",
    "    pred_seqs_2.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_2'].values[0])\n",
    "    who_errs.append(df.loc[df['year'] == YEAR]['ldistance_WHO'].values[0])\n",
    "    qnet_errs_0.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_0'].values[0])\n",
    "    qnet_errs_1.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_1'].values[0])\n",
    "    qnet_errs_2.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_2'].values[0])\n",
    "    qnet_sample_size.append(df.loc[df['year'] == YEAR]['qnet_sample_size'].values[0])\n",
    "    \n",
    "pd.DataFrame({'strain':FILES_3CLUSTER, \n",
    "              'who':who_seqs, \n",
    "              'dominant':dom_seqs, \n",
    "              'qnet 0':pred_seqs_0,\n",
    "              'qnet 1':pred_seqs_1,\n",
    "              'qnet 2':pred_seqs_2,\n",
    "              'who err':who_errs,\n",
    "              'qnet err 0':qnet_errs_0,\n",
    "              'qnet err 1':qnet_errs_1,\n",
    "              'qnet err 2':qnet_errs_2,\n",
    "              'qnet sample':qnet_sample_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558f2a6",
   "metadata": {},
   "source": [
    "## 2022-2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-anthony",
   "metadata": {},
   "source": [
    "### Single Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f9295801",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2022_2023'\n",
    "\n",
    "# Manually add WHO recommendations\n",
    "table_dict['north_h1n1_ha'].loc[table_dict['north_h1n1_ha']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict['north_h1n1_ha'].loc[table_dict['north_h1n1_ha']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict['north_h1n1_na'].loc[table_dict['north_h1n1_na']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict['north_h1n1_na'].loc[table_dict['north_h1n1_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict['north_h3n2_ha'].loc[table_dict['north_h3n2_ha']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict['north_h3n2_ha'].loc[table_dict['north_h3n2_ha']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict['north_h3n2_na'].loc[table_dict['north_h3n2_na']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict['north_h3n2_na'].loc[table_dict['north_h3n2_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict['south_h1n1_ha'].loc[table_dict['south_h1n1_ha']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict['south_h1n1_ha'].loc[table_dict['south_h1n1_ha']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict['south_h1n1_na'].loc[table_dict['south_h1n1_na']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict['south_h1n1_na'].loc[table_dict['south_h1n1_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict['south_h3n2_ha'].loc[table_dict['south_h3n2_ha']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict['south_h3n2_ha'].loc[table_dict['south_h3n2_ha']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict['south_h3n2_na'].loc[table_dict['south_h3n2_na']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict['south_h3n2_na'].loc[table_dict['south_h3n2_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d79b1fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>who</th>\n",
       "      <th>dominant</th>\n",
       "      <th>qnet</th>\n",
       "      <th>who err</th>\n",
       "      <th>qnet err</th>\n",
       "      <th>qnet sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>north_h1n1_ha</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Netherlands/00068/2022</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north_h1n1_na</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Lyon/820/2021</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>north_h3n2_ha</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Denmark/370/2022</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>north_h3n2_na</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Michigan/UOM10042819294/2021</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>south_h1n1_ha</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Cote_D'Ivoire/1270/2021</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>south_h1n1_na</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Dakar/35/2021</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>south_h3n2_ha</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Saint-Martin/00754/2022</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>south_h3n2_na</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Texas/12723/2022</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  who dominant                            qnet  who err  \\\n",
       "0  north_h1n1_ha   -1       -1        A/Netherlands/00068/2022       -1   \n",
       "1  north_h1n1_na   -1       -1                 A/Lyon/820/2021       -1   \n",
       "2  north_h3n2_ha   -1       -1              A/Denmark/370/2022       -1   \n",
       "3  north_h3n2_na   -1       -1  A/Michigan/UOM10042819294/2021       -1   \n",
       "4  south_h1n1_ha   -1       -1       A/Cote_D'Ivoire/1270/2021       -1   \n",
       "5  south_h1n1_na   -1       -1                 A/Dakar/35/2021       -1   \n",
       "6  south_h3n2_ha   -1       -1       A/Saint-Martin/00754/2022       -1   \n",
       "7  south_h3n2_na   -1       -1              A/Texas/12723/2022       -1   \n",
       "\n",
       "   qnet err  qnet sample  \n",
       "0        -1          976  \n",
       "1        -1          961  \n",
       "2        -1         1000  \n",
       "3        -1         1000  \n",
       "4        -1          281  \n",
       "5        -1          264  \n",
       "6        -1          641  \n",
       "7        -1          628  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_seqs = []\n",
    "dom_seqs = []\n",
    "pred_seqs = []\n",
    "who_errs = []\n",
    "qnet_errs = []\n",
    "qnet_sample_size = []\n",
    "\n",
    "for FILE in FILES:\n",
    "    df = table_dict[FILE]\n",
    "    add_new_row(df, YEAR)\n",
    "    # add_dominant_sequence(df, FILE, YEAR)\n",
    "    add_predicted_sequence(df, FILE, YEAR)\n",
    "    # add_who_qnet_errors(df, YEAR)\n",
    "    add_qnet_sample_size(df, FILE, YEAR)\n",
    "    # items to display\n",
    "    who_seqs.append(df.loc[df['year'] == YEAR]['WHO_recommendation_name'].values[0])\n",
    "    dom_seqs.append(df.loc[df['year'] == YEAR]['dominant_strain_accession_name'].values[0])\n",
    "    pred_seqs.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name'].values[0])\n",
    "    who_errs.append(df.loc[df['year'] == YEAR]['ldistance_WHO'].values[0])\n",
    "    qnet_errs.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation'].values[0])\n",
    "    qnet_sample_size.append(df.loc[df['year'] == YEAR]['qnet_sample_size'].values[0])\n",
    "    \n",
    "pd.DataFrame({'strain':FILES, \n",
    "              'who':who_seqs, \n",
    "              'dominant':dom_seqs, \n",
    "              'qnet':pred_seqs,\n",
    "              'who err':who_errs,\n",
    "              'qnet err':qnet_errs,\n",
    "              'qnet sample':qnet_sample_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-blast",
   "metadata": {},
   "source": [
    "### Multi-Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8c064972",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2022_2023'\n",
    "\n",
    "# Manually add WHO recommendations\n",
    "for FILE in FILES_3CLUSTER:\n",
    "    df = table_dict_3cluster[FILE]\n",
    "    add_new_row(df, YEAR, multi_cluster=True)\n",
    "    \n",
    "table_dict_3cluster['north_h1n1_na'].loc[table_dict_3cluster['north_h1n1_na']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict_3cluster['north_h1n1_na'].loc[table_dict_3cluster['north_h1n1_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict_3cluster['north_h3n2_na'].loc[table_dict_3cluster['north_h3n2_na']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict_3cluster['north_h3n2_na'].loc[table_dict_3cluster['north_h3n2_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict_3cluster['south_h1n1_na'].loc[table_dict_3cluster['south_h1n1_na']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict_3cluster['south_h1n1_na'].loc[table_dict_3cluster['south_h1n1_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1\n",
    "table_dict_3cluster['south_h3n2_na'].loc[table_dict_3cluster['south_h3n2_na']['year'] == YEAR, ['WHO_recommendation_name']] = -1\n",
    "table_dict_3cluster['south_h3n2_na'].loc[table_dict_3cluster['south_h3n2_na']['year'] == YEAR, ['WHO_recommendation_sequence']] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ae541f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strain</th>\n",
       "      <th>who</th>\n",
       "      <th>dominant</th>\n",
       "      <th>qnet 0</th>\n",
       "      <th>qnet 1</th>\n",
       "      <th>qnet 2</th>\n",
       "      <th>who err</th>\n",
       "      <th>qnet err 0</th>\n",
       "      <th>qnet err 1</th>\n",
       "      <th>qnet err 2</th>\n",
       "      <th>qnet sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>north_h1n1_na</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Netherlands/10646/2022</td>\n",
       "      <td>A/Sydney/234/2022</td>\n",
       "      <td>A/Wisconsin/03/2021</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>north_h3n2_na</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Maine/02/2022</td>\n",
       "      <td>A/Michigan/UOM10042819294/2021</td>\n",
       "      <td>A/Netherlands/10082/2022</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>south_h1n1_na</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Switzerland/86136/2022</td>\n",
       "      <td>A/Wisconsin/04/2021</td>\n",
       "      <td>A/Wisconsin/05/2021</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>south_h3n2_na</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>A/Congo/313/2021</td>\n",
       "      <td>A/Texas/12723/2022</td>\n",
       "      <td>A/Netherlands/00037/2022</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          strain  who dominant                    qnet 0  \\\n",
       "0  north_h1n1_na   -1       -1  A/Netherlands/10646/2022   \n",
       "1  north_h3n2_na   -1       -1           A/Maine/02/2022   \n",
       "2  south_h1n1_na   -1       -1  A/Switzerland/86136/2022   \n",
       "3  south_h3n2_na   -1       -1          A/Congo/313/2021   \n",
       "\n",
       "                           qnet 1                    qnet 2  who err  \\\n",
       "0               A/Sydney/234/2022       A/Wisconsin/03/2021       -1   \n",
       "1  A/Michigan/UOM10042819294/2021  A/Netherlands/10082/2022       -1   \n",
       "2             A/Wisconsin/04/2021       A/Wisconsin/05/2021       -1   \n",
       "3              A/Texas/12723/2022  A/Netherlands/00037/2022       -1   \n",
       "\n",
       "   qnet err 0  qnet err 1  qnet err 2  qnet sample  \n",
       "0          -1          -1          -1          961  \n",
       "1          -1          -1          -1         1000  \n",
       "2          -1          -1          -1          264  \n",
       "3          -1          -1          -1          628  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_seqs = []\n",
    "dom_seqs = []\n",
    "pred_seqs_0 = []\n",
    "pred_seqs_1 = []\n",
    "pred_seqs_2 = []\n",
    "who_errs = []\n",
    "qnet_errs_0 = []\n",
    "qnet_errs_1 = []\n",
    "qnet_errs_2 = []\n",
    "qnet_sample_size = []\n",
    "\n",
    "for FILE in FILES_3CLUSTER:\n",
    "    df = table_dict_3cluster[FILE]\n",
    "    add_new_row(df, YEAR, multi_cluster=True)\n",
    "    # add_dominant_sequence(df, FILE, YEAR)\n",
    "    add_predicted_sequence(df, FILE, YEAR, multi_cluster=True)\n",
    "    # add_who_qnet_errors(df, YEAR, multi_cluster=True)\n",
    "    add_qnet_sample_size(df, FILE, YEAR)\n",
    "    # items to display\n",
    "    who_seqs.append(df.loc[df['year'] == YEAR]['WHO_recommendation_name'].values[0])\n",
    "    dom_seqs.append(df.loc[df['year'] == YEAR]['dominant_strain_accession_name'].values[0])\n",
    "    pred_seqs_0.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_0'].values[0])\n",
    "    pred_seqs_1.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_1'].values[0])\n",
    "    pred_seqs_2.append(df.loc[df['year'] == YEAR]['qdistance_recommendation_accession_name_2'].values[0])\n",
    "    who_errs.append(df.loc[df['year'] == YEAR]['ldistance_WHO'].values[0])\n",
    "    qnet_errs_0.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_0'].values[0])\n",
    "    qnet_errs_1.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_1'].values[0])\n",
    "    qnet_errs_2.append(df.loc[df['year'] == YEAR]['ldistance_Qnet_recommendation_2'].values[0])\n",
    "    qnet_sample_size.append(df.loc[df['year'] == YEAR]['qnet_sample_size'].values[0])\n",
    "    \n",
    "pd.DataFrame({'strain':FILES_3CLUSTER, \n",
    "              'who':who_seqs, \n",
    "              'dominant':dom_seqs, \n",
    "              'qnet 0':pred_seqs_0,\n",
    "              'qnet 1':pred_seqs_1,\n",
    "              'qnet 2':pred_seqs_2,\n",
    "              'who err':who_errs,\n",
    "              'qnet err 0':qnet_errs_0,\n",
    "              'qnet err 1':qnet_errs_1,\n",
    "              'qnet err 2':qnet_errs_2,\n",
    "              'qnet sample':qnet_sample_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e6960",
   "metadata": {},
   "source": [
    "## Save Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ed736d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for FILE in FILES:\n",
    "    os.makedirs('tables', exist_ok=True)  \n",
    "    table_dict[FILE].to_csv('tables/' + FILE + '.csv', index=False)\n",
    "    \n",
    "for FILE in FILES_3CLUSTER:\n",
    "    os.makedirs('tables', exist_ok=True)  \n",
    "    table_dict_3cluster[FILE].to_csv('tables/' + FILE + '_3cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a711c5fb",
   "metadata": {},
   "source": [
    "## Total Data Retreived (SI Table 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7fbef434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>strain</th>\n",
       "      <th>no. seqs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCBI</td>\n",
       "      <td>h1n1_ha</td>\n",
       "      <td>17894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCBI</td>\n",
       "      <td>h1n1_na</td>\n",
       "      <td>16637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCBI</td>\n",
       "      <td>h3n2_ha</td>\n",
       "      <td>18265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCBI</td>\n",
       "      <td>h3n2_na</td>\n",
       "      <td>14699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GISAID</td>\n",
       "      <td>h1n1_ha</td>\n",
       "      <td>1528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GISAID</td>\n",
       "      <td>h1n1_na</td>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GISAID</td>\n",
       "      <td>h3n2_ha</td>\n",
       "      <td>13975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GISAID</td>\n",
       "      <td>h3n2_na</td>\n",
       "      <td>13811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Total</td>\n",
       "      <td></td>\n",
       "      <td>98299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  database   strain  no. seqs\n",
       "0     NCBI  h1n1_ha     17894\n",
       "1     NCBI  h1n1_na     16637\n",
       "2     NCBI  h3n2_ha     18265\n",
       "3     NCBI  h3n2_na     14699\n",
       "4   GISAID  h1n1_ha      1528\n",
       "5   GISAID  h1n1_na      1490\n",
       "6   GISAID  h3n2_ha     13975\n",
       "7   GISAID  h3n2_na     13811\n",
       "8    Total              98299"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STRAINS = ['h1n1_ha', 'h1n1_na', 'h3n2_ha', 'h3n2_na']\n",
    "GISAID_YEARS = ['_20', '_21']\n",
    "ncbi_counts = []\n",
    "gisaid_counts = []\n",
    "\n",
    "for STRAIN in STRAINS:\n",
    "    # ncbi\n",
    "    ncbi_num = 0\n",
    "    NCBI_DIR = NCBI_PATH + STRAIN + '.fasta'\n",
    "    for record in SeqIO.parse(NCBI_DIR, 'fasta'):\n",
    "        ncbi_num += 1\n",
    "    ncbi_counts.append(ncbi_num)\n",
    "    \n",
    "    # gisaid\n",
    "    gisaid_num = 0\n",
    "    for FILE in FILES:\n",
    "        if STRAIN in FILE:\n",
    "            for YEAR in GISAID_YEARS:\n",
    "                GISAID_DIR = GISAID_PATH + FILE + YEAR + '.fasta'\n",
    "                for record in SeqIO.parse(GISAID_DIR, 'fasta'):\n",
    "                    gisaid_num += 1\n",
    "    gisaid_counts.append(gisaid_num)\n",
    "    \n",
    "total_seqs = pd.DataFrame({'database':4*['NCBI'] + 4*['GISAID'], \n",
    "                           'strain':STRAINS + STRAINS, \n",
    "                           'no. seqs':ncbi_counts + gisaid_counts})\n",
    "total_seqs.loc[total_seqs.shape[0]] = ['Total','',total_seqs['no. seqs'].sum()]\n",
    "total_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5b311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
