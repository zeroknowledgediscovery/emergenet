{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a01728-b9ae-48b6-b5ff-0f283ecb8837",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1bc065-dabb-45cb-8aff-a243fd9749c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from domseq import DomSeq, save_model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeae7b7-8fa9-4e44-a490-f9484e86b40b",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "**Sources: [GISAID](https://platform.epicov.org/epi3/cfrontend#586f5f) and [NCBI](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Protein&HostLineage_ss=Homo%20sapiens%20(human),%20taxid:9606&LabHost_s=include&ProtNames_ss=hemagglutinin&CollectionDate_dr=2003-11-01T00:00:00.00Z%20TO%202004-05-01T23:59:59.00Z&SLen_i=550%20TO%20566&VirusLineage_ss=H1N1%20subtype,%20taxid:114727)**\n",
    "- Host: Human\n",
    "- Subtype: H1N1 or H3N2\n",
    "- Segment: HA (4) and NA (6)\n",
    "- Download all data from 09/25/2001 - 02/15/2023 (collection date) from both NCBI and GISAID\n",
    "- For NCBI, filter by the following sequence length\n",
    "    - HA: min = 550, max = 570\n",
    "    - NA: min = 450, max = 470"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c76a4-e347-4206-a088-c6a91d37be5e",
   "metadata": {},
   "source": [
    "## Cleaning and Merging Data\n",
    "- Make `h1n1.csv` and `h3n2.csv`\n",
    "- Merge HA, and NA data\n",
    "    - Put HA strain in 'sequence' column, NA strain in 'na_sequence' column\n",
    "    - Keep only strains with both HA and NA available\n",
    "    - Truncate to 468 for NA (2 less than official length of 470)\n",
    "    - Truncate to 565 for HA (2 less than official length of 567)\n",
    "- Merge GISAID and NCBI data\n",
    "- Save to `raw_data/merged/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b05e16-b852-489f-b803-f820ab5df0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NCBI_DIR = 'raw_data/ncbi/'\n",
    "GISAID_DIR = 'raw_data/gisaid/'\n",
    "DATA_DIR = 'raw_data/merged/'\n",
    "\n",
    "NA_TRUNC = 468 # 2 less than official length of 470\n",
    "HA_TRUNC = 565 # 2 less than official length of 567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afef8c70-8fa1-4ada-bd83-3e3d65c63d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# returns merged sequence dataframe\n",
    "def load_ncbi_gisaid(domseq, NCBI_FILE, GISAID_FILE):\n",
    "    seq_df = pd.DataFrame({'acc':[],'name':[],'date':[],'sequence':[]})\n",
    "    if os.path.isfile(NCBI_FILE):\n",
    "        seq_df_ncbi = domseq.load_data(NCBI_FILE)\n",
    "        seq_df = seq_df.append(seq_df_ncbi)\n",
    "    if os.path.isfile(GISAID_FILE):\n",
    "        seq_df_gisaid = domseq.load_data(GISAID_FILE)\n",
    "        seq_df = seq_df.append(seq_df_gisaid)\n",
    "    return seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ba560a8-5391-4449-9b8b-e7539f117c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine GISAID and NCBI, merge on HA and NA, remove duplicates by name\n",
    "for SUBTYPE in ['h1n1', 'h3n2']:\n",
    "    # initialize the DomSeq\n",
    "    domseq_ha = DomSeq(seq_trunc_length=HA_TRUNC)\n",
    "    domseq_na = DomSeq(seq_trunc_length=NA_TRUNC)\n",
    "    \n",
    "    # file name\n",
    "    GISAID_FILE_HA = GISAID_DIR+SUBTYPE+'_ha.fasta'\n",
    "    GISAID_FILE_NA = GISAID_DIR+SUBTYPE+'_na.fasta'\n",
    "    NCBI_FILE_HA = NCBI_DIR+SUBTYPE+'_ha.fasta'\n",
    "    NCBI_FILE_NA = NCBI_DIR+SUBTYPE+'_na.fasta'\n",
    "    \n",
    "    # load data\n",
    "    seq_df_ha = load_ncbi_gisaid(domseq_ha, NCBI_FILE_HA, GISAID_FILE_HA)\n",
    "    seq_df_na = load_ncbi_gisaid(domseq_na, NCBI_FILE_NA, GISAID_FILE_NA)\n",
    "    \n",
    "    # drop duplicates by name\n",
    "    seq_df_ha.drop_duplicates(subset=['name'], inplace=True)\n",
    "    seq_df_na.drop_duplicates(subset=['name'], inplace=True)\n",
    "    seq_df_na.rename(columns={'acc':'acc_na', 'sequence':'sequence_na'}, inplace=True)\n",
    "    \n",
    "    # merge HA and NA on name and date\n",
    "    seq_df = seq_df_ha.merge(seq_df_na, how='inner', on=['name', 'date'])\n",
    "    seq_df['date'] = pd.to_datetime(seq_df['date'])\n",
    "    seq_df.sort_values(by='date', inplace=True)\n",
    "    \n",
    "    # save to csv\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)  \n",
    "    seq_df.to_csv(DATA_DIR+SUBTYPE+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23892e11-163a-4cac-878e-c9c91fa476ef",
   "metadata": {},
   "source": [
    "## Seasonal Files\n",
    "- Make seperate files for North H1N1, North H3N2, South H1N1, South H3N2\n",
    "    - Make seperate file for each season (21 seasons total for each category)\n",
    "- Flu Season example: \n",
    "    - Northern strains from 02/15/2002 - 02/14/2003: predict for 2003-04 season\n",
    "    - Southern strains from 09/25/2001 - 09/24/2002: predict for 2003 season\n",
    "    - Flu season dates from [CDC](https://www.cdc.gov/flu/school-business/travelersfacts.htm) and [WHO](https://www.who.int/teams/global-influenza-programme/vaccines/who-recommendations/recommendations-for-influenza-vaccine-composition-archive)\n",
    "- File names for raw data: HEMISPHERE_SEQUENCE_SEASON (+ '_pred' if prediction data)\n",
    "    - HEMISPHERE: \"north\" or \"south\"\n",
    "    - SEQUENCE: \"h1n1\" or \"h3n2\"\n",
    "    - SEASON: (ex. 02_03 for north 02/15/2002 - 02/14/2003, 02 for south 09/25/2001 - 09/24/2002)\n",
    "    - **'pred': all sequence data up to that point, used for prediction**\n",
    "        - Season specific data is for training models, but we will predict on all data up to that point\n",
    "- Save to `raw_data/merged/`\n",
    "    - Some seasons will have no strains from a particular database\n",
    "    - In each year record how many strains come from NCBI and GISAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ffe0c8b-8ed9-4b79-b963-d4c8e092b979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NORTH_YEARS = []\n",
    "for i in np.arange(2, 23):\n",
    "    YEAR = ''\n",
    "    if i < 10:\n",
    "        YEAR += '0' + str(i)\n",
    "    else:\n",
    "        YEAR += (str(i))\n",
    "    if i + 1 < 10:\n",
    "        YEAR += '_0' + str(i + 1)\n",
    "    else:\n",
    "        YEAR += '_' + str(i + 1)\n",
    "    NORTH_YEARS.append(YEAR)\n",
    "        \n",
    "SOUTH_YEARS = []\n",
    "for i in np.arange(2, 23):\n",
    "    if i < 10:\n",
    "        SOUTH_YEARS.append('0' + str(i))\n",
    "    else:\n",
    "        SOUTH_YEARS.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5031381-8641-4c06-a94f-dc3bc7fe4566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for SUBTYPE in ['h1n1', 'h3n2']:\n",
    "    df = pd.read_csv(DATA_DIR+SUBTYPE+'.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    for i in range(21):\n",
    "        NORTH_START = str(2002 + i) + '-02-15'\n",
    "        NORTH_END = str(2003 + i) + '-02-14'\n",
    "        NORTH_DIR = DATA_DIR + 'north_' + SUBTYPE + '/'\n",
    "        os.makedirs(NORTH_DIR, exist_ok=True) \n",
    "        os.makedirs(NORTH_DIR+'pred', exist_ok=True) \n",
    "        # north\n",
    "        north_df = df.loc[(df['date'] >= NORTH_START) & (df['date'] <= NORTH_END)]\n",
    "        north_df.to_csv(NORTH_DIR+'north_'+SUBTYPE+'_'+NORTH_YEARS[i]+'.csv', index=False)\n",
    "        # north prediction\n",
    "        north_pred_df = df.loc[df['date'] <= NORTH_END].drop_duplicates(subset=['sequence'])\n",
    "        north_pred_df.to_csv(NORTH_DIR+'pred/north_'+SUBTYPE+'_'+NORTH_YEARS[i]+'.csv', index=False)\n",
    "        \n",
    "        SOUTH_START = str(2001 + i) + '-09-25'\n",
    "        SOUTH_END = str(2002 + i) + '-09-24'\n",
    "        SOUTH_DIR = DATA_DIR + 'south_' + SUBTYPE + '/'\n",
    "        os.makedirs(SOUTH_DIR, exist_ok=True) \n",
    "        os.makedirs(SOUTH_DIR+'pred', exist_ok=True)\n",
    "        # south\n",
    "        south_df = df.loc[(df['date'] >= SOUTH_START) & (df['date'] <= SOUTH_END)]\n",
    "        south_df.to_csv(SOUTH_DIR+'south_'+SUBTYPE+'_'+SOUTH_YEARS[i]+'.csv', index=False)\n",
    "        # south prediction\n",
    "        south_pred_df = df.loc[df['date'] <= SOUTH_END].drop_duplicates(subset=['sequence'])\n",
    "        south_pred_df.to_csv(SOUTH_DIR+'pred/south_'+SUBTYPE+'_'+SOUTH_YEARS[i]+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c03d14fb-d6ef-43fe-a9c1-61ab67f24e32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>north_season</th>\n",
       "      <th>north_h1n1</th>\n",
       "      <th>north_h3n2</th>\n",
       "      <th>south_season</th>\n",
       "      <th>south_h1n1</th>\n",
       "      <th>south_h3n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02_03</td>\n",
       "      <td>34</td>\n",
       "      <td>233</td>\n",
       "      <td>02</td>\n",
       "      <td>16</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03_04</td>\n",
       "      <td>38</td>\n",
       "      <td>542</td>\n",
       "      <td>03</td>\n",
       "      <td>51</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04_05</td>\n",
       "      <td>8</td>\n",
       "      <td>463</td>\n",
       "      <td>04</td>\n",
       "      <td>23</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05_06</td>\n",
       "      <td>62</td>\n",
       "      <td>382</td>\n",
       "      <td>05</td>\n",
       "      <td>26</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06_07</td>\n",
       "      <td>338</td>\n",
       "      <td>235</td>\n",
       "      <td>06</td>\n",
       "      <td>79</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07_08</td>\n",
       "      <td>563</td>\n",
       "      <td>588</td>\n",
       "      <td>07</td>\n",
       "      <td>527</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08_09</td>\n",
       "      <td>664</td>\n",
       "      <td>512</td>\n",
       "      <td>08</td>\n",
       "      <td>580</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09_10</td>\n",
       "      <td>7689</td>\n",
       "      <td>920</td>\n",
       "      <td>09</td>\n",
       "      <td>4862</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10_11</td>\n",
       "      <td>2096</td>\n",
       "      <td>1398</td>\n",
       "      <td>10</td>\n",
       "      <td>4089</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11_12</td>\n",
       "      <td>973</td>\n",
       "      <td>1771</td>\n",
       "      <td>11</td>\n",
       "      <td>1932</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12_13</td>\n",
       "      <td>1220</td>\n",
       "      <td>3223</td>\n",
       "      <td>12</td>\n",
       "      <td>768</td>\n",
       "      <td>2346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13_14</td>\n",
       "      <td>2157</td>\n",
       "      <td>1643</td>\n",
       "      <td>13</td>\n",
       "      <td>1598</td>\n",
       "      <td>2740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14_15</td>\n",
       "      <td>1341</td>\n",
       "      <td>4267</td>\n",
       "      <td>14</td>\n",
       "      <td>2147</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15_16</td>\n",
       "      <td>4430</td>\n",
       "      <td>3689</td>\n",
       "      <td>15</td>\n",
       "      <td>1494</td>\n",
       "      <td>5307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16_17</td>\n",
       "      <td>3756</td>\n",
       "      <td>7986</td>\n",
       "      <td>16</td>\n",
       "      <td>6395</td>\n",
       "      <td>3437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17_18</td>\n",
       "      <td>3893</td>\n",
       "      <td>9815</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>11116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18_19</td>\n",
       "      <td>9167</td>\n",
       "      <td>7015</td>\n",
       "      <td>18</td>\n",
       "      <td>5786</td>\n",
       "      <td>7401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19_20</td>\n",
       "      <td>9508</td>\n",
       "      <td>10099</td>\n",
       "      <td>19</td>\n",
       "      <td>10038</td>\n",
       "      <td>10540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20_21</td>\n",
       "      <td>1728</td>\n",
       "      <td>844</td>\n",
       "      <td>20</td>\n",
       "      <td>7143</td>\n",
       "      <td>4608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21_22</td>\n",
       "      <td>735</td>\n",
       "      <td>6843</td>\n",
       "      <td>21</td>\n",
       "      <td>375</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22_23</td>\n",
       "      <td>8422</td>\n",
       "      <td>24342</td>\n",
       "      <td>22</td>\n",
       "      <td>2250</td>\n",
       "      <td>18703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   north_season  north_h1n1  north_h3n2 south_season  south_h1n1  south_h3n2\n",
       "0         02_03          34         233           02          16         346\n",
       "1         03_04          38         542           03          51         253\n",
       "2         04_05           8         463           04          23         564\n",
       "3         05_06          62         382           05          26         525\n",
       "4         06_07         338         235           06          79         197\n",
       "5         07_08         563         588           07         527         465\n",
       "6         08_09         664         512           08         580         528\n",
       "7         09_10        7689         920           09        4862        1046\n",
       "8         10_11        2096        1398           10        4089         613\n",
       "9         11_12         973        1771           11        1932        1578\n",
       "10        12_13        1220        3223           12         768        2346\n",
       "11        13_14        2157        1643           13        1598        2740\n",
       "12        14_15        1341        4267           14        2147        1981\n",
       "13        15_16        4430        3689           15        1494        5307\n",
       "14        16_17        3756        7986           16        6395        3437\n",
       "15        17_18        3893        9815           17        2018       11116\n",
       "16        18_19        9167        7015           18        5786        7401\n",
       "17        19_20        9508       10099           19       10038       10540\n",
       "18        20_21        1728         844           20        7143        4608\n",
       "19        21_22         735        6843           21         375         737\n",
       "20        22_23        8422       24342           22        2250       18703"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = pd.DataFrame({})\n",
    "for SEASON in ['north', 'south']:\n",
    "    YEARS = NORTH_YEARS\n",
    "    if SEASON == 'south':\n",
    "        YEARS = SOUTH_YEARS\n",
    "    num_seqs[SEASON + '_season'] = YEARS\n",
    "    \n",
    "    for SUBTYPE in ['h1n1', 'h3n2']:\n",
    "        seq_cnt = []\n",
    "        NAME = SEASON + '_' + SUBTYPE\n",
    "        DIR = DATA_DIR + NAME + '/'\n",
    "        for i in range(21):\n",
    "            seq_df = pd.read_csv(DIR+NAME+'_'+YEARS[i]+'.csv')\n",
    "            seq_cnt.append(len(seq_df))\n",
    "        num_seqs[NAME] = seq_cnt\n",
    "num_seqs.to_csv(DATA_DIR+'num_seqs.csv', index=False)\n",
    "num_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b17180b-7ad8-4e1a-ad33-d13fc0728ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>north_season</th>\n",
       "      <th>north_h1n1</th>\n",
       "      <th>north_h3n2</th>\n",
       "      <th>south_season</th>\n",
       "      <th>south_h1n1</th>\n",
       "      <th>south_h3n2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02_03</td>\n",
       "      <td>31</td>\n",
       "      <td>141</td>\n",
       "      <td>02</td>\n",
       "      <td>15</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03_04</td>\n",
       "      <td>37</td>\n",
       "      <td>305</td>\n",
       "      <td>03</td>\n",
       "      <td>35</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04_05</td>\n",
       "      <td>44</td>\n",
       "      <td>444</td>\n",
       "      <td>04</td>\n",
       "      <td>39</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05_06</td>\n",
       "      <td>84</td>\n",
       "      <td>567</td>\n",
       "      <td>05</td>\n",
       "      <td>53</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06_07</td>\n",
       "      <td>229</td>\n",
       "      <td>689</td>\n",
       "      <td>06</td>\n",
       "      <td>109</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>07_08</td>\n",
       "      <td>563</td>\n",
       "      <td>995</td>\n",
       "      <td>07</td>\n",
       "      <td>340</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08_09</td>\n",
       "      <td>1000</td>\n",
       "      <td>1248</td>\n",
       "      <td>08</td>\n",
       "      <td>723</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>09_10</td>\n",
       "      <td>3336</td>\n",
       "      <td>1623</td>\n",
       "      <td>09</td>\n",
       "      <td>2140</td>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10_11</td>\n",
       "      <td>4352</td>\n",
       "      <td>2175</td>\n",
       "      <td>10</td>\n",
       "      <td>3736</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11_12</td>\n",
       "      <td>4862</td>\n",
       "      <td>2890</td>\n",
       "      <td>11</td>\n",
       "      <td>4691</td>\n",
       "      <td>2450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12_13</td>\n",
       "      <td>5562</td>\n",
       "      <td>3893</td>\n",
       "      <td>12</td>\n",
       "      <td>5156</td>\n",
       "      <td>3357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13_14</td>\n",
       "      <td>6542</td>\n",
       "      <td>4490</td>\n",
       "      <td>13</td>\n",
       "      <td>6061</td>\n",
       "      <td>4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14_15</td>\n",
       "      <td>7101</td>\n",
       "      <td>5810</td>\n",
       "      <td>14</td>\n",
       "      <td>6912</td>\n",
       "      <td>4877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15_16</td>\n",
       "      <td>8549</td>\n",
       "      <td>7046</td>\n",
       "      <td>15</td>\n",
       "      <td>7552</td>\n",
       "      <td>6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16_17</td>\n",
       "      <td>9592</td>\n",
       "      <td>9458</td>\n",
       "      <td>16</td>\n",
       "      <td>9302</td>\n",
       "      <td>7692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17_18</td>\n",
       "      <td>11002</td>\n",
       "      <td>12105</td>\n",
       "      <td>17</td>\n",
       "      <td>10105</td>\n",
       "      <td>10901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18_19</td>\n",
       "      <td>14210</td>\n",
       "      <td>14332</td>\n",
       "      <td>18</td>\n",
       "      <td>12250</td>\n",
       "      <td>12977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19_20</td>\n",
       "      <td>17219</td>\n",
       "      <td>17363</td>\n",
       "      <td>19</td>\n",
       "      <td>15474</td>\n",
       "      <td>16191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20_21</td>\n",
       "      <td>17742</td>\n",
       "      <td>17695</td>\n",
       "      <td>20</td>\n",
       "      <td>17703</td>\n",
       "      <td>17613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21_22</td>\n",
       "      <td>18057</td>\n",
       "      <td>19054</td>\n",
       "      <td>21</td>\n",
       "      <td>17868</td>\n",
       "      <td>17904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22_23</td>\n",
       "      <td>20063</td>\n",
       "      <td>24297</td>\n",
       "      <td>22</td>\n",
       "      <td>18574</td>\n",
       "      <td>21509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   north_season  north_h1n1  north_h3n2 south_season  south_h1n1  south_h3n2\n",
       "0         02_03          31         141           02          15         123\n",
       "1         03_04          37         305           03          35         208\n",
       "2         04_05          44         444           04          39         381\n",
       "3         05_06          84         567           05          53         520\n",
       "4         06_07         229         689           06         109         602\n",
       "5         07_08         563         995           07         340         862\n",
       "6         08_09        1000        1248           08         723        1112\n",
       "7         09_10        3336        1623           09        2140        1553\n",
       "8         10_11        4352        2175           10        3736        1840\n",
       "9         11_12        4862        2890           11        4691        2450\n",
       "10        12_13        5562        3893           12        5156        3357\n",
       "11        13_14        6542        4490           13        6061        4167\n",
       "12        14_15        7101        5810           14        6912        4877\n",
       "13        15_16        8549        7046           15        7552        6508\n",
       "14        16_17        9592        9458           16        9302        7692\n",
       "15        17_18       11002       12105           17       10105       10901\n",
       "16        18_19       14210       14332           18       12250       12977\n",
       "17        19_20       17219       17363           19       15474       16191\n",
       "18        20_21       17742       17695           20       17703       17613\n",
       "19        21_22       18057       19054           21       17868       17904\n",
       "20        22_23       20063       24297           22       18574       21509"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs_pred = pd.DataFrame({})\n",
    "for SEASON in ['north', 'south']:\n",
    "    YEARS = NORTH_YEARS\n",
    "    if SEASON == 'south':\n",
    "        YEARS = SOUTH_YEARS\n",
    "    num_seqs_pred[SEASON + '_season'] = YEARS\n",
    "    \n",
    "    for SUBTYPE in ['h1n1', 'h3n2']:\n",
    "        seq_cnt = []\n",
    "        NAME = SEASON + '_' + SUBTYPE\n",
    "        DIR = DATA_DIR + NAME + '/pred/'\n",
    "        for i in range(21):\n",
    "            seq_df = pd.read_csv(DIR+NAME+'_'+YEARS[i]+'.csv')\n",
    "            seq_cnt.append(len(seq_df))\n",
    "        num_seqs_pred[NAME] = seq_cnt\n",
    "num_seqs_pred.to_csv(DATA_DIR+'num_seqs_pred.csv', index=False)\n",
    "num_seqs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148f7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
